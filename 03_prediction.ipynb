{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting diabetes status using NHANES\n",
    "\n",
    "[DSLC stages]: Analysis\n",
    "\n",
    "\n",
    "\n",
    "The following code sets up the libraries and creates cleaned and pre-processed training, validation and test data that we will use in this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from functions.load_diabetes_data import load_diabetes_data\n",
    "# load the diabetes data\n",
    "\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "val_data = pd.read_csv('val_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "imputed_2017 = pd.read_csv('imputed_2017.csv')\n",
    "\n",
    "train_data_noSMOTE = pd.read_csv('train_data_noSMOTE.csv')\n",
    "val_data_noSMOTE = pd.read_csv('val_data_noSMOTE.csv')\n",
    "test_data_noSMOTE = pd.read_csv('test_data_noSMOTE.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)\n",
    "print(imputed_2017.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2017 = imputed_2017.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test_2017 = imputed_2017['diabetes']\n",
    "X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "\n",
    "# To predict on the test data\n",
    "X_test = test_data.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test = test_data['diabetes']\n",
    "X_test = X_test.drop(columns=columns_to_drop.values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noSMOTE = train_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_train_noSMOTE = train_data_noSMOTE['diabetes']\n",
    "\n",
    "X_val_noSMOTE = val_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_val_noSMOTE = val_data_noSMOTE['diabetes']\n",
    "\n",
    "X_test_noSMOTE = test_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_test_noSMOTE = test_data_noSMOTE['diabetes']\n",
    "\n",
    "# Optional: Check for missing values\n",
    "#print(X_train.isnull().sum())\n",
    "#print(X_val.isnull().sum())\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_noSMOTE = scaler.fit_transform(X_train_noSMOTE)\n",
    "X_val_scaled_noSMOTE = scaler.transform(X_val_noSMOTE)\n",
    "X_test_scaled_noSMOTE = scaler.transform(X_test_noSMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_family_person_id</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>age</th>\n",
       "      <th>smoker</th>\n",
       "      <th>sex</th>\n",
       "      <th>coronary_heart_disease</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>height</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_condition</th>\n",
       "      <th>cancer</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>doctor_recommend_exercise</th>\n",
       "      <th>moderate_physical_activity</th>\n",
       "      <th>vigorous_physical_activity</th>\n",
       "      <th>alcohol_past_year</th>\n",
       "      <th>high_blood_pressure_prescription</th>\n",
       "      <th>medicated</th>\n",
       "      <th>prediabetes</th>\n",
       "      <th>insulin</th>\n",
       "      <th>region_Midwest</th>\n",
       "      <th>region_Northwest</th>\n",
       "      <th>region_South</th>\n",
       "      <th>marital_status_Divorced</th>\n",
       "      <th>marital_status_Living with partner</th>\n",
       "      <th>marital_status_Married</th>\n",
       "      <th>marital_status_Never_married</th>\n",
       "      <th>marital_status_Separated</th>\n",
       "      <th>marital_status_Widdowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277060102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.2</td>\n",
       "      <td>2307.4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389730101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2624.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468630101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256810101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2829.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300550101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>652990101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3055.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>429240101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>628450101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>392830101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>139790101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3026.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_family_person_id  diabetes   age  smoker  sex  \\\n",
       "0             277060102.0       1.0  60.0     0.0  1.0   \n",
       "1             389730101.0       1.0  48.0     1.0  0.0   \n",
       "2             468630101.0       0.0  66.0     0.0  1.0   \n",
       "3             256810101.0       0.0  48.0     1.0  1.0   \n",
       "4             300550101.0       0.0  39.0     1.0  0.0   \n",
       "5             652990101.0       0.0  61.0     1.0  0.0   \n",
       "6             429240101.0       0.0  69.0     1.0  1.0   \n",
       "7             628450101.0       1.0  80.0     0.0  0.0   \n",
       "8             392830101.0       0.0  60.0     0.0  0.0   \n",
       "9             139790101.0       0.0  30.0     0.0  0.0   \n",
       "\n",
       "   coronary_heart_disease  weight     bmi  height  hypertension  \\\n",
       "0                     0.0   136.2  2307.4    66.0           1.0   \n",
       "1                     0.0   188.0  2624.0    71.0           0.0   \n",
       "2                     0.0   140.0  2261.0    66.0           0.0   \n",
       "3                     0.0   165.0  2829.0    64.0           0.0   \n",
       "4                     0.0   148.0  2316.0    67.0           0.0   \n",
       "5                     0.0   195.0  3055.0    67.0           1.0   \n",
       "6                     0.0   140.0  2330.0    65.0           1.0   \n",
       "7                     1.0   212.0  2583.0    76.0           1.0   \n",
       "8                     0.0   214.0  2903.0    72.0           1.0   \n",
       "9                     0.0   242.0  3026.0    75.0           0.0   \n",
       "\n",
       "   heart_condition  cancer  family_history_diabetes  \\\n",
       "0              0.0     0.0                      1.0   \n",
       "1              0.0     0.0                      1.0   \n",
       "2              0.0     0.0                      0.0   \n",
       "3              0.0     0.0                      0.0   \n",
       "4              0.0     0.0                      1.0   \n",
       "5              1.0     0.0                      0.0   \n",
       "6              0.0     0.0                      1.0   \n",
       "7              0.0     0.0                      1.0   \n",
       "8              0.0     0.0                      0.0   \n",
       "9              0.0     0.0                      0.0   \n",
       "\n",
       "   doctor_recommend_exercise  moderate_physical_activity  \\\n",
       "0                        1.0                         5.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         7.0   \n",
       "3                        0.0                         5.0   \n",
       "4                        0.0                         0.0   \n",
       "5                        1.0                         7.0   \n",
       "6                        0.0                         0.0   \n",
       "7                        1.0                         7.0   \n",
       "8                        1.0                         3.0   \n",
       "9                        1.0                         7.0   \n",
       "\n",
       "   vigorous_physical_activity  alcohol_past_year  \\\n",
       "0                         0.0                2.0   \n",
       "1                         0.0                2.0   \n",
       "2                         0.0                0.0   \n",
       "3                         2.0                0.0   \n",
       "4                         0.0                5.0   \n",
       "5                         0.0                2.0   \n",
       "6                         0.0                0.0   \n",
       "7                         0.0                0.0   \n",
       "8                         0.0                1.0   \n",
       "9                         3.0                3.0   \n",
       "\n",
       "   high_blood_pressure_prescription  medicated  prediabetes  insulin  \\\n",
       "0                               1.0        1.0          0.0      0.0   \n",
       "1                               1.0        1.0          0.0      0.0   \n",
       "2                               1.0        1.0          0.0      1.0   \n",
       "3                               1.0        0.0          1.0      0.0   \n",
       "4                               1.0        0.0          0.0      0.0   \n",
       "5                               1.0        0.0          1.0      0.0   \n",
       "6                               1.0        0.0          1.0      0.0   \n",
       "7                               1.0        1.0          0.0      0.0   \n",
       "8                               1.0        0.0          0.0      0.0   \n",
       "9                               1.0        1.0          0.0      0.0   \n",
       "\n",
       "   region_Midwest  region_Northwest  region_South  marital_status_Divorced  \\\n",
       "0             0.0               0.0           0.0                      0.0   \n",
       "1             0.0               1.0           0.0                      0.0   \n",
       "2             1.0               0.0           0.0                      1.0   \n",
       "3             0.0               0.0           1.0                      1.0   \n",
       "4             1.0               0.0           0.0                      0.0   \n",
       "5             0.0               0.0           1.0                      0.0   \n",
       "6             0.0               0.0           1.0                      1.0   \n",
       "7             1.0               0.0           0.0                      0.0   \n",
       "8             0.0               0.0           0.0                      0.0   \n",
       "9             0.0               1.0           0.0                      0.0   \n",
       "\n",
       "   marital_status_Living with partner  marital_status_Married  \\\n",
       "0                                 0.0                     1.0   \n",
       "1                                 0.0                     1.0   \n",
       "2                                 0.0                     0.0   \n",
       "3                                 0.0                     0.0   \n",
       "4                                 0.0                     1.0   \n",
       "5                                 0.0                     1.0   \n",
       "6                                 0.0                     0.0   \n",
       "7                                 0.0                     0.0   \n",
       "8                                 0.0                     1.0   \n",
       "9                                 0.0                     1.0   \n",
       "\n",
       "   marital_status_Never_married  marital_status_Separated  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "5                           0.0                       0.0   \n",
       "6                           0.0                       0.0   \n",
       "7                           0.0                       0.0   \n",
       "8                           0.0                       0.0   \n",
       "9                           0.0                       0.0   \n",
       "\n",
       "   marital_status_Widdowed  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "5                      0.0  \n",
       "6                      0.0  \n",
       "7                      1.0  \n",
       "8                      0.0  \n",
       "9                      0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Sample dataset\n",
    "# df = pd.read_csv('your_data.csv')  # Load your dataset\n",
    "\n",
    "# Prepare your features (X)\n",
    "# Assuming 'diabetes' is your target variable and all other columns are features\n",
    "X = train_data.drop(columns=['diabetes'])\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = X.columns\n",
    "vif_data['VIF'] = [sm.OLS(X[column], X.loc[:, X.columns != column]).fit().rsquared for column in X.columns]\n",
    "\n",
    "# Calculate the VIF\n",
    "vif_data['VIF'] = 1 / (1 - vif_data['VIF'])\n",
    "\n",
    "# Display the VIF results\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with mean above the threshold\n",
    "threshold = 10\n",
    "columns_to_drop = vif_data[vif_data[\"VIF\"] > threshold]\n",
    "print(columns_to_drop)\n",
    "#print(vif_data[vif_data[\"VIF\"] > threshold])\n",
    "columns_to_drop = columns_to_drop[\"Feature\"]\n",
    "print(columns_to_drop.values)\n",
    "\n",
    "# Drop those columns\n",
    "train_data = train_data.drop(columns=columns_to_drop.values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26104, 24)\n",
      "(8701, 24)\n",
      "(26311, 24)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test_2017.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>smoker</th>\n",
       "      <th>sex</th>\n",
       "      <th>coronary_heart_disease</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>height</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_condition</th>\n",
       "      <th>cancer</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>doctor_recommend_exercise</th>\n",
       "      <th>moderate_physical_activity</th>\n",
       "      <th>vigorous_physical_activity</th>\n",
       "      <th>alcohol_past_year</th>\n",
       "      <th>high_blood_pressure_prescription</th>\n",
       "      <th>medicated</th>\n",
       "      <th>prediabetes</th>\n",
       "      <th>insulin</th>\n",
       "      <th>stroke</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>region_Midwest</th>\n",
       "      <th>region_Northwest</th>\n",
       "      <th>region_South</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>4313.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3227.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  smoker  sex  coronary_heart_disease  weight     bmi  height  \\\n",
       "0  65.0     1.0  1.0                     0.0   155.0  2930.0    61.0   \n",
       "1  19.0     0.0  0.0                     0.0   180.0  2309.0    74.0   \n",
       "2  45.0     1.0  0.0                     0.0   240.0  3544.0    69.0   \n",
       "3  67.0     1.0  1.0                     0.0   236.0  4313.0    62.0   \n",
       "4  40.0     1.0  0.0                     0.0   182.0  3227.0    63.0   \n",
       "\n",
       "   hypertension  heart_condition  cancer  family_history_diabetes  \\\n",
       "0           1.0              0.0     0.0                      0.0   \n",
       "1           0.0              0.0     0.0                      0.0   \n",
       "2           0.0              0.0     0.0                      0.0   \n",
       "3           0.0              0.0     0.0                      0.0   \n",
       "4           0.0              0.0     0.0                      0.0   \n",
       "\n",
       "   doctor_recommend_exercise  moderate_physical_activity  \\\n",
       "0                        1.0                         0.0   \n",
       "1                        1.0                         3.8   \n",
       "2                        0.0                         2.0   \n",
       "3                        1.0                         7.0   \n",
       "4                        0.0                         3.0   \n",
       "\n",
       "   vigorous_physical_activity  alcohol_past_year  \\\n",
       "0                         7.0                1.0   \n",
       "1                         3.0                2.0   \n",
       "2                         0.0                2.0   \n",
       "3                         3.0               12.0   \n",
       "4                         0.0                3.0   \n",
       "\n",
       "   high_blood_pressure_prescription  medicated  prediabetes  insulin  stroke  \\\n",
       "0                               1.0        0.0          0.0      0.0     0.0   \n",
       "1                               1.0        0.0          0.0      0.0     0.0   \n",
       "2                               1.0        0.0          0.0      0.0     0.0   \n",
       "3                               1.0        0.0          1.0      0.0     0.0   \n",
       "4                               1.0        0.0          0.0      0.0     0.0   \n",
       "\n",
       "   cholesterol  region_Midwest  region_Northwest  region_South  \n",
       "0          0.0             1.0               0.0           0.0  \n",
       "1          0.0             0.0               1.0           0.0  \n",
       "2          0.0             0.0               1.0           0.0  \n",
       "3          0.0             0.0               1.0           0.0  \n",
       "4          0.0             1.0               0.0           0.0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 0.9397410358565738\n",
      "Confusion Matrix:\n",
      " [[16922   463]\n",
      " [ 1110  7609]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96     17385\n",
      "         1.0       0.94      0.87      0.91      8719\n",
      "\n",
      "    accuracy                           0.94     26104\n",
      "   macro avg       0.94      0.92      0.93     26104\n",
      "weighted avg       0.94      0.94      0.94     26104\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9339156418802437\n",
      "Confusion Matrix:\n",
      " [[5592  173]\n",
      " [ 402 2534]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95      5765\n",
      "         1.0       0.94      0.86      0.90      2936\n",
      "\n",
      "    accuracy                           0.93      8701\n",
      "   macro avg       0.93      0.92      0.92      8701\n",
      "weighted avg       0.93      0.93      0.93      8701\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.936451390484946\n",
      "Confusion Matrix:\n",
      " [[5684  171]\n",
      " [ 382 2465]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95      5855\n",
      "         1.0       0.94      0.87      0.90      2847\n",
      "\n",
      "    accuracy                           0.94      8702\n",
      "   macro avg       0.94      0.92      0.93      8702\n",
      "weighted avg       0.94      0.94      0.94      8702\n",
      "\n",
      "\n",
      "[[21970  1551]\n",
      " [ 1034  1756]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94     23521\n",
      "         1.0       0.53      0.63      0.58      2790\n",
      "\n",
      "    accuracy                           0.90     26311\n",
      "   macro avg       0.74      0.78      0.76     26311\n",
      "weighted avg       0.91      0.90      0.91     26311\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9156246436851507\n",
      "Confusion Matrix:\n",
      " [[22893   628]\n",
      " [ 1592  1198]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95     23521\n",
      "         1.0       0.66      0.43      0.52      2790\n",
      "\n",
      "    accuracy                           0.92     26311\n",
      "   macro avg       0.80      0.70      0.74     26311\n",
      "weighted avg       0.91      0.92      0.91     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming the target variable is named 'diabetes' and is binary (0 or 1)\n",
    "X_train = train_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_train = train_data['diabetes']\n",
    "\n",
    "X_val = val_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_val = val_data['diabetes']\n",
    "# Drop those columns\n",
    "X_val = X_val.drop(columns=columns_to_drop.values[1:])\n",
    "\n",
    "# Optional: Check for missing values\n",
    "#print(X_train.isnull().sum())\n",
    "#print(X_val.isnull().sum())\n",
    "\n",
    "# Scale the features\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Calculate the number of samples in each class\n",
    "count_0 = sum(y_train == 0)\n",
    "count_1 = sum(y_train == 1)\n",
    "\n",
    "# Calculate the ratio\n",
    "ratio_of_majority_to_minority = count_0 / count_1\n",
    "\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=2000, \n",
    "    learning_rate=0.005, \n",
    "    eval_metric='aucpr', \n",
    "    max_depth=5,\n",
    "    reg_alpha=5,  # Increased L1 regularization\n",
    "    reg_lambda=15,  # Increased L2 regularization\n",
    "    #scale_pos_weight=ratio_of_majority_to_minority\n",
    ")\n",
    "#xgb_clf = XGBClassifier(n_estimators=1000, learning_rate=0.01, eval_metric='aucpr', max_depth=3)\n",
    "xgb_clf.fit(X_train, y_train, eval_set=[(X_test_2017, y_test_2017)], verbose=False)\n",
    "\n",
    "y_train_pred = xgb_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = xgb_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "#X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "y_pred_2017 = xgb_clf.predict(X_test_2017)\n",
    "y_pred_probs = xgb_clf.predict_proba(X_test_2017)[:, 1]\n",
    "threshold = 0.2632804811000824\n",
    "y_pred_custom = (y_pred_probs >= threshold).astype(int)  # Apply custom threshold\n",
    "print()\n",
    "print(confusion_matrix(y_test_2017, y_pred_custom))\n",
    "print(classification_report(y_test_2017, y_pred_custom))\n",
    "\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_2017, y_pred_probs)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Precision / Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-Score: 0.5760209939314417 at Threshold: 0.2632804811000824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize best score\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "# Test different thresholds\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_probs >= thresh).astype(int)\n",
    "    f1 = f1_score(y_test_2017, y_pred_thresh)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"Best F1-Score: {best_f1} at Threshold: {best_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 0.9477474716518541\n",
      "Confusion Matrix:\n",
      " [[17044   341]\n",
      " [ 1023  7696]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     17385\n",
      "         1.0       0.96      0.88      0.92      8719\n",
      "\n",
      "    accuracy                           0.95     26104\n",
      "   macro avg       0.95      0.93      0.94     26104\n",
      "weighted avg       0.95      0.95      0.95     26104\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9352947937018733\n",
      "Confusion Matrix:\n",
      " [[5611  154]\n",
      " [ 409 2527]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95      5765\n",
      "         1.0       0.94      0.86      0.90      2936\n",
      "\n",
      "    accuracy                           0.94      8701\n",
      "   macro avg       0.94      0.92      0.93      8701\n",
      "weighted avg       0.94      0.94      0.93      8701\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.9342679843714089\n",
      "Confusion Matrix:\n",
      " [[5680  175]\n",
      " [ 397 2450]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95      5855\n",
      "         1.0       0.93      0.86      0.90      2847\n",
      "\n",
      "    accuracy                           0.93      8702\n",
      "   macro avg       0.93      0.92      0.92      8702\n",
      "weighted avg       0.93      0.93      0.93      8702\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9150925468435255\n",
      "Confusion Matrix:\n",
      " [[22907   614]\n",
      " [ 1620  1170]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95     23521\n",
      "         1.0       0.66      0.42      0.51      2790\n",
      "\n",
      "    accuracy                           0.92     26311\n",
      "   macro avg       0.79      0.70      0.73     26311\n",
      "weighted avg       0.90      0.92      0.91     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'scale_pos_weight': [1, 10, 20]  # Adjust this based on the imbalance\n",
    "}\n",
    "\n",
    "model = XGBClassifier()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='precision', cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = best_model.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 0.9911124731841864\n",
      "Confusion Matrix:\n",
      " [[17153   232]\n",
      " [    0  8719]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99     17385\n",
      "         1.0       0.97      1.00      0.99      8719\n",
      "\n",
      "    accuracy                           0.99     26104\n",
      "   macro avg       0.99      0.99      0.99     26104\n",
      "weighted avg       0.99      0.99      0.99     26104\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9304677623261695\n",
      "Confusion Matrix:\n",
      " [[5468  297]\n",
      " [ 308 2628]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95      5765\n",
      "         1.0       0.90      0.90      0.90      2936\n",
      "\n",
      "    accuracy                           0.93      8701\n",
      "   macro avg       0.92      0.92      0.92      8701\n",
      "weighted avg       0.93      0.93      0.93      8701\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.9343829004826477\n",
      "Confusion Matrix:\n",
      " [[5573  282]\n",
      " [ 289 2558]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95      5855\n",
      "         1.0       0.90      0.90      0.90      2847\n",
      "\n",
      "    accuracy                           0.93      8702\n",
      "   macro avg       0.93      0.93      0.93      8702\n",
      "weighted avg       0.93      0.93      0.93      8702\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9095435369237201\n",
      "Confusion Matrix:\n",
      " [[22423  1098]\n",
      " [ 1282  1508]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95     23521\n",
      "         1.0       0.58      0.54      0.56      2790\n",
      "\n",
      "    accuracy                           0.91     26311\n",
      "   macro avg       0.76      0.75      0.75     26311\n",
      "weighted avg       0.91      0.91      0.91     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "clf = BalancedRandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = clf.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->catboost) (6.4.5)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.20.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_clf = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.01, is_unbalance=True)\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = lgb_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = lgb_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = lgb_clf.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m      2\u001b[0m cat_clf \u001b[38;5;241m=\u001b[39m CatBoostClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, auto_class_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m cat_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_clf = CatBoostClassifier(n_estimators=1000, learning_rate=0.01, auto_class_weights='Balanced', verbose=False)\n",
    "cat_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = cat_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = cat_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = cat_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = cat_clf.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: lightgbm\n"
     ]
    }
   ],
   "source": [
    "pip show lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(n_estimators=1000, learning_rate=0.01)),\n",
    "]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = stacking_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = stacking_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = stacking_clf.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665694785366072 0.6543052146339281\n"
     ]
    }
   ],
   "source": [
    "m = 26311\n",
    "p0 = 0.94\n",
    "p1 = 0.66\n",
    "p_ = p1+ 1.95*((p1*(1-p1)/m)**0.5)\n",
    "p__ = p1-1.95*((p1*(1-p1)/m)**0.5)\n",
    "\n",
    "print(p_,p__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = xgb_clf.predict(X_val)\n",
    "\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "report = classification_report((y_val, y_val_pred, output_dict=True)\n",
    "precision_0 = report['0.0']['precision']\n",
    "recall_0 = report['0.0']['recall']\n",
    "precision_1 = report['1.0']['precision']\n",
    "recall_1 = report['1.0']['recall']\n",
    "\n",
    "y_pred_2017 = xgb_clf.predict(X_test_2017)\n",
    "\n",
    "report_2017 = classification_report(y_test_2017, y_pred_2017, output_dict=True)\n",
    "precision_0_2017 = report_2017['0.0']['precision']\n",
    "recall_0_2017 = report_2017['0.0']['recall']\n",
    "precision_1_2017 = report_2017['1.0']['precision']\n",
    "recall_1_2017 = report_2017['1.0']['recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 Performance Evaluation:\n",
      "Observed Precision: 0.9354\n",
      "Null Hypothesis Precision (p0): 0.9451\n",
      "Z-Statistic: -6.9477\n",
      "P-Value: 0.0000\n",
      "Reject the null hypothesis: The model's precision for class 0.0 is significantly different from the expected value.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Class 1.0 Performance Evaluation:\n",
      "Observed Precision: 0.6569\n",
      "Null Hypothesis Precision (p0): 0.9560\n",
      "Z-Statistic: -236.4810\n",
      "P-Value: 0.0000\n",
      "Reject the null hypothesis: The model's precision for class 1.0 is significantly different from the expected value.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Define null hypothesis values (expected precision under H0)\n",
    "p0_0 = precision_0  # Expected precision for class 0.0 (you can adjust this)\n",
    "p0_1 = precision_1  # Expected precision for class 1.0 (you can adjust this)\n",
    "\n",
    "# Get the number of samples for the precision calculations\n",
    "n = len(y_pred_2017)  # Total number of samples\n",
    "\n",
    "# 1. Evaluate the performance for class 0.0\n",
    "observed_precision_0 = precision_0_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 0.0\n",
    "Z_0 = (observed_precision_0 - p0_0) / np.sqrt((p0_0 * (1 - p0_0)) / n)\n",
    "\n",
    "# Calculate p-value for class 0.0\n",
    "p_value_0 = 2 * (1 - stats.norm.cdf(np.abs(Z_0)))\n",
    "\n",
    "# Evaluate the hypothesis for class 0.0\n",
    "print(f\"Class 0.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_0:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_0:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_0:.4f}\")\n",
    "print(f\"P-Value: {p_value_0:.4f}\")\n",
    "\n",
    "if p_value_0 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 0.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 0.0.\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity\n",
    "\n",
    "# 2. Evaluate the performance for class 1.0\n",
    "observed_precision_1 = precision_1_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 1.0\n",
    "Z_1 = (observed_precision_1 - p0_1) / np.sqrt((p0_1 * (1 - p0_1)) / n)\n",
    "\n",
    "# Calculate p-value for class 1.0\n",
    "p_value_1 = 2 * (1 - stats.norm.cdf(np.abs(Z_1)))\n",
    "\n",
    "# Evaluate the hypothesis for class 1.0\n",
    "print(f\"Class 1.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_1:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_1:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_1:.4f}\")\n",
    "print(f\"P-Value: {p_value_1:.4f}\")\n",
    "\n",
    "if p_value_1 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 1.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 1.0.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.36085\n",
      "[1]\tvalidation_0-logloss:0.35843\n",
      "[2]\tvalidation_0-logloss:0.35608\n",
      "[3]\tvalidation_0-logloss:0.35378\n",
      "[4]\tvalidation_0-logloss:0.35157\n",
      "[5]\tvalidation_0-logloss:0.34943\n",
      "[6]\tvalidation_0-logloss:0.34730\n",
      "[7]\tvalidation_0-logloss:0.34523\n",
      "[8]\tvalidation_0-logloss:0.34323\n",
      "[9]\tvalidation_0-logloss:0.34126\n",
      "[10]\tvalidation_0-logloss:0.33935\n",
      "[11]\tvalidation_0-logloss:0.33744\n",
      "[12]\tvalidation_0-logloss:0.33564\n",
      "[13]\tvalidation_0-logloss:0.33382\n",
      "[14]\tvalidation_0-logloss:0.33207\n",
      "[15]\tvalidation_0-logloss:0.33033\n",
      "[16]\tvalidation_0-logloss:0.32865\n",
      "[17]\tvalidation_0-logloss:0.32697\n",
      "[18]\tvalidation_0-logloss:0.32536\n",
      "[19]\tvalidation_0-logloss:0.32378\n",
      "[20]\tvalidation_0-logloss:0.32221\n",
      "[21]\tvalidation_0-logloss:0.32067\n",
      "[22]\tvalidation_0-logloss:0.31912\n",
      "[23]\tvalidation_0-logloss:0.31766\n",
      "[24]\tvalidation_0-logloss:0.31620\n",
      "[25]\tvalidation_0-logloss:0.31479\n",
      "[26]\tvalidation_0-logloss:0.31338\n",
      "[27]\tvalidation_0-logloss:0.31200\n",
      "[28]\tvalidation_0-logloss:0.31066\n",
      "[29]\tvalidation_0-logloss:0.30932\n",
      "[30]\tvalidation_0-logloss:0.30803\n",
      "[31]\tvalidation_0-logloss:0.30674\n",
      "[32]\tvalidation_0-logloss:0.30546\n",
      "[33]\tvalidation_0-logloss:0.30422\n",
      "[34]\tvalidation_0-logloss:0.30296\n",
      "[35]\tvalidation_0-logloss:0.30176\n",
      "[36]\tvalidation_0-logloss:0.30055\n",
      "[37]\tvalidation_0-logloss:0.29940\n",
      "[38]\tvalidation_0-logloss:0.29825\n",
      "[39]\tvalidation_0-logloss:0.29711\n",
      "[40]\tvalidation_0-logloss:0.29600\n",
      "[41]\tvalidation_0-logloss:0.29489\n",
      "[42]\tvalidation_0-logloss:0.29382\n",
      "[43]\tvalidation_0-logloss:0.29276\n",
      "[44]\tvalidation_0-logloss:0.29170\n",
      "[45]\tvalidation_0-logloss:0.29068\n",
      "[46]\tvalidation_0-logloss:0.28966\n",
      "[47]\tvalidation_0-logloss:0.28866\n",
      "[48]\tvalidation_0-logloss:0.28767\n",
      "[49]\tvalidation_0-logloss:0.28670\n",
      "[50]\tvalidation_0-logloss:0.28574\n",
      "[51]\tvalidation_0-logloss:0.28479\n",
      "[52]\tvalidation_0-logloss:0.28386\n",
      "[53]\tvalidation_0-logloss:0.28295\n",
      "[54]\tvalidation_0-logloss:0.28205\n",
      "[55]\tvalidation_0-logloss:0.28115\n",
      "[56]\tvalidation_0-logloss:0.28028\n",
      "[57]\tvalidation_0-logloss:0.27941\n",
      "[58]\tvalidation_0-logloss:0.27856\n",
      "[59]\tvalidation_0-logloss:0.27773\n",
      "[60]\tvalidation_0-logloss:0.27691\n",
      "[61]\tvalidation_0-logloss:0.27610\n",
      "[62]\tvalidation_0-logloss:0.27528\n",
      "[63]\tvalidation_0-logloss:0.27449\n",
      "[64]\tvalidation_0-logloss:0.27371\n",
      "[65]\tvalidation_0-logloss:0.27292\n",
      "[66]\tvalidation_0-logloss:0.27215\n",
      "[67]\tvalidation_0-logloss:0.27140\n",
      "[68]\tvalidation_0-logloss:0.27067\n",
      "[69]\tvalidation_0-logloss:0.26995\n",
      "[70]\tvalidation_0-logloss:0.26924\n",
      "[71]\tvalidation_0-logloss:0.26854\n",
      "[72]\tvalidation_0-logloss:0.26784\n",
      "[73]\tvalidation_0-logloss:0.26717\n",
      "[74]\tvalidation_0-logloss:0.26650\n",
      "[75]\tvalidation_0-logloss:0.26585\n",
      "[76]\tvalidation_0-logloss:0.26518\n",
      "[77]\tvalidation_0-logloss:0.26452\n",
      "[78]\tvalidation_0-logloss:0.26388\n",
      "[79]\tvalidation_0-logloss:0.26325\n",
      "[80]\tvalidation_0-logloss:0.26265\n",
      "[81]\tvalidation_0-logloss:0.26205\n",
      "[82]\tvalidation_0-logloss:0.26145\n",
      "[83]\tvalidation_0-logloss:0.26087\n",
      "[84]\tvalidation_0-logloss:0.26029\n",
      "[85]\tvalidation_0-logloss:0.25972\n",
      "[86]\tvalidation_0-logloss:0.25914\n",
      "[87]\tvalidation_0-logloss:0.25858\n",
      "[88]\tvalidation_0-logloss:0.25802\n",
      "[89]\tvalidation_0-logloss:0.25748\n",
      "[90]\tvalidation_0-logloss:0.25695\n",
      "[91]\tvalidation_0-logloss:0.25641\n",
      "[92]\tvalidation_0-logloss:0.25588\n",
      "[93]\tvalidation_0-logloss:0.25536\n",
      "[94]\tvalidation_0-logloss:0.25485\n",
      "[95]\tvalidation_0-logloss:0.25434\n",
      "[96]\tvalidation_0-logloss:0.25384\n",
      "[97]\tvalidation_0-logloss:0.25335\n",
      "[98]\tvalidation_0-logloss:0.25287\n",
      "[99]\tvalidation_0-logloss:0.25239\n",
      "[100]\tvalidation_0-logloss:0.25192\n",
      "[101]\tvalidation_0-logloss:0.25146\n",
      "[102]\tvalidation_0-logloss:0.25100\n",
      "[103]\tvalidation_0-logloss:0.25056\n",
      "[104]\tvalidation_0-logloss:0.25010\n",
      "[105]\tvalidation_0-logloss:0.24967\n",
      "[106]\tvalidation_0-logloss:0.24924\n",
      "[107]\tvalidation_0-logloss:0.24882\n",
      "[108]\tvalidation_0-logloss:0.24839\n",
      "[109]\tvalidation_0-logloss:0.24798\n",
      "[110]\tvalidation_0-logloss:0.24756\n",
      "[111]\tvalidation_0-logloss:0.24715\n",
      "[112]\tvalidation_0-logloss:0.24675\n",
      "[113]\tvalidation_0-logloss:0.24634\n",
      "[114]\tvalidation_0-logloss:0.24595\n",
      "[115]\tvalidation_0-logloss:0.24557\n",
      "[116]\tvalidation_0-logloss:0.24518\n",
      "[117]\tvalidation_0-logloss:0.24482\n",
      "[118]\tvalidation_0-logloss:0.24445\n",
      "[119]\tvalidation_0-logloss:0.24408\n",
      "[120]\tvalidation_0-logloss:0.24371\n",
      "[121]\tvalidation_0-logloss:0.24336\n",
      "[122]\tvalidation_0-logloss:0.24301\n",
      "[123]\tvalidation_0-logloss:0.24267\n",
      "[124]\tvalidation_0-logloss:0.24232\n",
      "[125]\tvalidation_0-logloss:0.24199\n",
      "[126]\tvalidation_0-logloss:0.24165\n",
      "[127]\tvalidation_0-logloss:0.24131\n",
      "[128]\tvalidation_0-logloss:0.24098\n",
      "[129]\tvalidation_0-logloss:0.24065\n",
      "[130]\tvalidation_0-logloss:0.24034\n",
      "[131]\tvalidation_0-logloss:0.24000\n",
      "[132]\tvalidation_0-logloss:0.23970\n",
      "[133]\tvalidation_0-logloss:0.23937\n",
      "[134]\tvalidation_0-logloss:0.23907\n",
      "[135]\tvalidation_0-logloss:0.23874\n",
      "[136]\tvalidation_0-logloss:0.23843\n",
      "[137]\tvalidation_0-logloss:0.23813\n",
      "[138]\tvalidation_0-logloss:0.23783\n",
      "[139]\tvalidation_0-logloss:0.23753\n",
      "[140]\tvalidation_0-logloss:0.23723\n",
      "[141]\tvalidation_0-logloss:0.23696\n",
      "[142]\tvalidation_0-logloss:0.23665\n",
      "[143]\tvalidation_0-logloss:0.23635\n",
      "[144]\tvalidation_0-logloss:0.23605\n",
      "[145]\tvalidation_0-logloss:0.23578\n",
      "[146]\tvalidation_0-logloss:0.23548\n",
      "[147]\tvalidation_0-logloss:0.23520\n",
      "[148]\tvalidation_0-logloss:0.23491\n",
      "[149]\tvalidation_0-logloss:0.23465\n",
      "[150]\tvalidation_0-logloss:0.23437\n",
      "[151]\tvalidation_0-logloss:0.23414\n",
      "[152]\tvalidation_0-logloss:0.23387\n",
      "[153]\tvalidation_0-logloss:0.23361\n",
      "[154]\tvalidation_0-logloss:0.23335\n",
      "[155]\tvalidation_0-logloss:0.23311\n",
      "[156]\tvalidation_0-logloss:0.23285\n",
      "[157]\tvalidation_0-logloss:0.23261\n",
      "[158]\tvalidation_0-logloss:0.23236\n",
      "[159]\tvalidation_0-logloss:0.23211\n",
      "[160]\tvalidation_0-logloss:0.23189\n",
      "[161]\tvalidation_0-logloss:0.23166\n",
      "[162]\tvalidation_0-logloss:0.23143\n",
      "[163]\tvalidation_0-logloss:0.23120\n",
      "[164]\tvalidation_0-logloss:0.23099\n",
      "[165]\tvalidation_0-logloss:0.23075\n",
      "[166]\tvalidation_0-logloss:0.23053\n",
      "[167]\tvalidation_0-logloss:0.23029\n",
      "[168]\tvalidation_0-logloss:0.23010\n",
      "[169]\tvalidation_0-logloss:0.22988\n",
      "[170]\tvalidation_0-logloss:0.22966\n",
      "[171]\tvalidation_0-logloss:0.22947\n",
      "[172]\tvalidation_0-logloss:0.22925\n",
      "[173]\tvalidation_0-logloss:0.22905\n",
      "[174]\tvalidation_0-logloss:0.22883\n",
      "[175]\tvalidation_0-logloss:0.22862\n",
      "[176]\tvalidation_0-logloss:0.22843\n",
      "[177]\tvalidation_0-logloss:0.22825\n",
      "[178]\tvalidation_0-logloss:0.22807\n",
      "[179]\tvalidation_0-logloss:0.22790\n",
      "[180]\tvalidation_0-logloss:0.22770\n",
      "[181]\tvalidation_0-logloss:0.22752\n",
      "[182]\tvalidation_0-logloss:0.22735\n",
      "[183]\tvalidation_0-logloss:0.22718\n",
      "[184]\tvalidation_0-logloss:0.22698\n",
      "[185]\tvalidation_0-logloss:0.22682\n",
      "[186]\tvalidation_0-logloss:0.22666\n",
      "[187]\tvalidation_0-logloss:0.22650\n",
      "[188]\tvalidation_0-logloss:0.22631\n",
      "[189]\tvalidation_0-logloss:0.22616\n",
      "[190]\tvalidation_0-logloss:0.22600\n",
      "[191]\tvalidation_0-logloss:0.22586\n",
      "[192]\tvalidation_0-logloss:0.22569\n",
      "[193]\tvalidation_0-logloss:0.22555\n",
      "[194]\tvalidation_0-logloss:0.22538\n",
      "[195]\tvalidation_0-logloss:0.22525\n",
      "[196]\tvalidation_0-logloss:0.22510\n",
      "[197]\tvalidation_0-logloss:0.22498\n",
      "[198]\tvalidation_0-logloss:0.22483\n",
      "[199]\tvalidation_0-logloss:0.22470\n",
      "[200]\tvalidation_0-logloss:0.22456\n",
      "[201]\tvalidation_0-logloss:0.22441\n",
      "[202]\tvalidation_0-logloss:0.22428\n",
      "[203]\tvalidation_0-logloss:0.22411\n",
      "[204]\tvalidation_0-logloss:0.22397\n",
      "[205]\tvalidation_0-logloss:0.22382\n",
      "[206]\tvalidation_0-logloss:0.22372\n",
      "[207]\tvalidation_0-logloss:0.22356\n",
      "[208]\tvalidation_0-logloss:0.22343\n",
      "[209]\tvalidation_0-logloss:0.22330\n",
      "[210]\tvalidation_0-logloss:0.22316\n",
      "[211]\tvalidation_0-logloss:0.22305\n",
      "[212]\tvalidation_0-logloss:0.22295\n",
      "[213]\tvalidation_0-logloss:0.22283\n",
      "[214]\tvalidation_0-logloss:0.22269\n",
      "[215]\tvalidation_0-logloss:0.22258\n",
      "[216]\tvalidation_0-logloss:0.22245\n",
      "[217]\tvalidation_0-logloss:0.22233\n",
      "[218]\tvalidation_0-logloss:0.22222\n",
      "[219]\tvalidation_0-logloss:0.22211\n",
      "[220]\tvalidation_0-logloss:0.22202\n",
      "[221]\tvalidation_0-logloss:0.22191\n",
      "[222]\tvalidation_0-logloss:0.22177\n",
      "[223]\tvalidation_0-logloss:0.22163\n",
      "[224]\tvalidation_0-logloss:0.22152\n",
      "[225]\tvalidation_0-logloss:0.22139\n",
      "[226]\tvalidation_0-logloss:0.22127\n",
      "[227]\tvalidation_0-logloss:0.22117\n",
      "[228]\tvalidation_0-logloss:0.22105\n",
      "[229]\tvalidation_0-logloss:0.22093\n",
      "[230]\tvalidation_0-logloss:0.22083\n",
      "[231]\tvalidation_0-logloss:0.22072\n",
      "[232]\tvalidation_0-logloss:0.22061\n",
      "[233]\tvalidation_0-logloss:0.22052\n",
      "[234]\tvalidation_0-logloss:0.22042\n",
      "[235]\tvalidation_0-logloss:0.22032\n",
      "[236]\tvalidation_0-logloss:0.22019\n",
      "[237]\tvalidation_0-logloss:0.22009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238]\tvalidation_0-logloss:0.21997\n",
      "[239]\tvalidation_0-logloss:0.21987\n",
      "[240]\tvalidation_0-logloss:0.21976\n",
      "[241]\tvalidation_0-logloss:0.21964\n",
      "[242]\tvalidation_0-logloss:0.21953\n",
      "[243]\tvalidation_0-logloss:0.21944\n",
      "[244]\tvalidation_0-logloss:0.21936\n",
      "[245]\tvalidation_0-logloss:0.21927\n",
      "[246]\tvalidation_0-logloss:0.21919\n",
      "[247]\tvalidation_0-logloss:0.21908\n",
      "[248]\tvalidation_0-logloss:0.21898\n",
      "[249]\tvalidation_0-logloss:0.21888\n",
      "[250]\tvalidation_0-logloss:0.21880\n",
      "[251]\tvalidation_0-logloss:0.21871\n",
      "[252]\tvalidation_0-logloss:0.21861\n",
      "[253]\tvalidation_0-logloss:0.21853\n",
      "[254]\tvalidation_0-logloss:0.21845\n",
      "[255]\tvalidation_0-logloss:0.21838\n",
      "[256]\tvalidation_0-logloss:0.21830\n",
      "[257]\tvalidation_0-logloss:0.21821\n",
      "[258]\tvalidation_0-logloss:0.21811\n",
      "[259]\tvalidation_0-logloss:0.21804\n",
      "[260]\tvalidation_0-logloss:0.21796\n",
      "[261]\tvalidation_0-logloss:0.21788\n",
      "[262]\tvalidation_0-logloss:0.21780\n",
      "[263]\tvalidation_0-logloss:0.21772\n",
      "[264]\tvalidation_0-logloss:0.21765\n",
      "[265]\tvalidation_0-logloss:0.21756\n",
      "[266]\tvalidation_0-logloss:0.21748\n",
      "[267]\tvalidation_0-logloss:0.21740\n",
      "[268]\tvalidation_0-logloss:0.21731\n",
      "[269]\tvalidation_0-logloss:0.21721\n",
      "[270]\tvalidation_0-logloss:0.21713\n",
      "[271]\tvalidation_0-logloss:0.21706\n",
      "[272]\tvalidation_0-logloss:0.21696\n",
      "[273]\tvalidation_0-logloss:0.21691\n",
      "[274]\tvalidation_0-logloss:0.21684\n",
      "[275]\tvalidation_0-logloss:0.21677\n",
      "[276]\tvalidation_0-logloss:0.21669\n",
      "[277]\tvalidation_0-logloss:0.21662\n",
      "[278]\tvalidation_0-logloss:0.21655\n",
      "[279]\tvalidation_0-logloss:0.21647\n",
      "[280]\tvalidation_0-logloss:0.21640\n",
      "[281]\tvalidation_0-logloss:0.21632\n",
      "[282]\tvalidation_0-logloss:0.21626\n",
      "[283]\tvalidation_0-logloss:0.21619\n",
      "[284]\tvalidation_0-logloss:0.21613\n",
      "[285]\tvalidation_0-logloss:0.21607\n",
      "[286]\tvalidation_0-logloss:0.21600\n",
      "[287]\tvalidation_0-logloss:0.21594\n",
      "[288]\tvalidation_0-logloss:0.21587\n",
      "[289]\tvalidation_0-logloss:0.21581\n",
      "[290]\tvalidation_0-logloss:0.21574\n",
      "[291]\tvalidation_0-logloss:0.21568\n",
      "[292]\tvalidation_0-logloss:0.21562\n",
      "[293]\tvalidation_0-logloss:0.21557\n",
      "[294]\tvalidation_0-logloss:0.21551\n",
      "[295]\tvalidation_0-logloss:0.21546\n",
      "[296]\tvalidation_0-logloss:0.21539\n",
      "[297]\tvalidation_0-logloss:0.21534\n",
      "[298]\tvalidation_0-logloss:0.21528\n",
      "[299]\tvalidation_0-logloss:0.21524\n",
      "[300]\tvalidation_0-logloss:0.21519\n",
      "[301]\tvalidation_0-logloss:0.21514\n",
      "[302]\tvalidation_0-logloss:0.21508\n",
      "[303]\tvalidation_0-logloss:0.21504\n",
      "[304]\tvalidation_0-logloss:0.21499\n",
      "[305]\tvalidation_0-logloss:0.21495\n",
      "[306]\tvalidation_0-logloss:0.21490\n",
      "[307]\tvalidation_0-logloss:0.21484\n",
      "[308]\tvalidation_0-logloss:0.21479\n",
      "[309]\tvalidation_0-logloss:0.21474\n",
      "[310]\tvalidation_0-logloss:0.21470\n",
      "[311]\tvalidation_0-logloss:0.21465\n",
      "[312]\tvalidation_0-logloss:0.21462\n",
      "[313]\tvalidation_0-logloss:0.21457\n",
      "[314]\tvalidation_0-logloss:0.21452\n",
      "[315]\tvalidation_0-logloss:0.21448\n",
      "[316]\tvalidation_0-logloss:0.21442\n",
      "[317]\tvalidation_0-logloss:0.21439\n",
      "[318]\tvalidation_0-logloss:0.21434\n",
      "[319]\tvalidation_0-logloss:0.21430\n",
      "[320]\tvalidation_0-logloss:0.21427\n",
      "[321]\tvalidation_0-logloss:0.21422\n",
      "[322]\tvalidation_0-logloss:0.21418\n",
      "[323]\tvalidation_0-logloss:0.21412\n",
      "[324]\tvalidation_0-logloss:0.21409\n",
      "[325]\tvalidation_0-logloss:0.21405\n",
      "[326]\tvalidation_0-logloss:0.21401\n",
      "[327]\tvalidation_0-logloss:0.21397\n",
      "[328]\tvalidation_0-logloss:0.21393\n",
      "[329]\tvalidation_0-logloss:0.21389\n",
      "[330]\tvalidation_0-logloss:0.21383\n",
      "[331]\tvalidation_0-logloss:0.21379\n",
      "[332]\tvalidation_0-logloss:0.21375\n",
      "[333]\tvalidation_0-logloss:0.21370\n",
      "[334]\tvalidation_0-logloss:0.21366\n",
      "[335]\tvalidation_0-logloss:0.21363\n",
      "[336]\tvalidation_0-logloss:0.21357\n",
      "[337]\tvalidation_0-logloss:0.21353\n",
      "[338]\tvalidation_0-logloss:0.21350\n",
      "[339]\tvalidation_0-logloss:0.21347\n",
      "[340]\tvalidation_0-logloss:0.21341\n",
      "[341]\tvalidation_0-logloss:0.21336\n",
      "[342]\tvalidation_0-logloss:0.21332\n",
      "[343]\tvalidation_0-logloss:0.21329\n",
      "[344]\tvalidation_0-logloss:0.21324\n",
      "[345]\tvalidation_0-logloss:0.21321\n",
      "[346]\tvalidation_0-logloss:0.21317\n",
      "[347]\tvalidation_0-logloss:0.21313\n",
      "[348]\tvalidation_0-logloss:0.21310\n",
      "[349]\tvalidation_0-logloss:0.21306\n",
      "[350]\tvalidation_0-logloss:0.21302\n",
      "[351]\tvalidation_0-logloss:0.21300\n",
      "[352]\tvalidation_0-logloss:0.21296\n",
      "[353]\tvalidation_0-logloss:0.21293\n",
      "[354]\tvalidation_0-logloss:0.21289\n",
      "[355]\tvalidation_0-logloss:0.21286\n",
      "[356]\tvalidation_0-logloss:0.21282\n",
      "[357]\tvalidation_0-logloss:0.21279\n",
      "[358]\tvalidation_0-logloss:0.21275\n",
      "[359]\tvalidation_0-logloss:0.21272\n",
      "[360]\tvalidation_0-logloss:0.21269\n",
      "[361]\tvalidation_0-logloss:0.21266\n",
      "[362]\tvalidation_0-logloss:0.21263\n",
      "[363]\tvalidation_0-logloss:0.21261\n",
      "[364]\tvalidation_0-logloss:0.21258\n",
      "[365]\tvalidation_0-logloss:0.21256\n",
      "[366]\tvalidation_0-logloss:0.21253\n",
      "[367]\tvalidation_0-logloss:0.21251\n",
      "[368]\tvalidation_0-logloss:0.21248\n",
      "[369]\tvalidation_0-logloss:0.21246\n",
      "[370]\tvalidation_0-logloss:0.21242\n",
      "[371]\tvalidation_0-logloss:0.21240\n",
      "[372]\tvalidation_0-logloss:0.21239\n",
      "[373]\tvalidation_0-logloss:0.21237\n",
      "[374]\tvalidation_0-logloss:0.21234\n",
      "[375]\tvalidation_0-logloss:0.21233\n",
      "[376]\tvalidation_0-logloss:0.21231\n",
      "[377]\tvalidation_0-logloss:0.21229\n",
      "[378]\tvalidation_0-logloss:0.21227\n",
      "[379]\tvalidation_0-logloss:0.21225\n",
      "[380]\tvalidation_0-logloss:0.21222\n",
      "[381]\tvalidation_0-logloss:0.21220\n",
      "[382]\tvalidation_0-logloss:0.21219\n",
      "[383]\tvalidation_0-logloss:0.21217\n",
      "[384]\tvalidation_0-logloss:0.21215\n",
      "[385]\tvalidation_0-logloss:0.21212\n",
      "[386]\tvalidation_0-logloss:0.21210\n",
      "[387]\tvalidation_0-logloss:0.21207\n",
      "[388]\tvalidation_0-logloss:0.21206\n",
      "[389]\tvalidation_0-logloss:0.21204\n",
      "[390]\tvalidation_0-logloss:0.21201\n",
      "[391]\tvalidation_0-logloss:0.21200\n",
      "[392]\tvalidation_0-logloss:0.21198\n",
      "[393]\tvalidation_0-logloss:0.21197\n",
      "[394]\tvalidation_0-logloss:0.21196\n",
      "[395]\tvalidation_0-logloss:0.21194\n",
      "[396]\tvalidation_0-logloss:0.21193\n",
      "[397]\tvalidation_0-logloss:0.21191\n",
      "[398]\tvalidation_0-logloss:0.21190\n",
      "[399]\tvalidation_0-logloss:0.21188\n",
      "[400]\tvalidation_0-logloss:0.21186\n",
      "[401]\tvalidation_0-logloss:0.21184\n",
      "[402]\tvalidation_0-logloss:0.21182\n",
      "[403]\tvalidation_0-logloss:0.21181\n",
      "[404]\tvalidation_0-logloss:0.21180\n",
      "[405]\tvalidation_0-logloss:0.21179\n",
      "[406]\tvalidation_0-logloss:0.21178\n",
      "[407]\tvalidation_0-logloss:0.21177\n",
      "[408]\tvalidation_0-logloss:0.21176\n",
      "[409]\tvalidation_0-logloss:0.21175\n",
      "[410]\tvalidation_0-logloss:0.21174\n",
      "[411]\tvalidation_0-logloss:0.21174\n",
      "[412]\tvalidation_0-logloss:0.21173\n",
      "[413]\tvalidation_0-logloss:0.21172\n",
      "[414]\tvalidation_0-logloss:0.21171\n",
      "[415]\tvalidation_0-logloss:0.21170\n",
      "[416]\tvalidation_0-logloss:0.21169\n",
      "[417]\tvalidation_0-logloss:0.21168\n",
      "[418]\tvalidation_0-logloss:0.21167\n",
      "[419]\tvalidation_0-logloss:0.21167\n",
      "[420]\tvalidation_0-logloss:0.21166\n",
      "[421]\tvalidation_0-logloss:0.21164\n",
      "[422]\tvalidation_0-logloss:0.21163\n",
      "[423]\tvalidation_0-logloss:0.21162\n",
      "[424]\tvalidation_0-logloss:0.21162\n",
      "[425]\tvalidation_0-logloss:0.21162\n",
      "[426]\tvalidation_0-logloss:0.21161\n",
      "[427]\tvalidation_0-logloss:0.21160\n",
      "[428]\tvalidation_0-logloss:0.21160\n",
      "[429]\tvalidation_0-logloss:0.21159\n",
      "[430]\tvalidation_0-logloss:0.21158\n",
      "[431]\tvalidation_0-logloss:0.21158\n",
      "[432]\tvalidation_0-logloss:0.21158\n",
      "[433]\tvalidation_0-logloss:0.21155\n",
      "[434]\tvalidation_0-logloss:0.21154\n",
      "[435]\tvalidation_0-logloss:0.21153\n",
      "[436]\tvalidation_0-logloss:0.21151\n",
      "[437]\tvalidation_0-logloss:0.21150\n",
      "[438]\tvalidation_0-logloss:0.21150\n",
      "[439]\tvalidation_0-logloss:0.21149\n",
      "[440]\tvalidation_0-logloss:0.21148\n",
      "[441]\tvalidation_0-logloss:0.21147\n",
      "[442]\tvalidation_0-logloss:0.21145\n",
      "[443]\tvalidation_0-logloss:0.21144\n",
      "[444]\tvalidation_0-logloss:0.21143\n",
      "[445]\tvalidation_0-logloss:0.21142\n",
      "[446]\tvalidation_0-logloss:0.21141\n",
      "[447]\tvalidation_0-logloss:0.21141\n",
      "[448]\tvalidation_0-logloss:0.21139\n",
      "[449]\tvalidation_0-logloss:0.21138\n",
      "[450]\tvalidation_0-logloss:0.21136\n",
      "[451]\tvalidation_0-logloss:0.21135\n",
      "[452]\tvalidation_0-logloss:0.21135\n",
      "[453]\tvalidation_0-logloss:0.21135\n",
      "[454]\tvalidation_0-logloss:0.21132\n",
      "[455]\tvalidation_0-logloss:0.21131\n",
      "[456]\tvalidation_0-logloss:0.21129\n",
      "[457]\tvalidation_0-logloss:0.21129\n",
      "[458]\tvalidation_0-logloss:0.21129\n",
      "[459]\tvalidation_0-logloss:0.21127\n",
      "[460]\tvalidation_0-logloss:0.21127\n",
      "[461]\tvalidation_0-logloss:0.21127\n",
      "[462]\tvalidation_0-logloss:0.21127\n",
      "[463]\tvalidation_0-logloss:0.21126\n",
      "[464]\tvalidation_0-logloss:0.21123\n",
      "[465]\tvalidation_0-logloss:0.21124\n",
      "[466]\tvalidation_0-logloss:0.21121\n",
      "[467]\tvalidation_0-logloss:0.21121\n",
      "[468]\tvalidation_0-logloss:0.21120\n",
      "[469]\tvalidation_0-logloss:0.21118\n",
      "[470]\tvalidation_0-logloss:0.21118\n",
      "[471]\tvalidation_0-logloss:0.21117\n",
      "[472]\tvalidation_0-logloss:0.21116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[473]\tvalidation_0-logloss:0.21116\n",
      "[474]\tvalidation_0-logloss:0.21116\n",
      "[475]\tvalidation_0-logloss:0.21113\n",
      "[476]\tvalidation_0-logloss:0.21113\n",
      "[477]\tvalidation_0-logloss:0.21114\n",
      "[478]\tvalidation_0-logloss:0.21114\n",
      "[479]\tvalidation_0-logloss:0.21113\n",
      "[480]\tvalidation_0-logloss:0.21112\n",
      "[481]\tvalidation_0-logloss:0.21112\n",
      "[482]\tvalidation_0-logloss:0.21112\n",
      "[483]\tvalidation_0-logloss:0.21110\n",
      "[484]\tvalidation_0-logloss:0.21108\n",
      "[485]\tvalidation_0-logloss:0.21108\n",
      "[486]\tvalidation_0-logloss:0.21110\n",
      "[487]\tvalidation_0-logloss:0.21109\n",
      "[488]\tvalidation_0-logloss:0.21107\n",
      "[489]\tvalidation_0-logloss:0.21107\n",
      "[490]\tvalidation_0-logloss:0.21106\n",
      "[491]\tvalidation_0-logloss:0.21106\n",
      "[492]\tvalidation_0-logloss:0.21105\n",
      "[493]\tvalidation_0-logloss:0.21106\n",
      "[494]\tvalidation_0-logloss:0.21106\n",
      "[495]\tvalidation_0-logloss:0.21106\n",
      "[496]\tvalidation_0-logloss:0.21105\n",
      "[497]\tvalidation_0-logloss:0.21103\n",
      "[498]\tvalidation_0-logloss:0.21103\n",
      "[499]\tvalidation_0-logloss:0.21103\n",
      "[500]\tvalidation_0-logloss:0.21103\n",
      "[501]\tvalidation_0-logloss:0.21102\n",
      "[502]\tvalidation_0-logloss:0.21102\n",
      "[503]\tvalidation_0-logloss:0.21101\n",
      "[504]\tvalidation_0-logloss:0.21101\n",
      "[505]\tvalidation_0-logloss:0.21102\n",
      "[506]\tvalidation_0-logloss:0.21101\n",
      "[507]\tvalidation_0-logloss:0.21101\n",
      "[508]\tvalidation_0-logloss:0.21098\n",
      "[509]\tvalidation_0-logloss:0.21098\n",
      "[510]\tvalidation_0-logloss:0.21099\n",
      "[511]\tvalidation_0-logloss:0.21098\n",
      "[512]\tvalidation_0-logloss:0.21098\n",
      "[513]\tvalidation_0-logloss:0.21099\n",
      "[514]\tvalidation_0-logloss:0.21098\n",
      "[515]\tvalidation_0-logloss:0.21098\n",
      "[516]\tvalidation_0-logloss:0.21097\n",
      "[517]\tvalidation_0-logloss:0.21097\n",
      "[518]\tvalidation_0-logloss:0.21094\n",
      "[519]\tvalidation_0-logloss:0.21096\n",
      "[520]\tvalidation_0-logloss:0.21096\n",
      "[521]\tvalidation_0-logloss:0.21096\n",
      "[522]\tvalidation_0-logloss:0.21095\n",
      "[523]\tvalidation_0-logloss:0.21096\n",
      "[524]\tvalidation_0-logloss:0.21095\n",
      "[525]\tvalidation_0-logloss:0.21094\n",
      "[526]\tvalidation_0-logloss:0.21094\n",
      "[527]\tvalidation_0-logloss:0.21093\n",
      "[528]\tvalidation_0-logloss:0.21093\n",
      "[529]\tvalidation_0-logloss:0.21093\n",
      "[530]\tvalidation_0-logloss:0.21092\n",
      "[531]\tvalidation_0-logloss:0.21093\n",
      "[532]\tvalidation_0-logloss:0.21093\n",
      "[533]\tvalidation_0-logloss:0.21093\n",
      "[534]\tvalidation_0-logloss:0.21094\n",
      "[535]\tvalidation_0-logloss:0.21092\n",
      "[536]\tvalidation_0-logloss:0.21093\n",
      "[537]\tvalidation_0-logloss:0.21093\n",
      "[538]\tvalidation_0-logloss:0.21093\n",
      "[539]\tvalidation_0-logloss:0.21092\n",
      "[540]\tvalidation_0-logloss:0.21092\n",
      "[541]\tvalidation_0-logloss:0.21092\n",
      "[542]\tvalidation_0-logloss:0.21091\n",
      "[543]\tvalidation_0-logloss:0.21092\n",
      "[544]\tvalidation_0-logloss:0.21092\n",
      "[545]\tvalidation_0-logloss:0.21093\n",
      "[546]\tvalidation_0-logloss:0.21092\n",
      "[547]\tvalidation_0-logloss:0.21091\n",
      "[548]\tvalidation_0-logloss:0.21091\n",
      "[549]\tvalidation_0-logloss:0.21091\n",
      "[550]\tvalidation_0-logloss:0.21089\n",
      "[551]\tvalidation_0-logloss:0.21089\n",
      "[552]\tvalidation_0-logloss:0.21089\n",
      "[553]\tvalidation_0-logloss:0.21089\n",
      "[554]\tvalidation_0-logloss:0.21088\n",
      "[555]\tvalidation_0-logloss:0.21089\n",
      "[556]\tvalidation_0-logloss:0.21088\n",
      "[557]\tvalidation_0-logloss:0.21088\n",
      "[558]\tvalidation_0-logloss:0.21088\n",
      "[559]\tvalidation_0-logloss:0.21087\n",
      "[560]\tvalidation_0-logloss:0.21086\n",
      "[561]\tvalidation_0-logloss:0.21085\n",
      "[562]\tvalidation_0-logloss:0.21086\n",
      "[563]\tvalidation_0-logloss:0.21085\n",
      "[564]\tvalidation_0-logloss:0.21086\n",
      "[565]\tvalidation_0-logloss:0.21085\n",
      "[566]\tvalidation_0-logloss:0.21086\n",
      "[567]\tvalidation_0-logloss:0.21085\n",
      "[568]\tvalidation_0-logloss:0.21085\n",
      "[569]\tvalidation_0-logloss:0.21084\n",
      "[570]\tvalidation_0-logloss:0.21085\n",
      "[571]\tvalidation_0-logloss:0.21085\n",
      "[572]\tvalidation_0-logloss:0.21085\n",
      "[573]\tvalidation_0-logloss:0.21083\n",
      "[574]\tvalidation_0-logloss:0.21083\n",
      "[575]\tvalidation_0-logloss:0.21081\n",
      "[576]\tvalidation_0-logloss:0.21083\n",
      "[577]\tvalidation_0-logloss:0.21083\n",
      "[578]\tvalidation_0-logloss:0.21083\n",
      "[579]\tvalidation_0-logloss:0.21082\n",
      "[580]\tvalidation_0-logloss:0.21081\n",
      "[581]\tvalidation_0-logloss:0.21081\n",
      "[582]\tvalidation_0-logloss:0.21081\n",
      "[583]\tvalidation_0-logloss:0.21081\n",
      "[584]\tvalidation_0-logloss:0.21081\n",
      "[585]\tvalidation_0-logloss:0.21082\n",
      "[586]\tvalidation_0-logloss:0.21082\n",
      "[587]\tvalidation_0-logloss:0.21082\n",
      "[588]\tvalidation_0-logloss:0.21081\n",
      "[589]\tvalidation_0-logloss:0.21081\n",
      "[590]\tvalidation_0-logloss:0.21082\n",
      "[591]\tvalidation_0-logloss:0.21082\n",
      "[592]\tvalidation_0-logloss:0.21082\n",
      "[593]\tvalidation_0-logloss:0.21083\n",
      "[594]\tvalidation_0-logloss:0.21083\n",
      "[595]\tvalidation_0-logloss:0.21083\n",
      "[596]\tvalidation_0-logloss:0.21084\n",
      "[597]\tvalidation_0-logloss:0.21084\n",
      "[598]\tvalidation_0-logloss:0.21086\n",
      "[599]\tvalidation_0-logloss:0.21086\n",
      "[600]\tvalidation_0-logloss:0.21086\n",
      "[601]\tvalidation_0-logloss:0.21087\n",
      "[602]\tvalidation_0-logloss:0.21087\n",
      "[603]\tvalidation_0-logloss:0.21087\n",
      "[604]\tvalidation_0-logloss:0.21088\n",
      "[605]\tvalidation_0-logloss:0.21087\n",
      "[606]\tvalidation_0-logloss:0.21086\n",
      "[607]\tvalidation_0-logloss:0.21086\n",
      "[608]\tvalidation_0-logloss:0.21086\n",
      "[609]\tvalidation_0-logloss:0.21086\n",
      "[610]\tvalidation_0-logloss:0.21086\n",
      "[611]\tvalidation_0-logloss:0.21086\n",
      "[612]\tvalidation_0-logloss:0.21086\n",
      "[613]\tvalidation_0-logloss:0.21086\n",
      "[614]\tvalidation_0-logloss:0.21084\n",
      "[615]\tvalidation_0-logloss:0.21085\n",
      "[616]\tvalidation_0-logloss:0.21085\n",
      "[617]\tvalidation_0-logloss:0.21085\n",
      "[618]\tvalidation_0-logloss:0.21085\n",
      "[619]\tvalidation_0-logloss:0.21084\n",
      "[620]\tvalidation_0-logloss:0.21084\n",
      "[621]\tvalidation_0-logloss:0.21083\n",
      "[622]\tvalidation_0-logloss:0.21083\n",
      "[623]\tvalidation_0-logloss:0.21084\n",
      "[624]\tvalidation_0-logloss:0.21084\n",
      "[625]\tvalidation_0-logloss:0.21085\n",
      "[626]\tvalidation_0-logloss:0.21084\n",
      "[627]\tvalidation_0-logloss:0.21084\n",
      "[628]\tvalidation_0-logloss:0.21082\n",
      "[629]\tvalidation_0-logloss:0.21082\n",
      "[630]\tvalidation_0-logloss:0.21082\n",
      "[631]\tvalidation_0-logloss:0.21083\n",
      "[632]\tvalidation_0-logloss:0.21083\n",
      "[633]\tvalidation_0-logloss:0.21083\n",
      "[634]\tvalidation_0-logloss:0.21082\n",
      "[635]\tvalidation_0-logloss:0.21082\n",
      "[636]\tvalidation_0-logloss:0.21082\n",
      "[637]\tvalidation_0-logloss:0.21082\n",
      "[638]\tvalidation_0-logloss:0.21082\n",
      "[639]\tvalidation_0-logloss:0.21082\n",
      "[640]\tvalidation_0-logloss:0.21082\n",
      "[641]\tvalidation_0-logloss:0.21082\n",
      "[642]\tvalidation_0-logloss:0.21082\n",
      "[643]\tvalidation_0-logloss:0.21081\n",
      "[644]\tvalidation_0-logloss:0.21081\n",
      "[645]\tvalidation_0-logloss:0.21082\n",
      "[646]\tvalidation_0-logloss:0.21082\n",
      "[647]\tvalidation_0-logloss:0.21082\n",
      "[648]\tvalidation_0-logloss:0.21080\n",
      "[649]\tvalidation_0-logloss:0.21080\n",
      "[650]\tvalidation_0-logloss:0.21081\n",
      "[651]\tvalidation_0-logloss:0.21081\n",
      "[652]\tvalidation_0-logloss:0.21082\n",
      "[653]\tvalidation_0-logloss:0.21083\n",
      "[654]\tvalidation_0-logloss:0.21082\n",
      "[655]\tvalidation_0-logloss:0.21081\n",
      "[656]\tvalidation_0-logloss:0.21082\n",
      "[657]\tvalidation_0-logloss:0.21082\n",
      "[658]\tvalidation_0-logloss:0.21083\n",
      "[659]\tvalidation_0-logloss:0.21082\n",
      "[660]\tvalidation_0-logloss:0.21083\n",
      "[661]\tvalidation_0-logloss:0.21084\n",
      "[662]\tvalidation_0-logloss:0.21084\n",
      "[663]\tvalidation_0-logloss:0.21085\n",
      "[664]\tvalidation_0-logloss:0.21084\n",
      "[665]\tvalidation_0-logloss:0.21085\n",
      "[666]\tvalidation_0-logloss:0.21085\n",
      "[667]\tvalidation_0-logloss:0.21085\n",
      "[668]\tvalidation_0-logloss:0.21086\n",
      "[669]\tvalidation_0-logloss:0.21085\n",
      "[670]\tvalidation_0-logloss:0.21084\n",
      "[671]\tvalidation_0-logloss:0.21085\n",
      "[672]\tvalidation_0-logloss:0.21084\n",
      "[673]\tvalidation_0-logloss:0.21084\n",
      "[674]\tvalidation_0-logloss:0.21084\n",
      "[675]\tvalidation_0-logloss:0.21085\n",
      "[676]\tvalidation_0-logloss:0.21084\n",
      "[677]\tvalidation_0-logloss:0.21084\n",
      "[678]\tvalidation_0-logloss:0.21086\n",
      "[679]\tvalidation_0-logloss:0.21086\n",
      "[680]\tvalidation_0-logloss:0.21086\n",
      "[681]\tvalidation_0-logloss:0.21086\n",
      "[682]\tvalidation_0-logloss:0.21087\n",
      "[683]\tvalidation_0-logloss:0.21086\n",
      "[684]\tvalidation_0-logloss:0.21086\n",
      "[685]\tvalidation_0-logloss:0.21087\n",
      "[686]\tvalidation_0-logloss:0.21088\n",
      "[687]\tvalidation_0-logloss:0.21087\n",
      "[688]\tvalidation_0-logloss:0.21088\n",
      "[689]\tvalidation_0-logloss:0.21089\n",
      "[690]\tvalidation_0-logloss:0.21088\n",
      "[691]\tvalidation_0-logloss:0.21088\n",
      "[692]\tvalidation_0-logloss:0.21089\n",
      "[693]\tvalidation_0-logloss:0.21089\n",
      "[694]\tvalidation_0-logloss:0.21089\n",
      "[695]\tvalidation_0-logloss:0.21089\n",
      "[696]\tvalidation_0-logloss:0.21090\n",
      "[697]\tvalidation_0-logloss:0.21090\n",
      "[698]\tvalidation_0-logloss:0.21090\n",
      "[699]\tvalidation_0-logloss:0.21089\n",
      "[700]\tvalidation_0-logloss:0.21090\n",
      "[701]\tvalidation_0-logloss:0.21091\n",
      "[702]\tvalidation_0-logloss:0.21091\n",
      "[703]\tvalidation_0-logloss:0.21091\n",
      "[704]\tvalidation_0-logloss:0.21091\n",
      "[705]\tvalidation_0-logloss:0.21090\n",
      "[706]\tvalidation_0-logloss:0.21090\n",
      "[707]\tvalidation_0-logloss:0.21091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708]\tvalidation_0-logloss:0.21091\n",
      "[709]\tvalidation_0-logloss:0.21091\n",
      "[710]\tvalidation_0-logloss:0.21091\n",
      "[711]\tvalidation_0-logloss:0.21091\n",
      "[712]\tvalidation_0-logloss:0.21091\n",
      "[713]\tvalidation_0-logloss:0.21091\n",
      "[714]\tvalidation_0-logloss:0.21091\n",
      "[715]\tvalidation_0-logloss:0.21092\n",
      "[716]\tvalidation_0-logloss:0.21093\n",
      "[717]\tvalidation_0-logloss:0.21092\n",
      "[718]\tvalidation_0-logloss:0.21093\n",
      "[719]\tvalidation_0-logloss:0.21093\n",
      "[720]\tvalidation_0-logloss:0.21093\n",
      "[721]\tvalidation_0-logloss:0.21094\n",
      "[722]\tvalidation_0-logloss:0.21093\n",
      "[723]\tvalidation_0-logloss:0.21092\n",
      "[724]\tvalidation_0-logloss:0.21092\n",
      "[725]\tvalidation_0-logloss:0.21092\n",
      "[726]\tvalidation_0-logloss:0.21092\n",
      "[727]\tvalidation_0-logloss:0.21093\n",
      "[728]\tvalidation_0-logloss:0.21094\n",
      "[729]\tvalidation_0-logloss:0.21094\n",
      "[730]\tvalidation_0-logloss:0.21094\n",
      "[731]\tvalidation_0-logloss:0.21093\n",
      "[732]\tvalidation_0-logloss:0.21092\n",
      "[733]\tvalidation_0-logloss:0.21094\n",
      "[734]\tvalidation_0-logloss:0.21095\n",
      "[735]\tvalidation_0-logloss:0.21093\n",
      "[736]\tvalidation_0-logloss:0.21094\n",
      "[737]\tvalidation_0-logloss:0.21094\n",
      "[738]\tvalidation_0-logloss:0.21094\n",
      "[739]\tvalidation_0-logloss:0.21095\n",
      "[740]\tvalidation_0-logloss:0.21095\n",
      "[741]\tvalidation_0-logloss:0.21093\n",
      "[742]\tvalidation_0-logloss:0.21094\n",
      "[743]\tvalidation_0-logloss:0.21095\n",
      "[744]\tvalidation_0-logloss:0.21095\n",
      "[745]\tvalidation_0-logloss:0.21095\n",
      "[746]\tvalidation_0-logloss:0.21095\n",
      "[747]\tvalidation_0-logloss:0.21096\n",
      "[748]\tvalidation_0-logloss:0.21096\n",
      "[749]\tvalidation_0-logloss:0.21097\n",
      "[750]\tvalidation_0-logloss:0.21098\n",
      "[751]\tvalidation_0-logloss:0.21097\n",
      "[752]\tvalidation_0-logloss:0.21097\n",
      "[753]\tvalidation_0-logloss:0.21097\n",
      "[754]\tvalidation_0-logloss:0.21097\n",
      "[755]\tvalidation_0-logloss:0.21097\n",
      "[756]\tvalidation_0-logloss:0.21097\n",
      "[757]\tvalidation_0-logloss:0.21098\n",
      "[758]\tvalidation_0-logloss:0.21097\n",
      "[759]\tvalidation_0-logloss:0.21097\n",
      "[760]\tvalidation_0-logloss:0.21097\n",
      "[761]\tvalidation_0-logloss:0.21097\n",
      "[762]\tvalidation_0-logloss:0.21099\n",
      "[763]\tvalidation_0-logloss:0.21098\n",
      "[764]\tvalidation_0-logloss:0.21099\n",
      "[765]\tvalidation_0-logloss:0.21099\n",
      "[766]\tvalidation_0-logloss:0.21099\n",
      "[767]\tvalidation_0-logloss:0.21099\n",
      "[768]\tvalidation_0-logloss:0.21099\n",
      "[769]\tvalidation_0-logloss:0.21099\n",
      "[770]\tvalidation_0-logloss:0.21100\n",
      "[771]\tvalidation_0-logloss:0.21099\n",
      "[772]\tvalidation_0-logloss:0.21099\n",
      "[773]\tvalidation_0-logloss:0.21099\n",
      "[774]\tvalidation_0-logloss:0.21099\n",
      "[775]\tvalidation_0-logloss:0.21100\n",
      "[776]\tvalidation_0-logloss:0.21100\n",
      "[777]\tvalidation_0-logloss:0.21099\n",
      "[778]\tvalidation_0-logloss:0.21099\n",
      "[779]\tvalidation_0-logloss:0.21100\n",
      "[780]\tvalidation_0-logloss:0.21100\n",
      "[781]\tvalidation_0-logloss:0.21100\n",
      "[782]\tvalidation_0-logloss:0.21101\n",
      "[783]\tvalidation_0-logloss:0.21101\n",
      "[784]\tvalidation_0-logloss:0.21101\n",
      "[785]\tvalidation_0-logloss:0.21101\n",
      "[786]\tvalidation_0-logloss:0.21101\n",
      "[787]\tvalidation_0-logloss:0.21101\n",
      "[788]\tvalidation_0-logloss:0.21100\n",
      "[789]\tvalidation_0-logloss:0.21100\n",
      "[790]\tvalidation_0-logloss:0.21100\n",
      "[791]\tvalidation_0-logloss:0.21100\n",
      "[792]\tvalidation_0-logloss:0.21100\n",
      "[793]\tvalidation_0-logloss:0.21101\n",
      "[794]\tvalidation_0-logloss:0.21102\n",
      "[795]\tvalidation_0-logloss:0.21102\n",
      "[796]\tvalidation_0-logloss:0.21101\n",
      "[797]\tvalidation_0-logloss:0.21102\n",
      "[798]\tvalidation_0-logloss:0.21102\n",
      "[799]\tvalidation_0-logloss:0.21102\n",
      "[800]\tvalidation_0-logloss:0.21102\n",
      "[801]\tvalidation_0-logloss:0.21101\n",
      "[802]\tvalidation_0-logloss:0.21101\n",
      "[803]\tvalidation_0-logloss:0.21101\n",
      "[804]\tvalidation_0-logloss:0.21100\n",
      "[805]\tvalidation_0-logloss:0.21101\n",
      "[806]\tvalidation_0-logloss:0.21101\n",
      "[807]\tvalidation_0-logloss:0.21101\n",
      "[808]\tvalidation_0-logloss:0.21102\n",
      "[809]\tvalidation_0-logloss:0.21101\n",
      "[810]\tvalidation_0-logloss:0.21103\n",
      "[811]\tvalidation_0-logloss:0.21104\n",
      "[812]\tvalidation_0-logloss:0.21103\n",
      "[813]\tvalidation_0-logloss:0.21102\n",
      "[814]\tvalidation_0-logloss:0.21102\n",
      "[815]\tvalidation_0-logloss:0.21101\n",
      "[816]\tvalidation_0-logloss:0.21101\n",
      "[817]\tvalidation_0-logloss:0.21101\n",
      "[818]\tvalidation_0-logloss:0.21103\n",
      "[819]\tvalidation_0-logloss:0.21103\n",
      "[820]\tvalidation_0-logloss:0.21104\n",
      "[821]\tvalidation_0-logloss:0.21105\n",
      "[822]\tvalidation_0-logloss:0.21105\n",
      "[823]\tvalidation_0-logloss:0.21108\n",
      "[824]\tvalidation_0-logloss:0.21108\n",
      "[825]\tvalidation_0-logloss:0.21108\n",
      "[826]\tvalidation_0-logloss:0.21107\n",
      "[827]\tvalidation_0-logloss:0.21107\n",
      "[828]\tvalidation_0-logloss:0.21107\n",
      "[829]\tvalidation_0-logloss:0.21107\n",
      "[830]\tvalidation_0-logloss:0.21107\n",
      "[831]\tvalidation_0-logloss:0.21106\n",
      "[832]\tvalidation_0-logloss:0.21106\n",
      "[833]\tvalidation_0-logloss:0.21108\n",
      "[834]\tvalidation_0-logloss:0.21108\n",
      "[835]\tvalidation_0-logloss:0.21107\n",
      "[836]\tvalidation_0-logloss:0.21107\n",
      "[837]\tvalidation_0-logloss:0.21108\n",
      "[838]\tvalidation_0-logloss:0.21108\n",
      "[839]\tvalidation_0-logloss:0.21108\n",
      "[840]\tvalidation_0-logloss:0.21108\n",
      "[841]\tvalidation_0-logloss:0.21107\n",
      "[842]\tvalidation_0-logloss:0.21109\n",
      "[843]\tvalidation_0-logloss:0.21110\n",
      "[844]\tvalidation_0-logloss:0.21111\n",
      "[845]\tvalidation_0-logloss:0.21111\n",
      "[846]\tvalidation_0-logloss:0.21112\n",
      "[847]\tvalidation_0-logloss:0.21113\n",
      "[848]\tvalidation_0-logloss:0.21112\n",
      "[849]\tvalidation_0-logloss:0.21112\n",
      "[850]\tvalidation_0-logloss:0.21112\n",
      "[851]\tvalidation_0-logloss:0.21112\n",
      "[852]\tvalidation_0-logloss:0.21113\n",
      "[853]\tvalidation_0-logloss:0.21113\n",
      "[854]\tvalidation_0-logloss:0.21113\n",
      "[855]\tvalidation_0-logloss:0.21113\n",
      "[856]\tvalidation_0-logloss:0.21115\n",
      "[857]\tvalidation_0-logloss:0.21115\n",
      "[858]\tvalidation_0-logloss:0.21115\n",
      "[859]\tvalidation_0-logloss:0.21115\n",
      "[860]\tvalidation_0-logloss:0.21114\n",
      "[861]\tvalidation_0-logloss:0.21113\n",
      "[862]\tvalidation_0-logloss:0.21113\n",
      "[863]\tvalidation_0-logloss:0.21114\n",
      "[864]\tvalidation_0-logloss:0.21113\n",
      "[865]\tvalidation_0-logloss:0.21113\n",
      "[866]\tvalidation_0-logloss:0.21114\n",
      "[867]\tvalidation_0-logloss:0.21113\n",
      "[868]\tvalidation_0-logloss:0.21114\n",
      "[869]\tvalidation_0-logloss:0.21114\n",
      "[870]\tvalidation_0-logloss:0.21114\n",
      "[871]\tvalidation_0-logloss:0.21113\n",
      "[872]\tvalidation_0-logloss:0.21113\n",
      "[873]\tvalidation_0-logloss:0.21113\n",
      "[874]\tvalidation_0-logloss:0.21113\n",
      "[875]\tvalidation_0-logloss:0.21116\n",
      "[876]\tvalidation_0-logloss:0.21114\n",
      "[877]\tvalidation_0-logloss:0.21114\n",
      "[878]\tvalidation_0-logloss:0.21114\n",
      "[879]\tvalidation_0-logloss:0.21114\n",
      "[880]\tvalidation_0-logloss:0.21114\n",
      "[881]\tvalidation_0-logloss:0.21114\n",
      "[882]\tvalidation_0-logloss:0.21114\n",
      "[883]\tvalidation_0-logloss:0.21115\n",
      "[884]\tvalidation_0-logloss:0.21115\n",
      "[885]\tvalidation_0-logloss:0.21116\n",
      "[886]\tvalidation_0-logloss:0.21116\n",
      "[887]\tvalidation_0-logloss:0.21116\n",
      "[888]\tvalidation_0-logloss:0.21116\n",
      "[889]\tvalidation_0-logloss:0.21117\n",
      "[890]\tvalidation_0-logloss:0.21118\n",
      "[891]\tvalidation_0-logloss:0.21119\n",
      "[892]\tvalidation_0-logloss:0.21119\n",
      "[893]\tvalidation_0-logloss:0.21119\n",
      "[894]\tvalidation_0-logloss:0.21120\n",
      "[895]\tvalidation_0-logloss:0.21122\n",
      "[896]\tvalidation_0-logloss:0.21121\n",
      "[897]\tvalidation_0-logloss:0.21122\n",
      "[898]\tvalidation_0-logloss:0.21121\n",
      "[899]\tvalidation_0-logloss:0.21121\n",
      "[900]\tvalidation_0-logloss:0.21121\n",
      "[901]\tvalidation_0-logloss:0.21123\n",
      "[902]\tvalidation_0-logloss:0.21122\n",
      "[903]\tvalidation_0-logloss:0.21124\n",
      "[904]\tvalidation_0-logloss:0.21124\n",
      "[905]\tvalidation_0-logloss:0.21125\n",
      "[906]\tvalidation_0-logloss:0.21125\n",
      "[907]\tvalidation_0-logloss:0.21125\n",
      "[908]\tvalidation_0-logloss:0.21127\n",
      "[909]\tvalidation_0-logloss:0.21127\n",
      "[910]\tvalidation_0-logloss:0.21127\n",
      "[911]\tvalidation_0-logloss:0.21128\n",
      "[912]\tvalidation_0-logloss:0.21128\n",
      "[913]\tvalidation_0-logloss:0.21128\n",
      "[914]\tvalidation_0-logloss:0.21128\n",
      "[915]\tvalidation_0-logloss:0.21129\n",
      "[916]\tvalidation_0-logloss:0.21129\n",
      "[917]\tvalidation_0-logloss:0.21130\n",
      "[918]\tvalidation_0-logloss:0.21130\n",
      "[919]\tvalidation_0-logloss:0.21130\n",
      "[920]\tvalidation_0-logloss:0.21130\n",
      "[921]\tvalidation_0-logloss:0.21130\n",
      "[922]\tvalidation_0-logloss:0.21130\n",
      "[923]\tvalidation_0-logloss:0.21130\n",
      "[924]\tvalidation_0-logloss:0.21130\n",
      "[925]\tvalidation_0-logloss:0.21131\n",
      "[926]\tvalidation_0-logloss:0.21131\n",
      "[927]\tvalidation_0-logloss:0.21131\n",
      "[928]\tvalidation_0-logloss:0.21131\n",
      "[929]\tvalidation_0-logloss:0.21131\n",
      "[930]\tvalidation_0-logloss:0.21132\n",
      "[931]\tvalidation_0-logloss:0.21131\n",
      "[932]\tvalidation_0-logloss:0.21132\n",
      "[933]\tvalidation_0-logloss:0.21132\n",
      "[934]\tvalidation_0-logloss:0.21133\n",
      "[935]\tvalidation_0-logloss:0.21134\n",
      "[936]\tvalidation_0-logloss:0.21134\n",
      "[937]\tvalidation_0-logloss:0.21134\n",
      "[938]\tvalidation_0-logloss:0.21134\n",
      "[939]\tvalidation_0-logloss:0.21134\n",
      "[940]\tvalidation_0-logloss:0.21134\n",
      "[941]\tvalidation_0-logloss:0.21134\n",
      "[942]\tvalidation_0-logloss:0.21134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[943]\tvalidation_0-logloss:0.21134\n",
      "[944]\tvalidation_0-logloss:0.21134\n",
      "[945]\tvalidation_0-logloss:0.21134\n",
      "[946]\tvalidation_0-logloss:0.21135\n",
      "[947]\tvalidation_0-logloss:0.21135\n",
      "[948]\tvalidation_0-logloss:0.21135\n",
      "[949]\tvalidation_0-logloss:0.21136\n",
      "[950]\tvalidation_0-logloss:0.21137\n",
      "[951]\tvalidation_0-logloss:0.21137\n",
      "[952]\tvalidation_0-logloss:0.21137\n",
      "[953]\tvalidation_0-logloss:0.21137\n",
      "[954]\tvalidation_0-logloss:0.21137\n",
      "[955]\tvalidation_0-logloss:0.21137\n",
      "[956]\tvalidation_0-logloss:0.21140\n",
      "[957]\tvalidation_0-logloss:0.21140\n",
      "[958]\tvalidation_0-logloss:0.21141\n",
      "[959]\tvalidation_0-logloss:0.21141\n",
      "[960]\tvalidation_0-logloss:0.21141\n",
      "[961]\tvalidation_0-logloss:0.21142\n",
      "[962]\tvalidation_0-logloss:0.21142\n",
      "[963]\tvalidation_0-logloss:0.21143\n",
      "[964]\tvalidation_0-logloss:0.21142\n",
      "[965]\tvalidation_0-logloss:0.21142\n",
      "[966]\tvalidation_0-logloss:0.21144\n",
      "[967]\tvalidation_0-logloss:0.21144\n",
      "[968]\tvalidation_0-logloss:0.21145\n",
      "[969]\tvalidation_0-logloss:0.21145\n",
      "[970]\tvalidation_0-logloss:0.21146\n",
      "[971]\tvalidation_0-logloss:0.21146\n",
      "[972]\tvalidation_0-logloss:0.21146\n",
      "[973]\tvalidation_0-logloss:0.21146\n",
      "[974]\tvalidation_0-logloss:0.21147\n",
      "[975]\tvalidation_0-logloss:0.21146\n",
      "[976]\tvalidation_0-logloss:0.21147\n",
      "[977]\tvalidation_0-logloss:0.21147\n",
      "[978]\tvalidation_0-logloss:0.21146\n",
      "[979]\tvalidation_0-logloss:0.21146\n",
      "[980]\tvalidation_0-logloss:0.21147\n",
      "[981]\tvalidation_0-logloss:0.21147\n",
      "[982]\tvalidation_0-logloss:0.21147\n",
      "[983]\tvalidation_0-logloss:0.21146\n",
      "[984]\tvalidation_0-logloss:0.21146\n",
      "[985]\tvalidation_0-logloss:0.21147\n",
      "[986]\tvalidation_0-logloss:0.21147\n",
      "[987]\tvalidation_0-logloss:0.21148\n",
      "[988]\tvalidation_0-logloss:0.21149\n",
      "[989]\tvalidation_0-logloss:0.21150\n",
      "[990]\tvalidation_0-logloss:0.21149\n",
      "[991]\tvalidation_0-logloss:0.21149\n",
      "[992]\tvalidation_0-logloss:0.21149\n",
      "[993]\tvalidation_0-logloss:0.21150\n",
      "[994]\tvalidation_0-logloss:0.21150\n",
      "[995]\tvalidation_0-logloss:0.21151\n",
      "[996]\tvalidation_0-logloss:0.21152\n",
      "[997]\tvalidation_0-logloss:0.21153\n",
      "[998]\tvalidation_0-logloss:0.21153\n",
      "[999]\tvalidation_0-logloss:0.21154\n",
      "Train_noSMOTE\n",
      "Accuracy: 0.10723626852659111\n",
      "Confusion Matrix:\n",
      " [[    0 17408]\n",
      " [    0  2091]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     17408\n",
      "         1.0       0.11      1.00      0.19      2091\n",
      "\n",
      "    accuracy                           0.11     19499\n",
      "   macro avg       0.05      0.50      0.10     19499\n",
      "weighted avg       0.01      0.11      0.02     19499\n",
      "\n",
      "VAL_noSMOTE\n",
      "Accuracy: 0.11107692307692307\n",
      "Confusion Matrix:\n",
      " [[   0 5778]\n",
      " [   0  722]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      5778\n",
      "         1.0       0.11      1.00      0.20       722\n",
      "\n",
      "    accuracy                           0.11      6500\n",
      "   macro avg       0.06      0.50      0.10      6500\n",
      "weighted avg       0.01      0.11      0.02      6500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_noSMOTE = XGBClassifier(\n",
    "    reg_alpha=0.1,  # L1 regularization term (alpha)\n",
    "    reg_lambda=1    # L2 regularization term (lambda)\n",
    ")\n",
    "xgb_clf_noSMOTE = XGBClassifier(n_estimators=1000, learning_rate=0.01)\n",
    "xgb_clf_noSMOTE.fit(X_train_scaled_noSMOTE, y_train_noSMOTE, eval_set=[(X_val_scaled_noSMOTE, y_val_noSMOTE)])\n",
    "\n",
    "y_train_pred_noSMOTE = xgb_clf.predict(X_train_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train_noSMOTE, y_train_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train_noSMOTE, y_train_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train_noSMOTE, y_train_pred_noSMOTE))\n",
    "\n",
    "y_val_pred_noSMOTE = xgb_clf.predict(X_val_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_noSMOTE, y_val_pred_noSMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[17385     0]\n",
      " [    0  8719]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     17385\n",
      "         1.0       1.00      1.00      1.00      8719\n",
      "\n",
      "    accuracy                           1.00     26104\n",
      "   macro avg       1.00      1.00      1.00     26104\n",
      "weighted avg       1.00      1.00      1.00     26104\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9333409952878979\n",
      "Confusion Matrix:\n",
      " [[5630  135]\n",
      " [ 445 2491]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95      5765\n",
      "         1.0       0.95      0.85      0.90      2936\n",
      "\n",
      "    accuracy                           0.93      8701\n",
      "   macro avg       0.94      0.91      0.92      8701\n",
      "weighted avg       0.93      0.93      0.93      8701\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.6980004596644449\n",
      "Confusion Matrix:\n",
      " [[5365  490]\n",
      " [2138  709]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.92      0.80      5855\n",
      "         1.0       0.59      0.25      0.35      2847\n",
      "\n",
      "    accuracy                           0.70      8702\n",
      "   macro avg       0.65      0.58      0.58      8702\n",
      "weighted avg       0.67      0.70      0.66      8702\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9160047128577401\n",
      "Confusion Matrix:\n",
      " [[23030   491]\n",
      " [ 1719  1071]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95     23521\n",
      "         1.0       0.69      0.38      0.49      2790\n",
      "\n",
      "    accuracy                           0.92     26311\n",
      "   macro avg       0.81      0.68      0.72     26311\n",
      "weighted avg       0.90      0.92      0.91     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier  # for regression tasks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instantiate the Random Forest Regressor\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred =  rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = rf_model.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 0.6950275819797732\n",
      "Confusion Matrix:\n",
      " [[15922  1463]\n",
      " [ 6498  2221]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.92      0.80     17385\n",
      "         1.0       0.60      0.25      0.36      8719\n",
      "\n",
      "    accuracy                           0.70     26104\n",
      "   macro avg       0.66      0.59      0.58     26104\n",
      "weighted avg       0.67      0.70      0.65     26104\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.6914147799103552\n",
      "Confusion Matrix:\n",
      " [[5259  506]\n",
      " [2179  757]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.91      0.80      5765\n",
      "         1.0       0.60      0.26      0.36      2936\n",
      "\n",
      "    accuracy                           0.69      8701\n",
      "   macro avg       0.65      0.59      0.58      8701\n",
      "weighted avg       0.67      0.69      0.65      8701\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouse_family_person_id\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure the test data has the same features\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     26\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred =  model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# To predict on the test data\n",
    "X_test = test_data.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test = test_data['diabetes']\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "y_pred_2017 = model.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL\n",
      "Accuracy: 0.8442707734743133\n",
      "Confusion Matrix:\n",
      " [[5154  611]\n",
      " [ 744 2192]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88      5765\n",
      "         1.0       0.78      0.75      0.76      2936\n",
      "\n",
      "    accuracy                           0.84      8701\n",
      "   macro avg       0.83      0.82      0.82      8701\n",
      "weighted avg       0.84      0.84      0.84      8701\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.8516433003907148\n",
      "Confusion Matrix:\n",
      " [[5269  586]\n",
      " [ 705 2142]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89      5855\n",
      "         1.0       0.79      0.75      0.77      2847\n",
      "\n",
      "    accuracy                           0.85      8702\n",
      "   macro avg       0.83      0.83      0.83      8702\n",
      "weighted avg       0.85      0.85      0.85      8702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "val_data = pd.read_csv('val_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Inspect the data\n",
    "#print(train_data.head())\n",
    "#print(val_data.head())\n",
    "#print(test_data.head())\n",
    "\n",
    "# Assuming the target variable is named 'diabetes' and is binary (0 or 1)\n",
    "X_train = train_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_train = train_data['diabetes']\n",
    "\n",
    "X_val = val_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_val = val_data['diabetes']\n",
    "\n",
    "# Optional: Check for missing values\n",
    "#print(X_train.isnull().sum())\n",
    "#print(X_val.isnull().sum())\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# To predict on the test data\n",
    "X_test = test_data.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test = test_data['diabetes']\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL_noSMOTE\n",
      "Accuracy: 0.9107692307692308\n",
      "Confusion Matrix:\n",
      " [[5653  125]\n",
      " [ 455  267]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95      5778\n",
      "         1.0       0.68      0.37      0.48       722\n",
      "\n",
      "    accuracy                           0.91      6500\n",
      "   macro avg       0.80      0.67      0.72      6500\n",
      "weighted avg       0.90      0.91      0.90      6500\n",
      "\n",
      "TEST_noSMOTE\n",
      "Accuracy: 0.912\n",
      "Confusion Matrix:\n",
      " [[5778   41]\n",
      " [ 531  150]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95      5819\n",
      "         1.0       0.79      0.22      0.34       681\n",
      "\n",
      "    accuracy                           0.91      6500\n",
      "   macro avg       0.85      0.61      0.65      6500\n",
      "weighted avg       0.90      0.91      0.89      6500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "model_noSMOTE = LogisticRegression()\n",
    "model_noSMOTE.fit(X_train_scaled_noSMOTE, y_train_noSMOTE)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred_noSMOTE = model_noSMOTE.predict(X_val_scaled_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "\n",
    "# To predict on the test data\n",
    "X_test_noSMOTE = test_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test_noSMOTE = test_data_noSMOTE['diabetes']\n",
    "X_test_scaled_noSMOTE = scaler.transform(X_test_noSMOTE)\n",
    "\n",
    "y_test_pred_noSMOTE = model_noSMOTE.predict(X_test_scaled_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_noSMOTE, y_test_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_noSMOTE, y_test_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_noSMOTE, y_test_pred_noSMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "Accuracy: 0.8786819201094599\n",
      "Confusion Matrix:\n",
      " [[21183  2338]\n",
      " [  854  1936]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ny_test_pred_2017 = model_noSMOTE.predict(X_test_scaled_2017)\\n\\n# Evaluate the model\\nprint(\"TEST_noSMOTE\")\\nprint(\"Accuracy:\", accuracy_score(y_test_2017, y_test_pred_2017))\\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_test_pred_2017))\\nprint(\"Classification Report:\\n\", classification_report(y_test_2017, y_test_pred_2017))'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To predict on the test data\n",
    "model = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "X_test_2017 = imputed_2017.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test_2017 = imputed_2017['diabetes']\n",
    "X_test_scaled_2017 = scaler.transform(X_test_2017)\n",
    "\n",
    "y_test_pred_2017 = model.predict(X_test_2017)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_test_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_test_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_test_pred_2017))\n",
    "'''\n",
    "y_test_pred_2017 = model_noSMOTE.predict(X_test_scaled_2017)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_test_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_test_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_test_pred_2017))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.87      0.90     23521\n",
      "         1.0       0.31      0.50      0.38      2790\n",
      "\n",
      "    accuracy                           0.83     26311\n",
      "   macro avg       0.62      0.68      0.64     26311\n",
      "weighted avg       0.87      0.83      0.84     26311\n",
      "\n",
      "C: 0.01, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.54      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.70      0.79      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 0.1, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 1, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 10, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 100, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 1000, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of trying different values for C\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    log_reg_l2 = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    log_reg_l2.fit(X_train, y_train)\n",
    "    y_pred_l2 = log_reg_l2.predict(X_test_2017)\n",
    "    #print(f\"C: {c}, Performance:\\n\", classification_report(y_val, y_pred_l2))\n",
    "    y_test_pred_2017 = log_reg_l2.predict(X_test_2017)\n",
    "    print(f\"C: {c}, Performance:\\n\", classification_report(y_test_2017, y_test_pred_2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "report_2017 = classification_report(y_test_2017, y_test_pred_2017)\n",
    "precision_0_2017 = report['0.0']['precision']\n",
    "recall_0_2017 = report['0.0']['recall']\n",
    "precision_1 = report['1.0']['precision']\n",
    "recall_1 = report['1.0']['recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Define null hypothesis values (expected precision under H0)\n",
    "p0_0 = precision_0  # Expected precision for class 0.0 (you can adjust this)\n",
    "p0_1 = precision_1  # Expected precision for class 1.0 (you can adjust this)\n",
    "\n",
    "# Get the number of samples for the precision calculations\n",
    "n = len(y_pred_2017)  # Total number of samples\n",
    "\n",
    "# 1. Evaluate the performance for class 0.0\n",
    "observed_precision_0 = precision_0_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 0.0\n",
    "Z_0 = (observed_precision_0 - p0_0) / np.sqrt((p0_0 * (1 - p0_0)) / n)\n",
    "\n",
    "# Calculate p-value for class 0.0\n",
    "p_value_0 = 2 * (1 - stats.norm.cdf(np.abs(Z_0)))\n",
    "\n",
    "# Evaluate the hypothesis for class 0.0\n",
    "print(f\"Class 0.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_0:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_0:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_0:.4f}\")\n",
    "print(f\"P-Value: {p_value_0:.4f}\")\n",
    "\n",
    "if p_value_0 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 0.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 0.0.\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity\n",
    "\n",
    "# 2. Evaluate the performance for class 1.0\n",
    "observed_precision_1 = precision_1_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 1.0\n",
    "Z_1 = (observed_precision_1 - p0_1) / np.sqrt((p0_1 * (1 - p0_1)) / n)\n",
    "\n",
    "# Calculate p-value for class 1.0\n",
    "p_value_1 = 2 * (1 - stats.norm.cdf(np.abs(Z_1)))\n",
    "\n",
    "# Evaluate the hypothesis for class 1.0\n",
    "print(f\"Class 1.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_1:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_1:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_1:.4f}\")\n",
    "print(f\"P-Value: {p_value_1:.4f}\")\n",
    "\n",
    "if p_value_1 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 1.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 1.0.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill in this document to complete the diabetes prediction exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
