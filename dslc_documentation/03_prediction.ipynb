{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting diabetes status using NHANES\n",
    "\n",
    "[DSLC stages]: Analysis\n",
    "\n",
    "\n",
    "\n",
    "The following code sets up the libraries and creates cleaned and pre-processed training, validation and test data that we will use in this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37633, 35)\n",
      "(4705, 35)\n",
      "(4704, 35)\n",
      "(26311, 35)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from functions.load_diabetes_data import load_diabetes_data\n",
    "# load the diabetes data\n",
    "\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "val_data = pd.read_csv('val_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "imputed_2017 = pd.read_csv('imputed_2017.csv')\n",
    "\n",
    "train_data_noSMOTE = pd.read_csv('train_data_noSMOTE.csv')\n",
    "val_data_noSMOTE = pd.read_csv('val_data_noSMOTE.csv')\n",
    "test_data_noSMOTE = pd.read_csv('test_data_noSMOTE.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)\n",
    "print(imputed_2017.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noSMOTE = train_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_train_noSMOTE = train_data_noSMOTE['diabetes']\n",
    "\n",
    "X_val_noSMOTE = val_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_val_noSMOTE = val_data_noSMOTE['diabetes']\n",
    "\n",
    "X_test_noSMOTE = test_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_test_noSMOTE = test_data_noSMOTE['diabetes']\n",
    "\n",
    "# Optional: Check for missing values\n",
    "#print(X_train.isnull().sum())\n",
    "#print(X_val.isnull().sum())\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_noSMOTE = scaler.fit_transform(X_train_noSMOTE)\n",
    "X_val_scaled_noSMOTE = scaler.transform(X_val_noSMOTE)\n",
    "X_test_scaled_noSMOTE = scaler.transform(X_test_noSMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_family_person_id</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>age</th>\n",
       "      <th>smoker</th>\n",
       "      <th>sex</th>\n",
       "      <th>coronary_heart_disease</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>height</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_condition</th>\n",
       "      <th>cancer</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>doctor_recommend_exercise</th>\n",
       "      <th>moderate_physical_activity</th>\n",
       "      <th>vigorous_physical_activity</th>\n",
       "      <th>alcohol_past_year</th>\n",
       "      <th>high_blood_pressure_prescription</th>\n",
       "      <th>medicated</th>\n",
       "      <th>prediabetes</th>\n",
       "      <th>insulin</th>\n",
       "      <th>region_Midwest</th>\n",
       "      <th>region_Northwest</th>\n",
       "      <th>region_South</th>\n",
       "      <th>marital_status_Divorced</th>\n",
       "      <th>marital_status_Living with partner</th>\n",
       "      <th>marital_status_Married</th>\n",
       "      <th>marital_status_Never_married</th>\n",
       "      <th>marital_status_Separated</th>\n",
       "      <th>marital_status_Widdowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277060102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.2</td>\n",
       "      <td>2307.4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389730101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2624.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468630101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256810101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2829.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300550101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>652990101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3055.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>429240101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>628450101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>392830101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>139790101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3026.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_family_person_id  diabetes   age  smoker  sex  \\\n",
       "0             277060102.0       1.0  60.0     0.0  1.0   \n",
       "1             389730101.0       1.0  48.0     1.0  0.0   \n",
       "2             468630101.0       0.0  66.0     0.0  1.0   \n",
       "3             256810101.0       0.0  48.0     1.0  1.0   \n",
       "4             300550101.0       0.0  39.0     1.0  0.0   \n",
       "5             652990101.0       0.0  61.0     1.0  0.0   \n",
       "6             429240101.0       0.0  69.0     1.0  1.0   \n",
       "7             628450101.0       1.0  80.0     0.0  0.0   \n",
       "8             392830101.0       0.0  60.0     0.0  0.0   \n",
       "9             139790101.0       0.0  30.0     0.0  0.0   \n",
       "\n",
       "   coronary_heart_disease  weight     bmi  height  hypertension  \\\n",
       "0                     0.0   136.2  2307.4    66.0           1.0   \n",
       "1                     0.0   188.0  2624.0    71.0           0.0   \n",
       "2                     0.0   140.0  2261.0    66.0           0.0   \n",
       "3                     0.0   165.0  2829.0    64.0           0.0   \n",
       "4                     0.0   148.0  2316.0    67.0           0.0   \n",
       "5                     0.0   195.0  3055.0    67.0           1.0   \n",
       "6                     0.0   140.0  2330.0    65.0           1.0   \n",
       "7                     1.0   212.0  2583.0    76.0           1.0   \n",
       "8                     0.0   214.0  2903.0    72.0           1.0   \n",
       "9                     0.0   242.0  3026.0    75.0           0.0   \n",
       "\n",
       "   heart_condition  cancer  family_history_diabetes  \\\n",
       "0              0.0     0.0                      1.0   \n",
       "1              0.0     0.0                      1.0   \n",
       "2              0.0     0.0                      0.0   \n",
       "3              0.0     0.0                      0.0   \n",
       "4              0.0     0.0                      1.0   \n",
       "5              1.0     0.0                      0.0   \n",
       "6              0.0     0.0                      1.0   \n",
       "7              0.0     0.0                      1.0   \n",
       "8              0.0     0.0                      0.0   \n",
       "9              0.0     0.0                      0.0   \n",
       "\n",
       "   doctor_recommend_exercise  moderate_physical_activity  \\\n",
       "0                        1.0                         5.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         7.0   \n",
       "3                        0.0                         5.0   \n",
       "4                        0.0                         0.0   \n",
       "5                        1.0                         7.0   \n",
       "6                        0.0                         0.0   \n",
       "7                        1.0                         7.0   \n",
       "8                        1.0                         3.0   \n",
       "9                        1.0                         7.0   \n",
       "\n",
       "   vigorous_physical_activity  alcohol_past_year  \\\n",
       "0                         0.0                2.0   \n",
       "1                         0.0                2.0   \n",
       "2                         0.0                0.0   \n",
       "3                         2.0                0.0   \n",
       "4                         0.0                5.0   \n",
       "5                         0.0                2.0   \n",
       "6                         0.0                0.0   \n",
       "7                         0.0                0.0   \n",
       "8                         0.0                1.0   \n",
       "9                         3.0                3.0   \n",
       "\n",
       "   high_blood_pressure_prescription  medicated  prediabetes  insulin  \\\n",
       "0                               1.0        1.0          0.0      0.0   \n",
       "1                               1.0        1.0          0.0      0.0   \n",
       "2                               1.0        1.0          0.0      1.0   \n",
       "3                               1.0        0.0          1.0      0.0   \n",
       "4                               1.0        0.0          0.0      0.0   \n",
       "5                               1.0        0.0          1.0      0.0   \n",
       "6                               1.0        0.0          1.0      0.0   \n",
       "7                               1.0        1.0          0.0      0.0   \n",
       "8                               1.0        0.0          0.0      0.0   \n",
       "9                               1.0        1.0          0.0      0.0   \n",
       "\n",
       "   region_Midwest  region_Northwest  region_South  marital_status_Divorced  \\\n",
       "0             0.0               0.0           0.0                      0.0   \n",
       "1             0.0               1.0           0.0                      0.0   \n",
       "2             1.0               0.0           0.0                      1.0   \n",
       "3             0.0               0.0           1.0                      1.0   \n",
       "4             1.0               0.0           0.0                      0.0   \n",
       "5             0.0               0.0           1.0                      0.0   \n",
       "6             0.0               0.0           1.0                      1.0   \n",
       "7             1.0               0.0           0.0                      0.0   \n",
       "8             0.0               0.0           0.0                      0.0   \n",
       "9             0.0               1.0           0.0                      0.0   \n",
       "\n",
       "   marital_status_Living with partner  marital_status_Married  \\\n",
       "0                                 0.0                     1.0   \n",
       "1                                 0.0                     1.0   \n",
       "2                                 0.0                     0.0   \n",
       "3                                 0.0                     0.0   \n",
       "4                                 0.0                     1.0   \n",
       "5                                 0.0                     1.0   \n",
       "6                                 0.0                     0.0   \n",
       "7                                 0.0                     0.0   \n",
       "8                                 0.0                     1.0   \n",
       "9                                 0.0                     1.0   \n",
       "\n",
       "   marital_status_Never_married  marital_status_Separated  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "5                           0.0                       0.0   \n",
       "6                           0.0                       0.0   \n",
       "7                           0.0                       0.0   \n",
       "8                           0.0                       0.0   \n",
       "9                           0.0                       0.0   \n",
       "\n",
       "   marital_status_Widdowed  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "5                      0.0  \n",
       "6                      0.0  \n",
       "7                      1.0  \n",
       "8                      0.0  \n",
       "9                      0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Feature          VIF\n",
      "0                                const  1733.114392\n",
      "1               house_family_person_id     1.009493\n",
      "2                                  age     2.017734\n",
      "3                               smoker     1.070471\n",
      "4                                  sex     2.042067\n",
      "5               coronary_heart_disease     1.202662\n",
      "6                               weight     3.332867\n",
      "7                                  bmi     2.734942\n",
      "8                               height     2.788603\n",
      "9                         hypertension     1.587684\n",
      "10                     heart_condition     1.141521\n",
      "11                              cancer     1.106445\n",
      "12             family_history_diabetes     1.115867\n",
      "13           doctor_recommend_exercise     1.229994\n",
      "14          moderate_physical_activity     1.103417\n",
      "15          vigorous_physical_activity     1.155337\n",
      "16                   alcohol_past_year     1.007329\n",
      "17    high_blood_pressure_prescription     1.061586\n",
      "18                           medicated     1.104050\n",
      "19                         prediabetes     1.068789\n",
      "20                             insulin     1.092406\n",
      "21                              stroke     1.084119\n",
      "22                         cholesterol     1.009881\n",
      "23                     told_reduce_fat     1.025586\n",
      "24                 weight_loss_program     1.025824\n",
      "25                         hours_sleep     1.005266\n",
      "26                      region_Midwest     2.123039\n",
      "27                    region_Northwest     1.907677\n",
      "28                        region_South     1.881859\n",
      "29             marital_status_Divorced    75.039325\n",
      "30  marital_status_Living with partner    26.758011\n",
      "31              marital_status_Married   130.228658\n",
      "32        marital_status_Never_married    81.063712\n",
      "33            marital_status_Separated    15.997434\n",
      "34             marital_status_Widdowed    57.809216\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Sample dataset\n",
    "# df = pd.read_csv('your_data.csv')  # Load your dataset\n",
    "\n",
    "# Prepare your features (X)\n",
    "# Assuming 'diabetes' is your target variable and all other columns are features\n",
    "X = train_data.drop(columns=['diabetes'])\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = X.columns\n",
    "vif_data['VIF'] = [sm.OLS(X[column], X.loc[:, X.columns != column]).fit().rsquared for column in X.columns]\n",
    "\n",
    "# Calculate the VIF\n",
    "vif_data['VIF'] = 1 / (1 - vif_data['VIF'])\n",
    "\n",
    "# Display the VIF results\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Feature          VIF\n",
      "0                                const  1733.114392\n",
      "29             marital_status_Divorced    75.039325\n",
      "30  marital_status_Living with partner    26.758011\n",
      "31              marital_status_Married   130.228658\n",
      "32        marital_status_Never_married    81.063712\n",
      "33            marital_status_Separated    15.997434\n",
      "34             marital_status_Widdowed    57.809216\n",
      "['const' 'marital_status_Divorced' 'marital_status_Living with partner'\n",
      " 'marital_status_Married' 'marital_status_Never_married'\n",
      " 'marital_status_Separated' 'marital_status_Widdowed']\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with mean above the threshold\n",
    "threshold = 10\n",
    "columns_to_drop = vif_data[vif_data[\"VIF\"] > threshold]\n",
    "print(columns_to_drop)\n",
    "#print(vif_data[vif_data[\"VIF\"] > threshold])\n",
    "columns_to_drop = columns_to_drop[\"Feature\"]\n",
    "print(columns_to_drop.values)\n",
    "\n",
    "# Drop those columns\n",
    "train_data = train_data.drop(columns=columns_to_drop.values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2017 = imputed_2017.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test_2017 = imputed_2017['diabetes']\n",
    "X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "\n",
    "# To predict on the test data\n",
    "X_test = test_data.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test = test_data['diabetes']\n",
    "X_test = X_test.drop(columns=columns_to_drop.values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37633, 27)\n",
      "(4704, 27)\n",
      "(4705, 27)\n",
      "(26311, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(X_test_2017.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>smoker</th>\n",
       "      <th>sex</th>\n",
       "      <th>coronary_heart_disease</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>height</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_condition</th>\n",
       "      <th>cancer</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>doctor_recommend_exercise</th>\n",
       "      <th>moderate_physical_activity</th>\n",
       "      <th>vigorous_physical_activity</th>\n",
       "      <th>alcohol_past_year</th>\n",
       "      <th>high_blood_pressure_prescription</th>\n",
       "      <th>medicated</th>\n",
       "      <th>prediabetes</th>\n",
       "      <th>insulin</th>\n",
       "      <th>stroke</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>region_Midwest</th>\n",
       "      <th>region_Northwest</th>\n",
       "      <th>region_South</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>4313.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3227.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  smoker  sex  coronary_heart_disease  weight     bmi  height  \\\n",
       "0  65.0     1.0  1.0                     0.0   155.0  2930.0    61.0   \n",
       "1  19.0     0.0  0.0                     0.0   180.0  2309.0    74.0   \n",
       "2  45.0     1.0  0.0                     0.0   240.0  3544.0    69.0   \n",
       "3  67.0     1.0  1.0                     0.0   236.0  4313.0    62.0   \n",
       "4  40.0     1.0  0.0                     0.0   182.0  3227.0    63.0   \n",
       "\n",
       "   hypertension  heart_condition  cancer  family_history_diabetes  \\\n",
       "0           1.0              0.0     0.0                      0.0   \n",
       "1           0.0              0.0     0.0                      0.0   \n",
       "2           0.0              0.0     0.0                      0.0   \n",
       "3           0.0              0.0     0.0                      0.0   \n",
       "4           0.0              0.0     0.0                      0.0   \n",
       "\n",
       "   doctor_recommend_exercise  moderate_physical_activity  \\\n",
       "0                        1.0                         0.0   \n",
       "1                        1.0                         3.8   \n",
       "2                        0.0                         2.0   \n",
       "3                        1.0                         7.0   \n",
       "4                        0.0                         3.0   \n",
       "\n",
       "   vigorous_physical_activity  alcohol_past_year  \\\n",
       "0                         7.0                1.0   \n",
       "1                         3.0                2.0   \n",
       "2                         0.0                2.0   \n",
       "3                         3.0               12.0   \n",
       "4                         0.0                3.0   \n",
       "\n",
       "   high_blood_pressure_prescription  medicated  prediabetes  insulin  stroke  \\\n",
       "0                               1.0        0.0          0.0      0.0     0.0   \n",
       "1                               1.0        0.0          0.0      0.0     0.0   \n",
       "2                               1.0        0.0          0.0      0.0     0.0   \n",
       "3                               1.0        0.0          1.0      0.0     0.0   \n",
       "4                               1.0        0.0          0.0      0.0     0.0   \n",
       "\n",
       "   cholesterol  region_Midwest  region_Northwest  region_South  \n",
       "0          0.0             1.0               0.0           0.0  \n",
       "1          0.0             0.0               1.0           0.0  \n",
       "2          0.0             0.0               1.0           0.0  \n",
       "3          0.0             0.0               1.0           0.0  \n",
       "4          0.0             1.0               0.0           0.0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 0.9536842664682592\n",
      "Confusion Matrix:\n",
      " [[18341   484]\n",
      " [ 1259 17549]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95     18825\n",
      "         1.0       0.97      0.93      0.95     18808\n",
      "\n",
      "    accuracy                           0.95     37633\n",
      "   macro avg       0.95      0.95      0.95     37633\n",
      "weighted avg       0.95      0.95      0.95     37633\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9530187074829932\n",
      "Confusion Matrix:\n",
      " [[2257   66]\n",
      " [ 155 2226]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95      2323\n",
      "         1.0       0.97      0.93      0.95      2381\n",
      "\n",
      "    accuracy                           0.95      4704\n",
      "   macro avg       0.95      0.95      0.95      4704\n",
      "weighted avg       0.95      0.95      0.95      4704\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.9534537725823592\n",
      "Confusion Matrix:\n",
      " [[2316   57]\n",
      " [ 162 2170]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95      2373\n",
      "         1.0       0.97      0.93      0.95      2332\n",
      "\n",
      "    accuracy                           0.95      4705\n",
      "   macro avg       0.95      0.95      0.95      4705\n",
      "weighted avg       0.95      0.95      0.95      4705\n",
      "\n",
      "\n",
      "[[22119  1402]\n",
      " [  978  1812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     23521\n",
      "         1.0       0.56      0.65      0.60      2790\n",
      "\n",
      "    accuracy                           0.91     26311\n",
      "   macro avg       0.76      0.79      0.78     26311\n",
      "weighted avg       0.92      0.91      0.91     26311\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9205655429288131\n",
      "Confusion Matrix:\n",
      " [[22914   607]\n",
      " [ 1483  1307]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96     23521\n",
      "         1.0       0.68      0.47      0.56      2790\n",
      "\n",
      "    accuracy                           0.92     26311\n",
      "   macro avg       0.81      0.72      0.76     26311\n",
      "weighted avg       0.91      0.92      0.91     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming the target variable is named 'diabetes' and is binary (0 or 1)\n",
    "X_train = train_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_train = train_data['diabetes']\n",
    "\n",
    "X_val = val_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "y_val = val_data['diabetes']\n",
    "# Drop those columns\n",
    "X_val = X_val.drop(columns=columns_to_drop.values[1:])\n",
    "\n",
    "# Optional: Check for missing values\n",
    "#print(X_train.isnull().sum())\n",
    "#print(X_val.isnull().sum())\n",
    "\n",
    "# Scale the features\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=2000, \n",
    "    learning_rate=0.005, \n",
    "    eval_metric='aucpr', \n",
    "    max_depth=5,\n",
    "    reg_alpha=5,  # Increased L1 regularization\n",
    "    reg_lambda=15  # Increased L2 regularization\n",
    ")\n",
    "#xgb_clf = XGBClassifier(n_estimators=1000, learning_rate=0.01, eval_metric='aucpr', max_depth=3)\n",
    "xgb_clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "y_train_pred = xgb_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = xgb_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "#X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "y_pred_2017 = xgb_clf.predict(X_test_2017)\n",
    "y_pred_probs = xgb_clf.predict_proba(X_test_2017)[:, 1]\n",
    "threshold = 0.3\n",
    "y_pred_custom = (y_pred_probs >= threshold).astype(int)  # Apply custom threshold\n",
    "print()\n",
    "print(confusion_matrix(y_test_2017, y_pred_custom))\n",
    "print(classification_report(y_test_2017, y_pred_custom))\n",
    "\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_2017, y_pred_probs)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Precision / Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize best score\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "# Test different thresholds\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_probs >= thresh).astype(int)\n",
    "    f1 = f1_score(y_test_2017, y_pred_thresh)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"Best F1-Score: {best_f1} at Threshold: {best_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18808, number of negative: 18825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6881\n",
      "[LightGBM] [Info] Number of data points in the train set: 37633, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499774 -> initscore=-0.000903\n",
      "[LightGBM] [Info] Start training from score -0.000903\n",
      "Train\n",
      "Accuracy: 0.962745462758749\n",
      "Confusion Matrix:\n",
      " [[18519   306]\n",
      " [ 1096 17712]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     18825\n",
      "         1.0       0.98      0.94      0.96     18808\n",
      "\n",
      "    accuracy                           0.96     37633\n",
      "   macro avg       0.96      0.96      0.96     37633\n",
      "weighted avg       0.96      0.96      0.96     37633\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9570578231292517\n",
      "Confusion Matrix:\n",
      " [[2268   55]\n",
      " [ 147 2234]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      2323\n",
      "         1.0       0.98      0.94      0.96      2381\n",
      "\n",
      "    accuracy                           0.96      4704\n",
      "   macro avg       0.96      0.96      0.96      4704\n",
      "weighted avg       0.96      0.96      0.96      4704\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.9555791710945802\n",
      "Confusion Matrix:\n",
      " [[2322   51]\n",
      " [ 158 2174]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      2373\n",
      "         1.0       0.98      0.93      0.95      2332\n",
      "\n",
      "    accuracy                           0.96      4705\n",
      "   macro avg       0.96      0.96      0.96      4705\n",
      "weighted avg       0.96      0.96      0.96      4705\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9313215005130934\n",
      "Confusion Matrix:\n",
      " [[23109   412]\n",
      " [ 1395  1395]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     23521\n",
      "         1.0       0.77      0.50      0.61      2790\n",
      "\n",
      "    accuracy                           0.93     26311\n",
      "   macro avg       0.86      0.74      0.78     26311\n",
      "weighted avg       0.92      0.93      0.92     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Initialize the LightGBM classifier\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    n_estimators=2000,      # Number of trees (boosting rounds)\n",
    "    learning_rate=0.005,     # Learning rate\n",
    "    is_unbalance=True,      # Set to True if your data is imbalanced\n",
    "    num_leaves=31,          # Maximum number of leaves in one tree\n",
    "    max_depth=-1            # Unlimited tree depth\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = lgb_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = lgb_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "#X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "y_pred_2017 = lgb_clf.predict(X_test_2017)\n",
    "\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6754036\ttotal: 172ms\tremaining: 2m 52s\n",
      "1:\tlearn: 0.6588822\ttotal: 200ms\tremaining: 1m 40s\n",
      "2:\tlearn: 0.6431563\ttotal: 229ms\tremaining: 1m 15s\n",
      "3:\tlearn: 0.6284297\ttotal: 257ms\tremaining: 1m 3s\n",
      "4:\tlearn: 0.6163656\ttotal: 288ms\tremaining: 57.4s\n",
      "5:\tlearn: 0.6022816\ttotal: 317ms\tremaining: 52.4s\n",
      "6:\tlearn: 0.5890555\ttotal: 343ms\tremaining: 48.7s\n",
      "7:\tlearn: 0.5749990\ttotal: 372ms\tremaining: 46.2s\n",
      "8:\tlearn: 0.5615757\ttotal: 405ms\tremaining: 44.6s\n",
      "9:\tlearn: 0.5494727\ttotal: 435ms\tremaining: 43s\n",
      "10:\tlearn: 0.5380519\ttotal: 464ms\tremaining: 41.8s\n",
      "11:\tlearn: 0.5260613\ttotal: 508ms\tremaining: 41.8s\n",
      "12:\tlearn: 0.5148901\ttotal: 546ms\tremaining: 41.5s\n",
      "13:\tlearn: 0.5043925\ttotal: 577ms\tremaining: 40.7s\n",
      "14:\tlearn: 0.4938695\ttotal: 602ms\tremaining: 39.5s\n",
      "15:\tlearn: 0.4831472\ttotal: 629ms\tremaining: 38.7s\n",
      "16:\tlearn: 0.4731360\ttotal: 657ms\tremaining: 38s\n",
      "17:\tlearn: 0.4639362\ttotal: 694ms\tremaining: 37.9s\n",
      "18:\tlearn: 0.4543139\ttotal: 720ms\tremaining: 37.2s\n",
      "19:\tlearn: 0.4456222\ttotal: 744ms\tremaining: 36.5s\n",
      "20:\tlearn: 0.4371506\ttotal: 772ms\tremaining: 36s\n",
      "21:\tlearn: 0.4291043\ttotal: 796ms\tremaining: 35.4s\n",
      "22:\tlearn: 0.4209494\ttotal: 832ms\tremaining: 35.3s\n",
      "23:\tlearn: 0.4129352\ttotal: 880ms\tremaining: 35.8s\n",
      "24:\tlearn: 0.4052809\ttotal: 907ms\tremaining: 35.4s\n",
      "25:\tlearn: 0.3977981\ttotal: 932ms\tremaining: 34.9s\n",
      "26:\tlearn: 0.3913070\ttotal: 957ms\tremaining: 34.5s\n",
      "27:\tlearn: 0.3851112\ttotal: 985ms\tremaining: 34.2s\n",
      "28:\tlearn: 0.3784455\ttotal: 1.01s\tremaining: 33.9s\n",
      "29:\tlearn: 0.3725565\ttotal: 1.04s\tremaining: 33.7s\n",
      "30:\tlearn: 0.3672103\ttotal: 1.07s\tremaining: 33.4s\n",
      "31:\tlearn: 0.3612805\ttotal: 1.09s\tremaining: 33.1s\n",
      "32:\tlearn: 0.3557554\ttotal: 1.12s\tremaining: 32.9s\n",
      "33:\tlearn: 0.3508497\ttotal: 1.15s\tremaining: 32.6s\n",
      "34:\tlearn: 0.3457651\ttotal: 1.17s\tremaining: 32.3s\n",
      "35:\tlearn: 0.3407645\ttotal: 1.21s\tremaining: 32.3s\n",
      "36:\tlearn: 0.3358344\ttotal: 1.24s\tremaining: 32.2s\n",
      "37:\tlearn: 0.3313929\ttotal: 1.27s\tremaining: 32.1s\n",
      "38:\tlearn: 0.3271556\ttotal: 1.3s\tremaining: 31.9s\n",
      "39:\tlearn: 0.3235806\ttotal: 1.33s\tremaining: 31.9s\n",
      "40:\tlearn: 0.3193467\ttotal: 1.37s\tremaining: 32.1s\n",
      "41:\tlearn: 0.3154046\ttotal: 1.4s\tremaining: 31.9s\n",
      "42:\tlearn: 0.3115356\ttotal: 1.43s\tremaining: 31.8s\n",
      "43:\tlearn: 0.3083648\ttotal: 1.46s\tremaining: 31.8s\n",
      "44:\tlearn: 0.3046552\ttotal: 1.5s\tremaining: 31.9s\n",
      "45:\tlearn: 0.3006264\ttotal: 1.55s\tremaining: 32.3s\n",
      "46:\tlearn: 0.2965339\ttotal: 1.59s\tremaining: 32.2s\n",
      "47:\tlearn: 0.2937904\ttotal: 1.62s\tremaining: 32.1s\n",
      "48:\tlearn: 0.2905696\ttotal: 1.65s\tremaining: 32s\n",
      "49:\tlearn: 0.2870842\ttotal: 1.68s\tremaining: 31.9s\n",
      "50:\tlearn: 0.2835407\ttotal: 1.71s\tremaining: 31.8s\n",
      "51:\tlearn: 0.2799816\ttotal: 1.74s\tremaining: 31.7s\n",
      "52:\tlearn: 0.2778090\ttotal: 1.76s\tremaining: 31.5s\n",
      "53:\tlearn: 0.2748904\ttotal: 1.79s\tremaining: 31.4s\n",
      "54:\tlearn: 0.2722766\ttotal: 1.82s\tremaining: 31.3s\n",
      "55:\tlearn: 0.2700320\ttotal: 1.86s\tremaining: 31.3s\n",
      "56:\tlearn: 0.2679706\ttotal: 1.89s\tremaining: 31.2s\n",
      "57:\tlearn: 0.2660132\ttotal: 1.92s\tremaining: 31.1s\n",
      "58:\tlearn: 0.2628586\ttotal: 1.95s\tremaining: 31.1s\n",
      "59:\tlearn: 0.2597388\ttotal: 2s\tremaining: 31.3s\n",
      "60:\tlearn: 0.2565869\ttotal: 2.04s\tremaining: 31.5s\n",
      "61:\tlearn: 0.2541394\ttotal: 2.08s\tremaining: 31.5s\n",
      "62:\tlearn: 0.2514574\ttotal: 2.12s\tremaining: 31.5s\n",
      "63:\tlearn: 0.2496086\ttotal: 2.14s\tremaining: 31.4s\n",
      "64:\tlearn: 0.2469764\ttotal: 2.17s\tremaining: 31.2s\n",
      "65:\tlearn: 0.2442407\ttotal: 2.22s\tremaining: 31.4s\n",
      "66:\tlearn: 0.2418749\ttotal: 2.26s\tremaining: 31.5s\n",
      "67:\tlearn: 0.2401497\ttotal: 2.29s\tremaining: 31.4s\n",
      "68:\tlearn: 0.2376624\ttotal: 2.31s\tremaining: 31.2s\n",
      "69:\tlearn: 0.2364951\ttotal: 2.34s\tremaining: 31.1s\n",
      "70:\tlearn: 0.2346617\ttotal: 2.37s\tremaining: 30.9s\n",
      "71:\tlearn: 0.2325602\ttotal: 2.39s\tremaining: 30.9s\n",
      "72:\tlearn: 0.2309389\ttotal: 2.43s\tremaining: 30.8s\n",
      "73:\tlearn: 0.2290414\ttotal: 2.49s\tremaining: 31.2s\n",
      "74:\tlearn: 0.2279468\ttotal: 2.53s\tremaining: 31.2s\n",
      "75:\tlearn: 0.2263286\ttotal: 2.57s\tremaining: 31.2s\n",
      "76:\tlearn: 0.2249024\ttotal: 2.6s\tremaining: 31.2s\n",
      "77:\tlearn: 0.2234190\ttotal: 2.63s\tremaining: 31.1s\n",
      "78:\tlearn: 0.2223561\ttotal: 2.67s\tremaining: 31.1s\n",
      "79:\tlearn: 0.2206019\ttotal: 2.69s\tremaining: 31s\n",
      "80:\tlearn: 0.2188647\ttotal: 2.72s\tremaining: 30.9s\n",
      "81:\tlearn: 0.2178828\ttotal: 2.75s\tremaining: 30.8s\n",
      "82:\tlearn: 0.2164961\ttotal: 2.77s\tremaining: 30.6s\n",
      "83:\tlearn: 0.2154685\ttotal: 2.8s\tremaining: 30.5s\n",
      "84:\tlearn: 0.2137380\ttotal: 2.82s\tremaining: 30.4s\n",
      "85:\tlearn: 0.2124519\ttotal: 2.84s\tremaining: 30.2s\n",
      "86:\tlearn: 0.2113737\ttotal: 2.87s\tremaining: 30.1s\n",
      "87:\tlearn: 0.2099686\ttotal: 2.9s\tremaining: 30s\n",
      "88:\tlearn: 0.2084576\ttotal: 2.92s\tremaining: 29.9s\n",
      "89:\tlearn: 0.2073668\ttotal: 2.95s\tremaining: 29.8s\n",
      "90:\tlearn: 0.2063077\ttotal: 2.97s\tremaining: 29.7s\n",
      "91:\tlearn: 0.2050773\ttotal: 2.99s\tremaining: 29.5s\n",
      "92:\tlearn: 0.2040320\ttotal: 3.01s\tremaining: 29.4s\n",
      "93:\tlearn: 0.2030666\ttotal: 3.04s\tremaining: 29.3s\n",
      "94:\tlearn: 0.2024417\ttotal: 3.06s\tremaining: 29.2s\n",
      "95:\tlearn: 0.2010742\ttotal: 3.08s\tremaining: 29.1s\n",
      "96:\tlearn: 0.1995122\ttotal: 3.11s\tremaining: 29s\n",
      "97:\tlearn: 0.1984428\ttotal: 3.14s\tremaining: 28.9s\n",
      "98:\tlearn: 0.1969121\ttotal: 3.17s\tremaining: 28.8s\n",
      "99:\tlearn: 0.1955169\ttotal: 3.2s\tremaining: 28.8s\n",
      "100:\tlearn: 0.1946254\ttotal: 3.23s\tremaining: 28.7s\n",
      "101:\tlearn: 0.1936864\ttotal: 3.25s\tremaining: 28.6s\n",
      "102:\tlearn: 0.1926046\ttotal: 3.28s\tremaining: 28.6s\n",
      "103:\tlearn: 0.1913902\ttotal: 3.3s\tremaining: 28.4s\n",
      "104:\tlearn: 0.1905184\ttotal: 3.33s\tremaining: 28.4s\n",
      "105:\tlearn: 0.1897347\ttotal: 3.37s\tremaining: 28.4s\n",
      "106:\tlearn: 0.1888769\ttotal: 3.39s\tremaining: 28.3s\n",
      "107:\tlearn: 0.1878673\ttotal: 3.42s\tremaining: 28.3s\n",
      "108:\tlearn: 0.1873550\ttotal: 3.45s\tremaining: 28.2s\n",
      "109:\tlearn: 0.1866275\ttotal: 3.48s\tremaining: 28.2s\n",
      "110:\tlearn: 0.1853850\ttotal: 3.51s\tremaining: 28.1s\n",
      "111:\tlearn: 0.1847907\ttotal: 3.54s\tremaining: 28.1s\n",
      "112:\tlearn: 0.1836022\ttotal: 3.57s\tremaining: 28s\n",
      "113:\tlearn: 0.1827665\ttotal: 3.6s\tremaining: 28s\n",
      "114:\tlearn: 0.1817736\ttotal: 3.63s\tremaining: 27.9s\n",
      "115:\tlearn: 0.1811659\ttotal: 3.65s\tremaining: 27.8s\n",
      "116:\tlearn: 0.1805394\ttotal: 3.67s\tremaining: 27.7s\n",
      "117:\tlearn: 0.1800619\ttotal: 3.7s\tremaining: 27.6s\n",
      "118:\tlearn: 0.1794077\ttotal: 3.72s\tremaining: 27.5s\n",
      "119:\tlearn: 0.1785810\ttotal: 3.75s\tremaining: 27.5s\n",
      "120:\tlearn: 0.1777429\ttotal: 3.77s\tremaining: 27.4s\n",
      "121:\tlearn: 0.1772303\ttotal: 3.8s\tremaining: 27.4s\n",
      "122:\tlearn: 0.1764854\ttotal: 3.82s\tremaining: 27.3s\n",
      "123:\tlearn: 0.1757761\ttotal: 3.85s\tremaining: 27.2s\n",
      "124:\tlearn: 0.1751894\ttotal: 3.87s\tremaining: 27.1s\n",
      "125:\tlearn: 0.1748039\ttotal: 3.9s\tremaining: 27s\n",
      "126:\tlearn: 0.1740428\ttotal: 3.93s\tremaining: 27s\n",
      "127:\tlearn: 0.1734621\ttotal: 3.95s\tremaining: 26.9s\n",
      "128:\tlearn: 0.1725962\ttotal: 3.97s\tremaining: 26.8s\n",
      "129:\tlearn: 0.1720991\ttotal: 3.99s\tremaining: 26.7s\n",
      "130:\tlearn: 0.1715156\ttotal: 4.02s\tremaining: 26.7s\n",
      "131:\tlearn: 0.1707312\ttotal: 4.04s\tremaining: 26.6s\n",
      "132:\tlearn: 0.1701905\ttotal: 4.06s\tremaining: 26.5s\n",
      "133:\tlearn: 0.1697221\ttotal: 4.08s\tremaining: 26.4s\n",
      "134:\tlearn: 0.1693501\ttotal: 4.11s\tremaining: 26.3s\n",
      "135:\tlearn: 0.1687689\ttotal: 4.13s\tremaining: 26.2s\n",
      "136:\tlearn: 0.1682269\ttotal: 4.15s\tremaining: 26.1s\n",
      "137:\tlearn: 0.1677411\ttotal: 4.17s\tremaining: 26.1s\n",
      "138:\tlearn: 0.1673275\ttotal: 4.19s\tremaining: 26s\n",
      "139:\tlearn: 0.1667700\ttotal: 4.21s\tremaining: 25.9s\n",
      "140:\tlearn: 0.1664566\ttotal: 4.24s\tremaining: 25.8s\n",
      "141:\tlearn: 0.1655903\ttotal: 4.26s\tremaining: 25.7s\n",
      "142:\tlearn: 0.1649894\ttotal: 4.28s\tremaining: 25.7s\n",
      "143:\tlearn: 0.1641789\ttotal: 4.3s\tremaining: 25.6s\n",
      "144:\tlearn: 0.1635660\ttotal: 4.33s\tremaining: 25.5s\n",
      "145:\tlearn: 0.1632677\ttotal: 4.36s\tremaining: 25.5s\n",
      "146:\tlearn: 0.1628457\ttotal: 4.39s\tremaining: 25.5s\n",
      "147:\tlearn: 0.1625779\ttotal: 4.41s\tremaining: 25.4s\n",
      "148:\tlearn: 0.1623017\ttotal: 4.45s\tremaining: 25.4s\n",
      "149:\tlearn: 0.1619130\ttotal: 4.5s\tremaining: 25.5s\n",
      "150:\tlearn: 0.1614504\ttotal: 4.53s\tremaining: 25.5s\n",
      "151:\tlearn: 0.1608898\ttotal: 4.56s\tremaining: 25.4s\n",
      "152:\tlearn: 0.1604272\ttotal: 4.59s\tremaining: 25.4s\n",
      "153:\tlearn: 0.1599650\ttotal: 4.62s\tremaining: 25.4s\n",
      "154:\tlearn: 0.1593738\ttotal: 4.66s\tremaining: 25.4s\n",
      "155:\tlearn: 0.1588805\ttotal: 4.68s\tremaining: 25.3s\n",
      "156:\tlearn: 0.1585942\ttotal: 4.71s\tremaining: 25.3s\n",
      "157:\tlearn: 0.1582488\ttotal: 4.74s\tremaining: 25.3s\n",
      "158:\tlearn: 0.1577597\ttotal: 4.77s\tremaining: 25.2s\n",
      "159:\tlearn: 0.1575031\ttotal: 4.79s\tremaining: 25.2s\n",
      "160:\tlearn: 0.1570771\ttotal: 4.82s\tremaining: 25.1s\n",
      "161:\tlearn: 0.1569010\ttotal: 4.85s\tremaining: 25.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162:\tlearn: 0.1566992\ttotal: 4.88s\tremaining: 25.1s\n",
      "163:\tlearn: 0.1564547\ttotal: 4.91s\tremaining: 25.1s\n",
      "164:\tlearn: 0.1562255\ttotal: 4.94s\tremaining: 25s\n",
      "165:\tlearn: 0.1556544\ttotal: 4.97s\tremaining: 25s\n",
      "166:\tlearn: 0.1554670\ttotal: 5s\tremaining: 25s\n",
      "167:\tlearn: 0.1550976\ttotal: 5.04s\tremaining: 25s\n",
      "168:\tlearn: 0.1547003\ttotal: 5.07s\tremaining: 24.9s\n",
      "169:\tlearn: 0.1543819\ttotal: 5.11s\tremaining: 25s\n",
      "170:\tlearn: 0.1540333\ttotal: 5.15s\tremaining: 25s\n",
      "171:\tlearn: 0.1537322\ttotal: 5.17s\tremaining: 24.9s\n",
      "172:\tlearn: 0.1532986\ttotal: 5.21s\tremaining: 24.9s\n",
      "173:\tlearn: 0.1529720\ttotal: 5.24s\tremaining: 24.9s\n",
      "174:\tlearn: 0.1526644\ttotal: 5.27s\tremaining: 24.8s\n",
      "175:\tlearn: 0.1524949\ttotal: 5.29s\tremaining: 24.8s\n",
      "176:\tlearn: 0.1522939\ttotal: 5.32s\tremaining: 24.8s\n",
      "177:\tlearn: 0.1518307\ttotal: 5.35s\tremaining: 24.7s\n",
      "178:\tlearn: 0.1516355\ttotal: 5.39s\tremaining: 24.7s\n",
      "179:\tlearn: 0.1512148\ttotal: 5.42s\tremaining: 24.7s\n",
      "180:\tlearn: 0.1509001\ttotal: 5.45s\tremaining: 24.7s\n",
      "181:\tlearn: 0.1507332\ttotal: 5.49s\tremaining: 24.7s\n",
      "182:\tlearn: 0.1504498\ttotal: 5.51s\tremaining: 24.6s\n",
      "183:\tlearn: 0.1502817\ttotal: 5.55s\tremaining: 24.6s\n",
      "184:\tlearn: 0.1498099\ttotal: 5.58s\tremaining: 24.6s\n",
      "185:\tlearn: 0.1496509\ttotal: 5.61s\tremaining: 24.5s\n",
      "186:\tlearn: 0.1494321\ttotal: 5.63s\tremaining: 24.5s\n",
      "187:\tlearn: 0.1492785\ttotal: 5.67s\tremaining: 24.5s\n",
      "188:\tlearn: 0.1491035\ttotal: 5.7s\tremaining: 24.5s\n",
      "189:\tlearn: 0.1488529\ttotal: 5.73s\tremaining: 24.4s\n",
      "190:\tlearn: 0.1487253\ttotal: 5.75s\tremaining: 24.4s\n",
      "191:\tlearn: 0.1484341\ttotal: 5.79s\tremaining: 24.3s\n",
      "192:\tlearn: 0.1482872\ttotal: 5.82s\tremaining: 24.3s\n",
      "193:\tlearn: 0.1480258\ttotal: 5.85s\tremaining: 24.3s\n",
      "194:\tlearn: 0.1476629\ttotal: 5.87s\tremaining: 24.2s\n",
      "195:\tlearn: 0.1475088\ttotal: 5.9s\tremaining: 24.2s\n",
      "196:\tlearn: 0.1471720\ttotal: 5.92s\tremaining: 24.1s\n",
      "197:\tlearn: 0.1470065\ttotal: 5.95s\tremaining: 24.1s\n",
      "198:\tlearn: 0.1468886\ttotal: 5.97s\tremaining: 24s\n",
      "199:\tlearn: 0.1466149\ttotal: 6s\tremaining: 24s\n",
      "200:\tlearn: 0.1461893\ttotal: 6.02s\tremaining: 23.9s\n",
      "201:\tlearn: 0.1460158\ttotal: 6.05s\tremaining: 23.9s\n",
      "202:\tlearn: 0.1457167\ttotal: 6.08s\tremaining: 23.9s\n",
      "203:\tlearn: 0.1454088\ttotal: 6.1s\tremaining: 23.8s\n",
      "204:\tlearn: 0.1452927\ttotal: 6.13s\tremaining: 23.8s\n",
      "205:\tlearn: 0.1450465\ttotal: 6.16s\tremaining: 23.8s\n",
      "206:\tlearn: 0.1449223\ttotal: 6.19s\tremaining: 23.7s\n",
      "207:\tlearn: 0.1445490\ttotal: 6.21s\tremaining: 23.7s\n",
      "208:\tlearn: 0.1443852\ttotal: 6.25s\tremaining: 23.6s\n",
      "209:\tlearn: 0.1440922\ttotal: 6.28s\tremaining: 23.6s\n",
      "210:\tlearn: 0.1439861\ttotal: 6.3s\tremaining: 23.6s\n",
      "211:\tlearn: 0.1438637\ttotal: 6.33s\tremaining: 23.5s\n",
      "212:\tlearn: 0.1437408\ttotal: 6.35s\tremaining: 23.5s\n",
      "213:\tlearn: 0.1434060\ttotal: 6.38s\tremaining: 23.4s\n",
      "214:\tlearn: 0.1433026\ttotal: 6.4s\tremaining: 23.4s\n",
      "215:\tlearn: 0.1431136\ttotal: 6.43s\tremaining: 23.3s\n",
      "216:\tlearn: 0.1428116\ttotal: 6.46s\tremaining: 23.3s\n",
      "217:\tlearn: 0.1425495\ttotal: 6.49s\tremaining: 23.3s\n",
      "218:\tlearn: 0.1423591\ttotal: 6.51s\tremaining: 23.2s\n",
      "219:\tlearn: 0.1422469\ttotal: 6.53s\tremaining: 23.2s\n",
      "220:\tlearn: 0.1421357\ttotal: 6.56s\tremaining: 23.1s\n",
      "221:\tlearn: 0.1420200\ttotal: 6.58s\tremaining: 23.1s\n",
      "222:\tlearn: 0.1419219\ttotal: 6.61s\tremaining: 23s\n",
      "223:\tlearn: 0.1417429\ttotal: 6.63s\tremaining: 23s\n",
      "224:\tlearn: 0.1414391\ttotal: 6.67s\tremaining: 23s\n",
      "225:\tlearn: 0.1412783\ttotal: 6.7s\tremaining: 22.9s\n",
      "226:\tlearn: 0.1411997\ttotal: 6.72s\tremaining: 22.9s\n",
      "227:\tlearn: 0.1408803\ttotal: 6.75s\tremaining: 22.9s\n",
      "228:\tlearn: 0.1406427\ttotal: 6.78s\tremaining: 22.8s\n",
      "229:\tlearn: 0.1405395\ttotal: 6.81s\tremaining: 22.8s\n",
      "230:\tlearn: 0.1402578\ttotal: 6.83s\tremaining: 22.7s\n",
      "231:\tlearn: 0.1401705\ttotal: 6.86s\tremaining: 22.7s\n",
      "232:\tlearn: 0.1399369\ttotal: 6.88s\tremaining: 22.7s\n",
      "233:\tlearn: 0.1397978\ttotal: 6.91s\tremaining: 22.6s\n",
      "234:\tlearn: 0.1396721\ttotal: 6.94s\tremaining: 22.6s\n",
      "235:\tlearn: 0.1395874\ttotal: 6.96s\tremaining: 22.5s\n",
      "236:\tlearn: 0.1394956\ttotal: 6.99s\tremaining: 22.5s\n",
      "237:\tlearn: 0.1394012\ttotal: 7.01s\tremaining: 22.5s\n",
      "238:\tlearn: 0.1392671\ttotal: 7.04s\tremaining: 22.4s\n",
      "239:\tlearn: 0.1391236\ttotal: 7.06s\tremaining: 22.4s\n",
      "240:\tlearn: 0.1389957\ttotal: 7.08s\tremaining: 22.3s\n",
      "241:\tlearn: 0.1388899\ttotal: 7.1s\tremaining: 22.2s\n",
      "242:\tlearn: 0.1388033\ttotal: 7.13s\tremaining: 22.2s\n",
      "243:\tlearn: 0.1386828\ttotal: 7.15s\tremaining: 22.1s\n",
      "244:\tlearn: 0.1385927\ttotal: 7.17s\tremaining: 22.1s\n",
      "245:\tlearn: 0.1384977\ttotal: 7.19s\tremaining: 22s\n",
      "246:\tlearn: 0.1382721\ttotal: 7.21s\tremaining: 22s\n",
      "247:\tlearn: 0.1380724\ttotal: 7.24s\tremaining: 22s\n",
      "248:\tlearn: 0.1379831\ttotal: 7.27s\tremaining: 21.9s\n",
      "249:\tlearn: 0.1378935\ttotal: 7.29s\tremaining: 21.9s\n",
      "250:\tlearn: 0.1378141\ttotal: 7.32s\tremaining: 21.8s\n",
      "251:\tlearn: 0.1376884\ttotal: 7.34s\tremaining: 21.8s\n",
      "252:\tlearn: 0.1375875\ttotal: 7.37s\tremaining: 21.8s\n",
      "253:\tlearn: 0.1375084\ttotal: 7.41s\tremaining: 21.8s\n",
      "254:\tlearn: 0.1373882\ttotal: 7.43s\tremaining: 21.7s\n",
      "255:\tlearn: 0.1372123\ttotal: 7.45s\tremaining: 21.7s\n",
      "256:\tlearn: 0.1370338\ttotal: 7.48s\tremaining: 21.6s\n",
      "257:\tlearn: 0.1369709\ttotal: 7.5s\tremaining: 21.6s\n",
      "258:\tlearn: 0.1368791\ttotal: 7.52s\tremaining: 21.5s\n",
      "259:\tlearn: 0.1368178\ttotal: 7.54s\tremaining: 21.5s\n",
      "260:\tlearn: 0.1366549\ttotal: 7.57s\tremaining: 21.4s\n",
      "261:\tlearn: 0.1365833\ttotal: 7.59s\tremaining: 21.4s\n",
      "262:\tlearn: 0.1365086\ttotal: 7.61s\tremaining: 21.3s\n",
      "263:\tlearn: 0.1363789\ttotal: 7.63s\tremaining: 21.3s\n",
      "264:\tlearn: 0.1363050\ttotal: 7.66s\tremaining: 21.2s\n",
      "265:\tlearn: 0.1362097\ttotal: 7.68s\tremaining: 21.2s\n",
      "266:\tlearn: 0.1361448\ttotal: 7.7s\tremaining: 21.1s\n",
      "267:\tlearn: 0.1360747\ttotal: 7.72s\tremaining: 21.1s\n",
      "268:\tlearn: 0.1360142\ttotal: 7.75s\tremaining: 21.1s\n",
      "269:\tlearn: 0.1359014\ttotal: 7.77s\tremaining: 21s\n",
      "270:\tlearn: 0.1358334\ttotal: 7.79s\tremaining: 21s\n",
      "271:\tlearn: 0.1357616\ttotal: 7.81s\tremaining: 20.9s\n",
      "272:\tlearn: 0.1356889\ttotal: 7.83s\tremaining: 20.9s\n",
      "273:\tlearn: 0.1356182\ttotal: 7.86s\tremaining: 20.8s\n",
      "274:\tlearn: 0.1354551\ttotal: 7.88s\tremaining: 20.8s\n",
      "275:\tlearn: 0.1353818\ttotal: 7.9s\tremaining: 20.7s\n",
      "276:\tlearn: 0.1353219\ttotal: 7.92s\tremaining: 20.7s\n",
      "277:\tlearn: 0.1351625\ttotal: 7.94s\tremaining: 20.6s\n",
      "278:\tlearn: 0.1351111\ttotal: 7.96s\tremaining: 20.6s\n",
      "279:\tlearn: 0.1350120\ttotal: 7.99s\tremaining: 20.5s\n",
      "280:\tlearn: 0.1349600\ttotal: 8.01s\tremaining: 20.5s\n",
      "281:\tlearn: 0.1348017\ttotal: 8.04s\tremaining: 20.5s\n",
      "282:\tlearn: 0.1346762\ttotal: 8.06s\tremaining: 20.4s\n",
      "283:\tlearn: 0.1346135\ttotal: 8.08s\tremaining: 20.4s\n",
      "284:\tlearn: 0.1345630\ttotal: 8.1s\tremaining: 20.3s\n",
      "285:\tlearn: 0.1344876\ttotal: 8.13s\tremaining: 20.3s\n",
      "286:\tlearn: 0.1344276\ttotal: 8.15s\tremaining: 20.2s\n",
      "287:\tlearn: 0.1342491\ttotal: 8.18s\tremaining: 20.2s\n",
      "288:\tlearn: 0.1341910\ttotal: 8.21s\tremaining: 20.2s\n",
      "289:\tlearn: 0.1340546\ttotal: 8.23s\tremaining: 20.2s\n",
      "290:\tlearn: 0.1338934\ttotal: 8.26s\tremaining: 20.1s\n",
      "291:\tlearn: 0.1337664\ttotal: 8.28s\tremaining: 20.1s\n",
      "292:\tlearn: 0.1336165\ttotal: 8.31s\tremaining: 20s\n",
      "293:\tlearn: 0.1334706\ttotal: 8.33s\tremaining: 20s\n",
      "294:\tlearn: 0.1333894\ttotal: 8.36s\tremaining: 20s\n",
      "295:\tlearn: 0.1333332\ttotal: 8.39s\tremaining: 20s\n",
      "296:\tlearn: 0.1331643\ttotal: 8.42s\tremaining: 19.9s\n",
      "297:\tlearn: 0.1330394\ttotal: 8.45s\tremaining: 19.9s\n",
      "298:\tlearn: 0.1329890\ttotal: 8.47s\tremaining: 19.9s\n",
      "299:\tlearn: 0.1328095\ttotal: 8.5s\tremaining: 19.8s\n",
      "300:\tlearn: 0.1327488\ttotal: 8.53s\tremaining: 19.8s\n",
      "301:\tlearn: 0.1326511\ttotal: 8.55s\tremaining: 19.8s\n",
      "302:\tlearn: 0.1325960\ttotal: 8.58s\tremaining: 19.7s\n",
      "303:\tlearn: 0.1325329\ttotal: 8.61s\tremaining: 19.7s\n",
      "304:\tlearn: 0.1324776\ttotal: 8.64s\tremaining: 19.7s\n",
      "305:\tlearn: 0.1324285\ttotal: 8.66s\tremaining: 19.6s\n",
      "306:\tlearn: 0.1323867\ttotal: 8.69s\tremaining: 19.6s\n",
      "307:\tlearn: 0.1323418\ttotal: 8.72s\tremaining: 19.6s\n",
      "308:\tlearn: 0.1322982\ttotal: 8.74s\tremaining: 19.5s\n",
      "309:\tlearn: 0.1322124\ttotal: 8.77s\tremaining: 19.5s\n",
      "310:\tlearn: 0.1321047\ttotal: 8.8s\tremaining: 19.5s\n",
      "311:\tlearn: 0.1320556\ttotal: 8.82s\tremaining: 19.4s\n",
      "312:\tlearn: 0.1320003\ttotal: 8.84s\tremaining: 19.4s\n",
      "313:\tlearn: 0.1319255\ttotal: 8.87s\tremaining: 19.4s\n",
      "314:\tlearn: 0.1318760\ttotal: 8.89s\tremaining: 19.3s\n",
      "315:\tlearn: 0.1318206\ttotal: 8.92s\tremaining: 19.3s\n",
      "316:\tlearn: 0.1317665\ttotal: 8.97s\tremaining: 19.3s\n",
      "317:\tlearn: 0.1317288\ttotal: 8.99s\tremaining: 19.3s\n",
      "318:\tlearn: 0.1316853\ttotal: 9.02s\tremaining: 19.3s\n",
      "319:\tlearn: 0.1315246\ttotal: 9.04s\tremaining: 19.2s\n",
      "320:\tlearn: 0.1314582\ttotal: 9.06s\tremaining: 19.2s\n",
      "321:\tlearn: 0.1313681\ttotal: 9.08s\tremaining: 19.1s\n",
      "322:\tlearn: 0.1313293\ttotal: 9.1s\tremaining: 19.1s\n",
      "323:\tlearn: 0.1312778\ttotal: 9.13s\tremaining: 19s\n",
      "324:\tlearn: 0.1311118\ttotal: 9.15s\tremaining: 19s\n",
      "325:\tlearn: 0.1310732\ttotal: 9.17s\tremaining: 19s\n",
      "326:\tlearn: 0.1310252\ttotal: 9.19s\tremaining: 18.9s\n",
      "327:\tlearn: 0.1309769\ttotal: 9.21s\tremaining: 18.9s\n",
      "328:\tlearn: 0.1309278\ttotal: 9.23s\tremaining: 18.8s\n",
      "329:\tlearn: 0.1308847\ttotal: 9.25s\tremaining: 18.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330:\tlearn: 0.1307673\ttotal: 9.27s\tremaining: 18.7s\n",
      "331:\tlearn: 0.1306196\ttotal: 9.29s\tremaining: 18.7s\n",
      "332:\tlearn: 0.1305757\ttotal: 9.31s\tremaining: 18.7s\n",
      "333:\tlearn: 0.1305391\ttotal: 9.33s\tremaining: 18.6s\n",
      "334:\tlearn: 0.1304989\ttotal: 9.36s\tremaining: 18.6s\n",
      "335:\tlearn: 0.1304158\ttotal: 9.39s\tremaining: 18.6s\n",
      "336:\tlearn: 0.1302759\ttotal: 9.41s\tremaining: 18.5s\n",
      "337:\tlearn: 0.1301731\ttotal: 9.43s\tremaining: 18.5s\n",
      "338:\tlearn: 0.1301457\ttotal: 9.45s\tremaining: 18.4s\n",
      "339:\tlearn: 0.1300963\ttotal: 9.47s\tremaining: 18.4s\n",
      "340:\tlearn: 0.1300608\ttotal: 9.49s\tremaining: 18.3s\n",
      "341:\tlearn: 0.1300256\ttotal: 9.51s\tremaining: 18.3s\n",
      "342:\tlearn: 0.1299848\ttotal: 9.53s\tremaining: 18.3s\n",
      "343:\tlearn: 0.1299450\ttotal: 9.55s\tremaining: 18.2s\n",
      "344:\tlearn: 0.1298236\ttotal: 9.57s\tremaining: 18.2s\n",
      "345:\tlearn: 0.1297872\ttotal: 9.59s\tremaining: 18.1s\n",
      "346:\tlearn: 0.1297144\ttotal: 9.61s\tremaining: 18.1s\n",
      "347:\tlearn: 0.1296784\ttotal: 9.64s\tremaining: 18.1s\n",
      "348:\tlearn: 0.1296469\ttotal: 9.65s\tremaining: 18s\n",
      "349:\tlearn: 0.1295876\ttotal: 9.67s\tremaining: 18s\n",
      "350:\tlearn: 0.1294794\ttotal: 9.69s\tremaining: 17.9s\n",
      "351:\tlearn: 0.1294425\ttotal: 9.71s\tremaining: 17.9s\n",
      "352:\tlearn: 0.1293193\ttotal: 9.73s\tremaining: 17.8s\n",
      "353:\tlearn: 0.1292744\ttotal: 9.74s\tremaining: 17.8s\n",
      "354:\tlearn: 0.1292316\ttotal: 9.76s\tremaining: 17.7s\n",
      "355:\tlearn: 0.1292004\ttotal: 9.78s\tremaining: 17.7s\n",
      "356:\tlearn: 0.1291579\ttotal: 9.8s\tremaining: 17.6s\n",
      "357:\tlearn: 0.1289993\ttotal: 9.82s\tremaining: 17.6s\n",
      "358:\tlearn: 0.1289521\ttotal: 9.84s\tremaining: 17.6s\n",
      "359:\tlearn: 0.1289109\ttotal: 9.85s\tremaining: 17.5s\n",
      "360:\tlearn: 0.1288623\ttotal: 9.87s\tremaining: 17.5s\n",
      "361:\tlearn: 0.1287931\ttotal: 9.89s\tremaining: 17.4s\n",
      "362:\tlearn: 0.1287594\ttotal: 9.91s\tremaining: 17.4s\n",
      "363:\tlearn: 0.1287178\ttotal: 9.93s\tremaining: 17.3s\n",
      "364:\tlearn: 0.1286776\ttotal: 9.95s\tremaining: 17.3s\n",
      "365:\tlearn: 0.1285528\ttotal: 9.97s\tremaining: 17.3s\n",
      "366:\tlearn: 0.1285185\ttotal: 9.99s\tremaining: 17.2s\n",
      "367:\tlearn: 0.1284852\ttotal: 10s\tremaining: 17.2s\n",
      "368:\tlearn: 0.1284415\ttotal: 10s\tremaining: 17.2s\n",
      "369:\tlearn: 0.1283392\ttotal: 10.1s\tremaining: 17.1s\n",
      "370:\tlearn: 0.1282988\ttotal: 10.1s\tremaining: 17.1s\n",
      "371:\tlearn: 0.1282645\ttotal: 10.1s\tremaining: 17s\n",
      "372:\tlearn: 0.1282337\ttotal: 10.1s\tremaining: 17s\n",
      "373:\tlearn: 0.1281936\ttotal: 10.1s\tremaining: 17s\n",
      "374:\tlearn: 0.1281601\ttotal: 10.2s\tremaining: 17s\n",
      "375:\tlearn: 0.1281280\ttotal: 10.2s\tremaining: 16.9s\n",
      "376:\tlearn: 0.1280820\ttotal: 10.2s\tremaining: 16.9s\n",
      "377:\tlearn: 0.1280452\ttotal: 10.2s\tremaining: 16.9s\n",
      "378:\tlearn: 0.1279188\ttotal: 10.3s\tremaining: 16.8s\n",
      "379:\tlearn: 0.1278800\ttotal: 10.3s\tremaining: 16.8s\n",
      "380:\tlearn: 0.1277726\ttotal: 10.3s\tremaining: 16.8s\n",
      "381:\tlearn: 0.1276860\ttotal: 10.3s\tremaining: 16.7s\n",
      "382:\tlearn: 0.1276463\ttotal: 10.4s\tremaining: 16.7s\n",
      "383:\tlearn: 0.1276069\ttotal: 10.4s\tremaining: 16.7s\n",
      "384:\tlearn: 0.1274650\ttotal: 10.4s\tremaining: 16.6s\n",
      "385:\tlearn: 0.1274306\ttotal: 10.4s\tremaining: 16.6s\n",
      "386:\tlearn: 0.1273920\ttotal: 10.5s\tremaining: 16.6s\n",
      "387:\tlearn: 0.1273587\ttotal: 10.5s\tremaining: 16.5s\n",
      "388:\tlearn: 0.1273157\ttotal: 10.5s\tremaining: 16.5s\n",
      "389:\tlearn: 0.1272819\ttotal: 10.5s\tremaining: 16.5s\n",
      "390:\tlearn: 0.1272451\ttotal: 10.6s\tremaining: 16.4s\n",
      "391:\tlearn: 0.1272179\ttotal: 10.6s\tremaining: 16.4s\n",
      "392:\tlearn: 0.1271856\ttotal: 10.6s\tremaining: 16.4s\n",
      "393:\tlearn: 0.1270605\ttotal: 10.6s\tremaining: 16.3s\n",
      "394:\tlearn: 0.1270088\ttotal: 10.6s\tremaining: 16.3s\n",
      "395:\tlearn: 0.1269732\ttotal: 10.7s\tremaining: 16.3s\n",
      "396:\tlearn: 0.1269542\ttotal: 10.7s\tremaining: 16.2s\n",
      "397:\tlearn: 0.1268968\ttotal: 10.7s\tremaining: 16.2s\n",
      "398:\tlearn: 0.1268644\ttotal: 10.7s\tremaining: 16.2s\n",
      "399:\tlearn: 0.1268273\ttotal: 10.7s\tremaining: 16.1s\n",
      "400:\tlearn: 0.1267843\ttotal: 10.8s\tremaining: 16.1s\n",
      "401:\tlearn: 0.1267629\ttotal: 10.8s\tremaining: 16.1s\n",
      "402:\tlearn: 0.1267330\ttotal: 10.8s\tremaining: 16s\n",
      "403:\tlearn: 0.1266902\ttotal: 10.8s\tremaining: 16s\n",
      "404:\tlearn: 0.1266541\ttotal: 10.9s\tremaining: 16s\n",
      "405:\tlearn: 0.1266262\ttotal: 10.9s\tremaining: 15.9s\n",
      "406:\tlearn: 0.1265874\ttotal: 10.9s\tremaining: 15.9s\n",
      "407:\tlearn: 0.1265575\ttotal: 10.9s\tremaining: 15.9s\n",
      "408:\tlearn: 0.1265255\ttotal: 11s\tremaining: 15.8s\n",
      "409:\tlearn: 0.1264909\ttotal: 11s\tremaining: 15.8s\n",
      "410:\tlearn: 0.1264530\ttotal: 11s\tremaining: 15.8s\n",
      "411:\tlearn: 0.1264197\ttotal: 11s\tremaining: 15.7s\n",
      "412:\tlearn: 0.1263916\ttotal: 11s\tremaining: 15.7s\n",
      "413:\tlearn: 0.1263675\ttotal: 11.1s\tremaining: 15.7s\n",
      "414:\tlearn: 0.1263369\ttotal: 11.1s\tremaining: 15.6s\n",
      "415:\tlearn: 0.1262997\ttotal: 11.1s\tremaining: 15.6s\n",
      "416:\tlearn: 0.1262635\ttotal: 11.1s\tremaining: 15.5s\n",
      "417:\tlearn: 0.1262238\ttotal: 11.1s\tremaining: 15.5s\n",
      "418:\tlearn: 0.1261953\ttotal: 11.2s\tremaining: 15.5s\n",
      "419:\tlearn: 0.1261676\ttotal: 11.2s\tremaining: 15.5s\n",
      "420:\tlearn: 0.1260979\ttotal: 11.2s\tremaining: 15.4s\n",
      "421:\tlearn: 0.1260659\ttotal: 11.2s\tremaining: 15.4s\n",
      "422:\tlearn: 0.1259454\ttotal: 11.3s\tremaining: 15.4s\n",
      "423:\tlearn: 0.1259202\ttotal: 11.3s\tremaining: 15.3s\n",
      "424:\tlearn: 0.1258852\ttotal: 11.3s\tremaining: 15.3s\n",
      "425:\tlearn: 0.1258537\ttotal: 11.3s\tremaining: 15.2s\n",
      "426:\tlearn: 0.1258116\ttotal: 11.3s\tremaining: 15.2s\n",
      "427:\tlearn: 0.1257436\ttotal: 11.4s\tremaining: 15.2s\n",
      "428:\tlearn: 0.1257134\ttotal: 11.4s\tremaining: 15.2s\n",
      "429:\tlearn: 0.1256772\ttotal: 11.4s\tremaining: 15.1s\n",
      "430:\tlearn: 0.1256505\ttotal: 11.4s\tremaining: 15.1s\n",
      "431:\tlearn: 0.1256255\ttotal: 11.5s\tremaining: 15.1s\n",
      "432:\tlearn: 0.1255991\ttotal: 11.5s\tremaining: 15s\n",
      "433:\tlearn: 0.1255741\ttotal: 11.5s\tremaining: 15s\n",
      "434:\tlearn: 0.1255432\ttotal: 11.5s\tremaining: 15s\n",
      "435:\tlearn: 0.1254982\ttotal: 11.5s\tremaining: 14.9s\n",
      "436:\tlearn: 0.1254600\ttotal: 11.6s\tremaining: 14.9s\n",
      "437:\tlearn: 0.1254285\ttotal: 11.6s\tremaining: 14.9s\n",
      "438:\tlearn: 0.1253998\ttotal: 11.6s\tremaining: 14.8s\n",
      "439:\tlearn: 0.1253750\ttotal: 11.6s\tremaining: 14.8s\n",
      "440:\tlearn: 0.1253491\ttotal: 11.6s\tremaining: 14.8s\n",
      "441:\tlearn: 0.1253181\ttotal: 11.7s\tremaining: 14.7s\n",
      "442:\tlearn: 0.1252979\ttotal: 11.7s\tremaining: 14.7s\n",
      "443:\tlearn: 0.1252664\ttotal: 11.8s\tremaining: 14.7s\n",
      "444:\tlearn: 0.1252433\ttotal: 11.8s\tremaining: 14.7s\n",
      "445:\tlearn: 0.1252139\ttotal: 11.8s\tremaining: 14.7s\n",
      "446:\tlearn: 0.1251894\ttotal: 11.8s\tremaining: 14.6s\n",
      "447:\tlearn: 0.1251244\ttotal: 11.9s\tremaining: 14.6s\n",
      "448:\tlearn: 0.1250743\ttotal: 11.9s\tremaining: 14.6s\n",
      "449:\tlearn: 0.1250430\ttotal: 11.9s\tremaining: 14.6s\n",
      "450:\tlearn: 0.1250168\ttotal: 11.9s\tremaining: 14.5s\n",
      "451:\tlearn: 0.1249883\ttotal: 12s\tremaining: 14.5s\n",
      "452:\tlearn: 0.1249603\ttotal: 12s\tremaining: 14.5s\n",
      "453:\tlearn: 0.1249350\ttotal: 12s\tremaining: 14.4s\n",
      "454:\tlearn: 0.1249038\ttotal: 12s\tremaining: 14.4s\n",
      "455:\tlearn: 0.1248124\ttotal: 12s\tremaining: 14.4s\n",
      "456:\tlearn: 0.1247883\ttotal: 12.1s\tremaining: 14.3s\n",
      "457:\tlearn: 0.1247456\ttotal: 12.1s\tremaining: 14.3s\n",
      "458:\tlearn: 0.1247153\ttotal: 12.1s\tremaining: 14.3s\n",
      "459:\tlearn: 0.1246920\ttotal: 12.1s\tremaining: 14.2s\n",
      "460:\tlearn: 0.1246702\ttotal: 12.1s\tremaining: 14.2s\n",
      "461:\tlearn: 0.1246557\ttotal: 12.2s\tremaining: 14.2s\n",
      "462:\tlearn: 0.1245822\ttotal: 12.2s\tremaining: 14.1s\n",
      "463:\tlearn: 0.1245480\ttotal: 12.2s\tremaining: 14.1s\n",
      "464:\tlearn: 0.1245175\ttotal: 12.2s\tremaining: 14.1s\n",
      "465:\tlearn: 0.1244825\ttotal: 12.3s\tremaining: 14s\n",
      "466:\tlearn: 0.1244598\ttotal: 12.3s\tremaining: 14s\n",
      "467:\tlearn: 0.1244310\ttotal: 12.3s\tremaining: 14s\n",
      "468:\tlearn: 0.1244037\ttotal: 12.3s\tremaining: 13.9s\n",
      "469:\tlearn: 0.1243792\ttotal: 12.3s\tremaining: 13.9s\n",
      "470:\tlearn: 0.1243534\ttotal: 12.4s\tremaining: 13.9s\n",
      "471:\tlearn: 0.1243270\ttotal: 12.4s\tremaining: 13.9s\n",
      "472:\tlearn: 0.1243036\ttotal: 12.4s\tremaining: 13.8s\n",
      "473:\tlearn: 0.1242776\ttotal: 12.4s\tremaining: 13.8s\n",
      "474:\tlearn: 0.1241982\ttotal: 12.5s\tremaining: 13.8s\n",
      "475:\tlearn: 0.1241455\ttotal: 12.5s\tremaining: 13.7s\n",
      "476:\tlearn: 0.1240708\ttotal: 12.5s\tremaining: 13.7s\n",
      "477:\tlearn: 0.1240393\ttotal: 12.5s\tremaining: 13.7s\n",
      "478:\tlearn: 0.1240184\ttotal: 12.6s\tremaining: 13.7s\n",
      "479:\tlearn: 0.1239547\ttotal: 12.6s\tremaining: 13.6s\n",
      "480:\tlearn: 0.1239224\ttotal: 12.6s\tremaining: 13.6s\n",
      "481:\tlearn: 0.1238972\ttotal: 12.6s\tremaining: 13.6s\n",
      "482:\tlearn: 0.1238758\ttotal: 12.6s\tremaining: 13.5s\n",
      "483:\tlearn: 0.1238478\ttotal: 12.7s\tremaining: 13.5s\n",
      "484:\tlearn: 0.1238261\ttotal: 12.7s\tremaining: 13.5s\n",
      "485:\tlearn: 0.1237278\ttotal: 12.7s\tremaining: 13.4s\n",
      "486:\tlearn: 0.1237057\ttotal: 12.7s\tremaining: 13.4s\n",
      "487:\tlearn: 0.1236738\ttotal: 12.7s\tremaining: 13.4s\n",
      "488:\tlearn: 0.1236516\ttotal: 12.8s\tremaining: 13.3s\n",
      "489:\tlearn: 0.1236294\ttotal: 12.8s\tremaining: 13.3s\n",
      "490:\tlearn: 0.1236049\ttotal: 12.8s\tremaining: 13.3s\n",
      "491:\tlearn: 0.1235821\ttotal: 12.9s\tremaining: 13.3s\n",
      "492:\tlearn: 0.1235591\ttotal: 12.9s\tremaining: 13.3s\n",
      "493:\tlearn: 0.1235325\ttotal: 12.9s\tremaining: 13.2s\n",
      "494:\tlearn: 0.1235151\ttotal: 12.9s\tremaining: 13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495:\tlearn: 0.1234930\ttotal: 13s\tremaining: 13.2s\n",
      "496:\tlearn: 0.1234686\ttotal: 13s\tremaining: 13.2s\n",
      "497:\tlearn: 0.1234471\ttotal: 13s\tremaining: 13.1s\n",
      "498:\tlearn: 0.1234233\ttotal: 13.1s\tremaining: 13.1s\n",
      "499:\tlearn: 0.1234029\ttotal: 13.1s\tremaining: 13.1s\n",
      "500:\tlearn: 0.1233809\ttotal: 13.1s\tremaining: 13.1s\n",
      "501:\tlearn: 0.1233573\ttotal: 13.2s\tremaining: 13s\n",
      "502:\tlearn: 0.1233231\ttotal: 13.2s\tremaining: 13s\n",
      "503:\tlearn: 0.1232914\ttotal: 13.2s\tremaining: 13s\n",
      "504:\tlearn: 0.1232209\ttotal: 13.2s\tremaining: 13s\n",
      "505:\tlearn: 0.1231952\ttotal: 13.3s\tremaining: 12.9s\n",
      "506:\tlearn: 0.1231708\ttotal: 13.3s\tremaining: 12.9s\n",
      "507:\tlearn: 0.1231441\ttotal: 13.3s\tremaining: 12.9s\n",
      "508:\tlearn: 0.1231165\ttotal: 13.4s\tremaining: 12.9s\n",
      "509:\tlearn: 0.1230947\ttotal: 13.4s\tremaining: 12.9s\n",
      "510:\tlearn: 0.1230737\ttotal: 13.4s\tremaining: 12.9s\n",
      "511:\tlearn: 0.1230454\ttotal: 13.5s\tremaining: 12.8s\n",
      "512:\tlearn: 0.1230220\ttotal: 13.5s\tremaining: 12.8s\n",
      "513:\tlearn: 0.1229978\ttotal: 13.5s\tremaining: 12.8s\n",
      "514:\tlearn: 0.1229818\ttotal: 13.6s\tremaining: 12.8s\n",
      "515:\tlearn: 0.1229627\ttotal: 13.6s\tremaining: 12.7s\n",
      "516:\tlearn: 0.1229397\ttotal: 13.6s\tremaining: 12.7s\n",
      "517:\tlearn: 0.1228365\ttotal: 13.6s\tremaining: 12.7s\n",
      "518:\tlearn: 0.1228135\ttotal: 13.7s\tremaining: 12.7s\n",
      "519:\tlearn: 0.1227887\ttotal: 13.7s\tremaining: 12.6s\n",
      "520:\tlearn: 0.1227712\ttotal: 13.7s\tremaining: 12.6s\n",
      "521:\tlearn: 0.1227504\ttotal: 13.7s\tremaining: 12.6s\n",
      "522:\tlearn: 0.1227293\ttotal: 13.8s\tremaining: 12.6s\n",
      "523:\tlearn: 0.1227127\ttotal: 13.8s\tremaining: 12.5s\n",
      "524:\tlearn: 0.1226864\ttotal: 13.8s\tremaining: 12.5s\n",
      "525:\tlearn: 0.1226545\ttotal: 13.8s\tremaining: 12.5s\n",
      "526:\tlearn: 0.1226276\ttotal: 13.9s\tremaining: 12.4s\n",
      "527:\tlearn: 0.1225987\ttotal: 13.9s\tremaining: 12.4s\n",
      "528:\tlearn: 0.1225747\ttotal: 13.9s\tremaining: 12.4s\n",
      "529:\tlearn: 0.1225566\ttotal: 13.9s\tremaining: 12.4s\n",
      "530:\tlearn: 0.1225360\ttotal: 14s\tremaining: 12.3s\n",
      "531:\tlearn: 0.1225032\ttotal: 14s\tremaining: 12.3s\n",
      "532:\tlearn: 0.1224810\ttotal: 14.1s\tremaining: 12.3s\n",
      "533:\tlearn: 0.1224516\ttotal: 14.1s\tremaining: 12.3s\n",
      "534:\tlearn: 0.1224250\ttotal: 14.1s\tremaining: 12.3s\n",
      "535:\tlearn: 0.1224049\ttotal: 14.2s\tremaining: 12.3s\n",
      "536:\tlearn: 0.1223857\ttotal: 14.2s\tremaining: 12.2s\n",
      "537:\tlearn: 0.1223636\ttotal: 14.2s\tremaining: 12.2s\n",
      "538:\tlearn: 0.1223336\ttotal: 14.2s\tremaining: 12.2s\n",
      "539:\tlearn: 0.1222989\ttotal: 14.3s\tremaining: 12.1s\n",
      "540:\tlearn: 0.1222778\ttotal: 14.3s\tremaining: 12.1s\n",
      "541:\tlearn: 0.1222583\ttotal: 14.3s\tremaining: 12.1s\n",
      "542:\tlearn: 0.1222415\ttotal: 14.4s\tremaining: 12.1s\n",
      "543:\tlearn: 0.1222181\ttotal: 14.4s\tremaining: 12.1s\n",
      "544:\tlearn: 0.1221900\ttotal: 14.4s\tremaining: 12s\n",
      "545:\tlearn: 0.1221648\ttotal: 14.4s\tremaining: 12s\n",
      "546:\tlearn: 0.1221404\ttotal: 14.5s\tremaining: 12s\n",
      "547:\tlearn: 0.1220739\ttotal: 14.5s\tremaining: 12s\n",
      "548:\tlearn: 0.1220599\ttotal: 14.5s\tremaining: 11.9s\n",
      "549:\tlearn: 0.1220348\ttotal: 14.6s\tremaining: 11.9s\n",
      "550:\tlearn: 0.1220088\ttotal: 14.6s\tremaining: 11.9s\n",
      "551:\tlearn: 0.1219937\ttotal: 14.6s\tremaining: 11.9s\n",
      "552:\tlearn: 0.1219725\ttotal: 14.6s\tremaining: 11.8s\n",
      "553:\tlearn: 0.1219576\ttotal: 14.6s\tremaining: 11.8s\n",
      "554:\tlearn: 0.1219286\ttotal: 14.7s\tremaining: 11.8s\n",
      "555:\tlearn: 0.1218999\ttotal: 14.7s\tremaining: 11.7s\n",
      "556:\tlearn: 0.1218720\ttotal: 14.7s\tremaining: 11.7s\n",
      "557:\tlearn: 0.1218473\ttotal: 14.7s\tremaining: 11.7s\n",
      "558:\tlearn: 0.1218284\ttotal: 14.8s\tremaining: 11.6s\n",
      "559:\tlearn: 0.1218081\ttotal: 14.8s\tremaining: 11.6s\n",
      "560:\tlearn: 0.1217815\ttotal: 14.8s\tremaining: 11.6s\n",
      "561:\tlearn: 0.1217639\ttotal: 14.8s\tremaining: 11.6s\n",
      "562:\tlearn: 0.1217523\ttotal: 14.8s\tremaining: 11.5s\n",
      "563:\tlearn: 0.1217310\ttotal: 14.9s\tremaining: 11.5s\n",
      "564:\tlearn: 0.1217092\ttotal: 14.9s\tremaining: 11.5s\n",
      "565:\tlearn: 0.1216840\ttotal: 14.9s\tremaining: 11.4s\n",
      "566:\tlearn: 0.1216659\ttotal: 14.9s\tremaining: 11.4s\n",
      "567:\tlearn: 0.1216424\ttotal: 15s\tremaining: 11.4s\n",
      "568:\tlearn: 0.1216216\ttotal: 15s\tremaining: 11.4s\n",
      "569:\tlearn: 0.1216056\ttotal: 15s\tremaining: 11.3s\n",
      "570:\tlearn: 0.1215892\ttotal: 15s\tremaining: 11.3s\n",
      "571:\tlearn: 0.1215605\ttotal: 15.1s\tremaining: 11.3s\n",
      "572:\tlearn: 0.1215404\ttotal: 15.1s\tremaining: 11.2s\n",
      "573:\tlearn: 0.1215214\ttotal: 15.1s\tremaining: 11.2s\n",
      "574:\tlearn: 0.1214993\ttotal: 15.1s\tremaining: 11.2s\n",
      "575:\tlearn: 0.1214797\ttotal: 15.2s\tremaining: 11.2s\n",
      "576:\tlearn: 0.1214577\ttotal: 15.2s\tremaining: 11.1s\n",
      "577:\tlearn: 0.1214352\ttotal: 15.2s\tremaining: 11.1s\n",
      "578:\tlearn: 0.1214179\ttotal: 15.2s\tremaining: 11.1s\n",
      "579:\tlearn: 0.1213911\ttotal: 15.3s\tremaining: 11.1s\n",
      "580:\tlearn: 0.1213636\ttotal: 15.3s\tremaining: 11s\n",
      "581:\tlearn: 0.1213469\ttotal: 15.3s\tremaining: 11s\n",
      "582:\tlearn: 0.1213252\ttotal: 15.3s\tremaining: 11s\n",
      "583:\tlearn: 0.1213006\ttotal: 15.4s\tremaining: 10.9s\n",
      "584:\tlearn: 0.1212728\ttotal: 15.4s\tremaining: 10.9s\n",
      "585:\tlearn: 0.1212466\ttotal: 15.4s\tremaining: 10.9s\n",
      "586:\tlearn: 0.1212284\ttotal: 15.4s\tremaining: 10.9s\n",
      "587:\tlearn: 0.1211967\ttotal: 15.5s\tremaining: 10.8s\n",
      "588:\tlearn: 0.1211752\ttotal: 15.5s\tremaining: 10.8s\n",
      "589:\tlearn: 0.1211438\ttotal: 15.5s\tremaining: 10.8s\n",
      "590:\tlearn: 0.1210689\ttotal: 15.5s\tremaining: 10.7s\n",
      "591:\tlearn: 0.1210499\ttotal: 15.5s\tremaining: 10.7s\n",
      "592:\tlearn: 0.1210304\ttotal: 15.6s\tremaining: 10.7s\n",
      "593:\tlearn: 0.1210063\ttotal: 15.6s\tremaining: 10.7s\n",
      "594:\tlearn: 0.1209854\ttotal: 15.6s\tremaining: 10.6s\n",
      "595:\tlearn: 0.1209276\ttotal: 15.6s\tremaining: 10.6s\n",
      "596:\tlearn: 0.1209069\ttotal: 15.7s\tremaining: 10.6s\n",
      "597:\tlearn: 0.1208353\ttotal: 15.7s\tremaining: 10.5s\n",
      "598:\tlearn: 0.1208165\ttotal: 15.7s\tremaining: 10.5s\n",
      "599:\tlearn: 0.1207938\ttotal: 15.7s\tremaining: 10.5s\n",
      "600:\tlearn: 0.1207099\ttotal: 15.7s\tremaining: 10.5s\n",
      "601:\tlearn: 0.1206927\ttotal: 15.8s\tremaining: 10.4s\n",
      "602:\tlearn: 0.1206704\ttotal: 15.8s\tremaining: 10.4s\n",
      "603:\tlearn: 0.1206532\ttotal: 15.8s\tremaining: 10.4s\n",
      "604:\tlearn: 0.1206129\ttotal: 15.8s\tremaining: 10.3s\n",
      "605:\tlearn: 0.1205815\ttotal: 15.9s\tremaining: 10.3s\n",
      "606:\tlearn: 0.1205613\ttotal: 15.9s\tremaining: 10.3s\n",
      "607:\tlearn: 0.1205436\ttotal: 15.9s\tremaining: 10.3s\n",
      "608:\tlearn: 0.1205065\ttotal: 15.9s\tremaining: 10.2s\n",
      "609:\tlearn: 0.1204825\ttotal: 15.9s\tremaining: 10.2s\n",
      "610:\tlearn: 0.1204683\ttotal: 16s\tremaining: 10.2s\n",
      "611:\tlearn: 0.1204327\ttotal: 16s\tremaining: 10.1s\n",
      "612:\tlearn: 0.1204025\ttotal: 16s\tremaining: 10.1s\n",
      "613:\tlearn: 0.1203900\ttotal: 16s\tremaining: 10.1s\n",
      "614:\tlearn: 0.1203761\ttotal: 16.1s\tremaining: 10s\n",
      "615:\tlearn: 0.1203586\ttotal: 16.1s\tremaining: 10s\n",
      "616:\tlearn: 0.1203410\ttotal: 16.1s\tremaining: 9.99s\n",
      "617:\tlearn: 0.1203209\ttotal: 16.1s\tremaining: 9.96s\n",
      "618:\tlearn: 0.1202732\ttotal: 16.1s\tremaining: 9.93s\n",
      "619:\tlearn: 0.1202575\ttotal: 16.2s\tremaining: 9.9s\n",
      "620:\tlearn: 0.1202440\ttotal: 16.2s\tremaining: 9.88s\n",
      "621:\tlearn: 0.1202025\ttotal: 16.2s\tremaining: 9.85s\n",
      "622:\tlearn: 0.1201178\ttotal: 16.2s\tremaining: 9.82s\n",
      "623:\tlearn: 0.1200843\ttotal: 16.2s\tremaining: 9.79s\n",
      "624:\tlearn: 0.1200674\ttotal: 16.3s\tremaining: 9.76s\n",
      "625:\tlearn: 0.1200501\ttotal: 16.3s\tremaining: 9.75s\n",
      "626:\tlearn: 0.1200328\ttotal: 16.3s\tremaining: 9.72s\n",
      "627:\tlearn: 0.1200168\ttotal: 16.4s\tremaining: 9.7s\n",
      "628:\tlearn: 0.1199659\ttotal: 16.4s\tremaining: 9.67s\n",
      "629:\tlearn: 0.1199460\ttotal: 16.4s\tremaining: 9.64s\n",
      "630:\tlearn: 0.1199304\ttotal: 16.4s\tremaining: 9.62s\n",
      "631:\tlearn: 0.1199100\ttotal: 16.5s\tremaining: 9.59s\n",
      "632:\tlearn: 0.1198976\ttotal: 16.5s\tremaining: 9.56s\n",
      "633:\tlearn: 0.1198811\ttotal: 16.5s\tremaining: 9.53s\n",
      "634:\tlearn: 0.1198671\ttotal: 16.5s\tremaining: 9.5s\n",
      "635:\tlearn: 0.1198392\ttotal: 16.6s\tremaining: 9.47s\n",
      "636:\tlearn: 0.1198162\ttotal: 16.6s\tremaining: 9.45s\n",
      "637:\tlearn: 0.1197998\ttotal: 16.6s\tremaining: 9.42s\n",
      "638:\tlearn: 0.1197816\ttotal: 16.6s\tremaining: 9.39s\n",
      "639:\tlearn: 0.1197083\ttotal: 16.6s\tremaining: 9.36s\n",
      "640:\tlearn: 0.1196923\ttotal: 16.7s\tremaining: 9.34s\n",
      "641:\tlearn: 0.1196755\ttotal: 16.7s\tremaining: 9.31s\n",
      "642:\tlearn: 0.1196504\ttotal: 16.7s\tremaining: 9.28s\n",
      "643:\tlearn: 0.1196237\ttotal: 16.7s\tremaining: 9.25s\n",
      "644:\tlearn: 0.1195660\ttotal: 16.8s\tremaining: 9.23s\n",
      "645:\tlearn: 0.1195453\ttotal: 16.8s\tremaining: 9.2s\n",
      "646:\tlearn: 0.1195269\ttotal: 16.8s\tremaining: 9.17s\n",
      "647:\tlearn: 0.1195133\ttotal: 16.8s\tremaining: 9.15s\n",
      "648:\tlearn: 0.1194906\ttotal: 16.9s\tremaining: 9.12s\n",
      "649:\tlearn: 0.1194763\ttotal: 16.9s\tremaining: 9.09s\n",
      "650:\tlearn: 0.1194555\ttotal: 16.9s\tremaining: 9.06s\n",
      "651:\tlearn: 0.1194384\ttotal: 16.9s\tremaining: 9.04s\n",
      "652:\tlearn: 0.1194222\ttotal: 17s\tremaining: 9.01s\n",
      "653:\tlearn: 0.1194077\ttotal: 17s\tremaining: 8.98s\n",
      "654:\tlearn: 0.1193850\ttotal: 17s\tremaining: 8.96s\n",
      "655:\tlearn: 0.1193415\ttotal: 17s\tremaining: 8.93s\n",
      "656:\tlearn: 0.1193189\ttotal: 17.1s\tremaining: 8.9s\n",
      "657:\tlearn: 0.1192987\ttotal: 17.1s\tremaining: 8.88s\n",
      "658:\tlearn: 0.1192819\ttotal: 17.1s\tremaining: 8.85s\n",
      "659:\tlearn: 0.1192637\ttotal: 17.1s\tremaining: 8.82s\n",
      "660:\tlearn: 0.1192488\ttotal: 17.1s\tremaining: 8.79s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661:\tlearn: 0.1192314\ttotal: 17.2s\tremaining: 8.77s\n",
      "662:\tlearn: 0.1192111\ttotal: 17.2s\tremaining: 8.74s\n",
      "663:\tlearn: 0.1191849\ttotal: 17.2s\tremaining: 8.71s\n",
      "664:\tlearn: 0.1191624\ttotal: 17.2s\tremaining: 8.69s\n",
      "665:\tlearn: 0.1191436\ttotal: 17.3s\tremaining: 8.66s\n",
      "666:\tlearn: 0.1191242\ttotal: 17.3s\tremaining: 8.64s\n",
      "667:\tlearn: 0.1190950\ttotal: 17.3s\tremaining: 8.62s\n",
      "668:\tlearn: 0.1190782\ttotal: 17.4s\tremaining: 8.59s\n",
      "669:\tlearn: 0.1190611\ttotal: 17.4s\tremaining: 8.57s\n",
      "670:\tlearn: 0.1190350\ttotal: 17.4s\tremaining: 8.54s\n",
      "671:\tlearn: 0.1190243\ttotal: 17.5s\tremaining: 8.52s\n",
      "672:\tlearn: 0.1190073\ttotal: 17.5s\tremaining: 8.49s\n",
      "673:\tlearn: 0.1189799\ttotal: 17.5s\tremaining: 8.47s\n",
      "674:\tlearn: 0.1189621\ttotal: 17.5s\tremaining: 8.44s\n",
      "675:\tlearn: 0.1189384\ttotal: 17.6s\tremaining: 8.42s\n",
      "676:\tlearn: 0.1189138\ttotal: 17.6s\tremaining: 8.39s\n",
      "677:\tlearn: 0.1188983\ttotal: 17.6s\tremaining: 8.37s\n",
      "678:\tlearn: 0.1188789\ttotal: 17.6s\tremaining: 8.34s\n",
      "679:\tlearn: 0.1188561\ttotal: 17.7s\tremaining: 8.32s\n",
      "680:\tlearn: 0.1188474\ttotal: 17.7s\tremaining: 8.29s\n",
      "681:\tlearn: 0.1188298\ttotal: 17.7s\tremaining: 8.27s\n",
      "682:\tlearn: 0.1187475\ttotal: 17.8s\tremaining: 8.24s\n",
      "683:\tlearn: 0.1187286\ttotal: 17.8s\tremaining: 8.21s\n",
      "684:\tlearn: 0.1187008\ttotal: 17.8s\tremaining: 8.19s\n",
      "685:\tlearn: 0.1186866\ttotal: 17.8s\tremaining: 8.16s\n",
      "686:\tlearn: 0.1186690\ttotal: 17.9s\tremaining: 8.13s\n",
      "687:\tlearn: 0.1186546\ttotal: 17.9s\tremaining: 8.11s\n",
      "688:\tlearn: 0.1186347\ttotal: 17.9s\tremaining: 8.08s\n",
      "689:\tlearn: 0.1186114\ttotal: 17.9s\tremaining: 8.05s\n",
      "690:\tlearn: 0.1185571\ttotal: 17.9s\tremaining: 8.03s\n",
      "691:\tlearn: 0.1185114\ttotal: 18s\tremaining: 8s\n",
      "692:\tlearn: 0.1184923\ttotal: 18s\tremaining: 7.97s\n",
      "693:\tlearn: 0.1184694\ttotal: 18s\tremaining: 7.94s\n",
      "694:\tlearn: 0.1184420\ttotal: 18s\tremaining: 7.92s\n",
      "695:\tlearn: 0.1184201\ttotal: 18.1s\tremaining: 7.89s\n",
      "696:\tlearn: 0.1183958\ttotal: 18.1s\tremaining: 7.87s\n",
      "697:\tlearn: 0.1183828\ttotal: 18.1s\tremaining: 7.84s\n",
      "698:\tlearn: 0.1183547\ttotal: 18.1s\tremaining: 7.81s\n",
      "699:\tlearn: 0.1183327\ttotal: 18.2s\tremaining: 7.79s\n",
      "700:\tlearn: 0.1183146\ttotal: 18.2s\tremaining: 7.76s\n",
      "701:\tlearn: 0.1182945\ttotal: 18.2s\tremaining: 7.73s\n",
      "702:\tlearn: 0.1182730\ttotal: 18.2s\tremaining: 7.7s\n",
      "703:\tlearn: 0.1182527\ttotal: 18.3s\tremaining: 7.68s\n",
      "704:\tlearn: 0.1182269\ttotal: 18.3s\tremaining: 7.66s\n",
      "705:\tlearn: 0.1182088\ttotal: 18.3s\tremaining: 7.63s\n",
      "706:\tlearn: 0.1181834\ttotal: 18.4s\tremaining: 7.61s\n",
      "707:\tlearn: 0.1181656\ttotal: 18.4s\tremaining: 7.58s\n",
      "708:\tlearn: 0.1181490\ttotal: 18.4s\tremaining: 7.55s\n",
      "709:\tlearn: 0.1181329\ttotal: 18.4s\tremaining: 7.53s\n",
      "710:\tlearn: 0.1181115\ttotal: 18.5s\tremaining: 7.5s\n",
      "711:\tlearn: 0.1180922\ttotal: 18.5s\tremaining: 7.48s\n",
      "712:\tlearn: 0.1180746\ttotal: 18.5s\tremaining: 7.46s\n",
      "713:\tlearn: 0.1180502\ttotal: 18.6s\tremaining: 7.43s\n",
      "714:\tlearn: 0.1179955\ttotal: 18.6s\tremaining: 7.41s\n",
      "715:\tlearn: 0.1179712\ttotal: 18.6s\tremaining: 7.38s\n",
      "716:\tlearn: 0.1179607\ttotal: 18.6s\tremaining: 7.36s\n",
      "717:\tlearn: 0.1179467\ttotal: 18.7s\tremaining: 7.33s\n",
      "718:\tlearn: 0.1179295\ttotal: 18.7s\tremaining: 7.3s\n",
      "719:\tlearn: 0.1179136\ttotal: 18.7s\tremaining: 7.28s\n",
      "720:\tlearn: 0.1178937\ttotal: 18.7s\tremaining: 7.25s\n",
      "721:\tlearn: 0.1178794\ttotal: 18.8s\tremaining: 7.22s\n",
      "722:\tlearn: 0.1178676\ttotal: 18.8s\tremaining: 7.19s\n",
      "723:\tlearn: 0.1178189\ttotal: 18.8s\tremaining: 7.17s\n",
      "724:\tlearn: 0.1177945\ttotal: 18.8s\tremaining: 7.14s\n",
      "725:\tlearn: 0.1177752\ttotal: 18.8s\tremaining: 7.11s\n",
      "726:\tlearn: 0.1177519\ttotal: 18.9s\tremaining: 7.08s\n",
      "727:\tlearn: 0.1177295\ttotal: 18.9s\tremaining: 7.06s\n",
      "728:\tlearn: 0.1177095\ttotal: 18.9s\tremaining: 7.03s\n",
      "729:\tlearn: 0.1176902\ttotal: 18.9s\tremaining: 7s\n",
      "730:\tlearn: 0.1176788\ttotal: 19s\tremaining: 6.98s\n",
      "731:\tlearn: 0.1176580\ttotal: 19s\tremaining: 6.95s\n",
      "732:\tlearn: 0.1176440\ttotal: 19s\tremaining: 6.92s\n",
      "733:\tlearn: 0.1176281\ttotal: 19s\tremaining: 6.89s\n",
      "734:\tlearn: 0.1176111\ttotal: 19s\tremaining: 6.87s\n",
      "735:\tlearn: 0.1175924\ttotal: 19.1s\tremaining: 6.84s\n",
      "736:\tlearn: 0.1175795\ttotal: 19.1s\tremaining: 6.81s\n",
      "737:\tlearn: 0.1175652\ttotal: 19.1s\tremaining: 6.79s\n",
      "738:\tlearn: 0.1175463\ttotal: 19.1s\tremaining: 6.76s\n",
      "739:\tlearn: 0.1175201\ttotal: 19.2s\tremaining: 6.73s\n",
      "740:\tlearn: 0.1175076\ttotal: 19.2s\tremaining: 6.71s\n",
      "741:\tlearn: 0.1174460\ttotal: 19.2s\tremaining: 6.68s\n",
      "742:\tlearn: 0.1174285\ttotal: 19.2s\tremaining: 6.65s\n",
      "743:\tlearn: 0.1174115\ttotal: 19.3s\tremaining: 6.63s\n",
      "744:\tlearn: 0.1173894\ttotal: 19.3s\tremaining: 6.6s\n",
      "745:\tlearn: 0.1173772\ttotal: 19.3s\tremaining: 6.58s\n",
      "746:\tlearn: 0.1173615\ttotal: 19.3s\tremaining: 6.55s\n",
      "747:\tlearn: 0.1173404\ttotal: 19.4s\tremaining: 6.52s\n",
      "748:\tlearn: 0.1173222\ttotal: 19.4s\tremaining: 6.5s\n",
      "749:\tlearn: 0.1173045\ttotal: 19.4s\tremaining: 6.47s\n",
      "750:\tlearn: 0.1172866\ttotal: 19.4s\tremaining: 6.44s\n",
      "751:\tlearn: 0.1172669\ttotal: 19.5s\tremaining: 6.42s\n",
      "752:\tlearn: 0.1172447\ttotal: 19.5s\tremaining: 6.39s\n",
      "753:\tlearn: 0.1172283\ttotal: 19.5s\tremaining: 6.36s\n",
      "754:\tlearn: 0.1172149\ttotal: 19.5s\tremaining: 6.33s\n",
      "755:\tlearn: 0.1172007\ttotal: 19.5s\tremaining: 6.31s\n",
      "756:\tlearn: 0.1171842\ttotal: 19.6s\tremaining: 6.28s\n",
      "757:\tlearn: 0.1171238\ttotal: 19.6s\tremaining: 6.25s\n",
      "758:\tlearn: 0.1171139\ttotal: 19.6s\tremaining: 6.23s\n",
      "759:\tlearn: 0.1170950\ttotal: 19.6s\tremaining: 6.2s\n",
      "760:\tlearn: 0.1170815\ttotal: 19.7s\tremaining: 6.18s\n",
      "761:\tlearn: 0.1170638\ttotal: 19.7s\tremaining: 6.15s\n",
      "762:\tlearn: 0.1170462\ttotal: 19.7s\tremaining: 6.12s\n",
      "763:\tlearn: 0.1170202\ttotal: 19.7s\tremaining: 6.1s\n",
      "764:\tlearn: 0.1169661\ttotal: 19.8s\tremaining: 6.07s\n",
      "765:\tlearn: 0.1169519\ttotal: 19.8s\tremaining: 6.04s\n",
      "766:\tlearn: 0.1169339\ttotal: 19.8s\tremaining: 6.02s\n",
      "767:\tlearn: 0.1169158\ttotal: 19.9s\tremaining: 6s\n",
      "768:\tlearn: 0.1168953\ttotal: 19.9s\tremaining: 5.97s\n",
      "769:\tlearn: 0.1168761\ttotal: 19.9s\tremaining: 5.95s\n",
      "770:\tlearn: 0.1168455\ttotal: 19.9s\tremaining: 5.92s\n",
      "771:\tlearn: 0.1168274\ttotal: 20s\tremaining: 5.9s\n",
      "772:\tlearn: 0.1168101\ttotal: 20s\tremaining: 5.88s\n",
      "773:\tlearn: 0.1167931\ttotal: 20.1s\tremaining: 5.85s\n",
      "774:\tlearn: 0.1167841\ttotal: 20.1s\tremaining: 5.83s\n",
      "775:\tlearn: 0.1167657\ttotal: 20.1s\tremaining: 5.81s\n",
      "776:\tlearn: 0.1167440\ttotal: 20.2s\tremaining: 5.79s\n",
      "777:\tlearn: 0.1167302\ttotal: 20.2s\tremaining: 5.76s\n",
      "778:\tlearn: 0.1167150\ttotal: 20.2s\tremaining: 5.73s\n",
      "779:\tlearn: 0.1166973\ttotal: 20.2s\tremaining: 5.71s\n",
      "780:\tlearn: 0.1166818\ttotal: 20.3s\tremaining: 5.7s\n",
      "781:\tlearn: 0.1166509\ttotal: 20.4s\tremaining: 5.67s\n",
      "782:\tlearn: 0.1166364\ttotal: 20.4s\tremaining: 5.65s\n",
      "783:\tlearn: 0.1166178\ttotal: 20.4s\tremaining: 5.63s\n",
      "784:\tlearn: 0.1166045\ttotal: 20.4s\tremaining: 5.6s\n",
      "785:\tlearn: 0.1165856\ttotal: 20.5s\tremaining: 5.58s\n",
      "786:\tlearn: 0.1165708\ttotal: 20.5s\tremaining: 5.55s\n",
      "787:\tlearn: 0.1165430\ttotal: 20.5s\tremaining: 5.53s\n",
      "788:\tlearn: 0.1165318\ttotal: 20.6s\tremaining: 5.5s\n",
      "789:\tlearn: 0.1165143\ttotal: 20.6s\tremaining: 5.48s\n",
      "790:\tlearn: 0.1164968\ttotal: 20.6s\tremaining: 5.45s\n",
      "791:\tlearn: 0.1164815\ttotal: 20.7s\tremaining: 5.43s\n",
      "792:\tlearn: 0.1164624\ttotal: 20.7s\tremaining: 5.4s\n",
      "793:\tlearn: 0.1164444\ttotal: 20.7s\tremaining: 5.38s\n",
      "794:\tlearn: 0.1164234\ttotal: 20.8s\tremaining: 5.35s\n",
      "795:\tlearn: 0.1164090\ttotal: 20.8s\tremaining: 5.33s\n",
      "796:\tlearn: 0.1163915\ttotal: 20.8s\tremaining: 5.3s\n",
      "797:\tlearn: 0.1163714\ttotal: 20.8s\tremaining: 5.28s\n",
      "798:\tlearn: 0.1163575\ttotal: 20.9s\tremaining: 5.25s\n",
      "799:\tlearn: 0.1163199\ttotal: 20.9s\tremaining: 5.23s\n",
      "800:\tlearn: 0.1163095\ttotal: 20.9s\tremaining: 5.2s\n",
      "801:\tlearn: 0.1162929\ttotal: 21s\tremaining: 5.18s\n",
      "802:\tlearn: 0.1162746\ttotal: 21s\tremaining: 5.15s\n",
      "803:\tlearn: 0.1162620\ttotal: 21s\tremaining: 5.13s\n",
      "804:\tlearn: 0.1162444\ttotal: 21.1s\tremaining: 5.1s\n",
      "805:\tlearn: 0.1162243\ttotal: 21.1s\tremaining: 5.08s\n",
      "806:\tlearn: 0.1162089\ttotal: 21.1s\tremaining: 5.05s\n",
      "807:\tlearn: 0.1161922\ttotal: 21.2s\tremaining: 5.03s\n",
      "808:\tlearn: 0.1161779\ttotal: 21.2s\tremaining: 5s\n",
      "809:\tlearn: 0.1161580\ttotal: 21.2s\tremaining: 4.98s\n",
      "810:\tlearn: 0.1161412\ttotal: 21.3s\tremaining: 4.96s\n",
      "811:\tlearn: 0.1161233\ttotal: 21.3s\tremaining: 4.93s\n",
      "812:\tlearn: 0.1161037\ttotal: 21.3s\tremaining: 4.91s\n",
      "813:\tlearn: 0.1160680\ttotal: 21.4s\tremaining: 4.88s\n",
      "814:\tlearn: 0.1160483\ttotal: 21.4s\tremaining: 4.86s\n",
      "815:\tlearn: 0.1160327\ttotal: 21.4s\tremaining: 4.83s\n",
      "816:\tlearn: 0.1160151\ttotal: 21.5s\tremaining: 4.81s\n",
      "817:\tlearn: 0.1159964\ttotal: 21.5s\tremaining: 4.79s\n",
      "818:\tlearn: 0.1159818\ttotal: 21.5s\tremaining: 4.76s\n",
      "819:\tlearn: 0.1159712\ttotal: 21.6s\tremaining: 4.74s\n",
      "820:\tlearn: 0.1159567\ttotal: 21.6s\tremaining: 4.71s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821:\tlearn: 0.1159389\ttotal: 21.7s\tremaining: 4.69s\n",
      "822:\tlearn: 0.1159233\ttotal: 21.7s\tremaining: 4.66s\n",
      "823:\tlearn: 0.1159075\ttotal: 21.7s\tremaining: 4.64s\n",
      "824:\tlearn: 0.1158912\ttotal: 21.8s\tremaining: 4.61s\n",
      "825:\tlearn: 0.1158749\ttotal: 21.8s\tremaining: 4.59s\n",
      "826:\tlearn: 0.1158596\ttotal: 21.8s\tremaining: 4.56s\n",
      "827:\tlearn: 0.1158410\ttotal: 21.9s\tremaining: 4.54s\n",
      "828:\tlearn: 0.1158297\ttotal: 21.9s\tremaining: 4.51s\n",
      "829:\tlearn: 0.1158077\ttotal: 21.9s\tremaining: 4.49s\n",
      "830:\tlearn: 0.1157534\ttotal: 22s\tremaining: 4.46s\n",
      "831:\tlearn: 0.1157375\ttotal: 22s\tremaining: 4.44s\n",
      "832:\tlearn: 0.1157168\ttotal: 22s\tremaining: 4.41s\n",
      "833:\tlearn: 0.1157011\ttotal: 22.1s\tremaining: 4.39s\n",
      "834:\tlearn: 0.1156884\ttotal: 22.1s\tremaining: 4.36s\n",
      "835:\tlearn: 0.1156686\ttotal: 22.1s\tremaining: 4.34s\n",
      "836:\tlearn: 0.1156504\ttotal: 22.1s\tremaining: 4.31s\n",
      "837:\tlearn: 0.1156291\ttotal: 22.2s\tremaining: 4.29s\n",
      "838:\tlearn: 0.1156139\ttotal: 22.2s\tremaining: 4.26s\n",
      "839:\tlearn: 0.1156017\ttotal: 22.3s\tremaining: 4.24s\n",
      "840:\tlearn: 0.1155842\ttotal: 22.3s\tremaining: 4.22s\n",
      "841:\tlearn: 0.1155608\ttotal: 22.3s\tremaining: 4.19s\n",
      "842:\tlearn: 0.1155430\ttotal: 22.4s\tremaining: 4.17s\n",
      "843:\tlearn: 0.1155336\ttotal: 22.4s\tremaining: 4.14s\n",
      "844:\tlearn: 0.1155161\ttotal: 22.4s\tremaining: 4.12s\n",
      "845:\tlearn: 0.1154985\ttotal: 22.5s\tremaining: 4.09s\n",
      "846:\tlearn: 0.1154839\ttotal: 22.5s\tremaining: 4.07s\n",
      "847:\tlearn: 0.1154711\ttotal: 22.6s\tremaining: 4.04s\n",
      "848:\tlearn: 0.1154441\ttotal: 22.6s\tremaining: 4.02s\n",
      "849:\tlearn: 0.1154189\ttotal: 22.6s\tremaining: 3.99s\n",
      "850:\tlearn: 0.1154034\ttotal: 22.6s\tremaining: 3.96s\n",
      "851:\tlearn: 0.1153803\ttotal: 22.7s\tremaining: 3.94s\n",
      "852:\tlearn: 0.1153570\ttotal: 22.7s\tremaining: 3.91s\n",
      "853:\tlearn: 0.1153394\ttotal: 22.7s\tremaining: 3.89s\n",
      "854:\tlearn: 0.1153237\ttotal: 22.8s\tremaining: 3.86s\n",
      "855:\tlearn: 0.1153077\ttotal: 22.8s\tremaining: 3.83s\n",
      "856:\tlearn: 0.1152543\ttotal: 22.8s\tremaining: 3.81s\n",
      "857:\tlearn: 0.1152268\ttotal: 22.9s\tremaining: 3.78s\n",
      "858:\tlearn: 0.1152120\ttotal: 22.9s\tremaining: 3.76s\n",
      "859:\tlearn: 0.1151944\ttotal: 22.9s\tremaining: 3.73s\n",
      "860:\tlearn: 0.1151772\ttotal: 22.9s\tremaining: 3.7s\n",
      "861:\tlearn: 0.1151669\ttotal: 23s\tremaining: 3.67s\n",
      "862:\tlearn: 0.1151506\ttotal: 23s\tremaining: 3.65s\n",
      "863:\tlearn: 0.1151251\ttotal: 23s\tremaining: 3.62s\n",
      "864:\tlearn: 0.1151105\ttotal: 23.1s\tremaining: 3.6s\n",
      "865:\tlearn: 0.1150948\ttotal: 23.1s\tremaining: 3.57s\n",
      "866:\tlearn: 0.1150706\ttotal: 23.1s\tremaining: 3.55s\n",
      "867:\tlearn: 0.1150576\ttotal: 23.2s\tremaining: 3.52s\n",
      "868:\tlearn: 0.1150428\ttotal: 23.2s\tremaining: 3.5s\n",
      "869:\tlearn: 0.1150194\ttotal: 23.2s\tremaining: 3.47s\n",
      "870:\tlearn: 0.1150027\ttotal: 23.3s\tremaining: 3.44s\n",
      "871:\tlearn: 0.1149842\ttotal: 23.3s\tremaining: 3.42s\n",
      "872:\tlearn: 0.1149657\ttotal: 23.3s\tremaining: 3.39s\n",
      "873:\tlearn: 0.1149481\ttotal: 23.3s\tremaining: 3.37s\n",
      "874:\tlearn: 0.1149292\ttotal: 23.4s\tremaining: 3.34s\n",
      "875:\tlearn: 0.1149148\ttotal: 23.4s\tremaining: 3.31s\n",
      "876:\tlearn: 0.1148939\ttotal: 23.4s\tremaining: 3.28s\n",
      "877:\tlearn: 0.1148840\ttotal: 23.4s\tremaining: 3.26s\n",
      "878:\tlearn: 0.1148649\ttotal: 23.5s\tremaining: 3.23s\n",
      "879:\tlearn: 0.1148476\ttotal: 23.5s\tremaining: 3.2s\n",
      "880:\tlearn: 0.1148281\ttotal: 23.5s\tremaining: 3.18s\n",
      "881:\tlearn: 0.1148173\ttotal: 23.6s\tremaining: 3.15s\n",
      "882:\tlearn: 0.1148039\ttotal: 23.6s\tremaining: 3.12s\n",
      "883:\tlearn: 0.1147921\ttotal: 23.6s\tremaining: 3.1s\n",
      "884:\tlearn: 0.1147679\ttotal: 23.6s\tremaining: 3.07s\n",
      "885:\tlearn: 0.1147509\ttotal: 23.7s\tremaining: 3.04s\n",
      "886:\tlearn: 0.1147293\ttotal: 23.7s\tremaining: 3.02s\n",
      "887:\tlearn: 0.1147063\ttotal: 23.7s\tremaining: 2.99s\n",
      "888:\tlearn: 0.1146869\ttotal: 23.7s\tremaining: 2.96s\n",
      "889:\tlearn: 0.1146622\ttotal: 23.7s\tremaining: 2.93s\n",
      "890:\tlearn: 0.1146485\ttotal: 23.8s\tremaining: 2.91s\n",
      "891:\tlearn: 0.1146356\ttotal: 23.8s\tremaining: 2.88s\n",
      "892:\tlearn: 0.1146216\ttotal: 23.8s\tremaining: 2.85s\n",
      "893:\tlearn: 0.1146085\ttotal: 23.8s\tremaining: 2.82s\n",
      "894:\tlearn: 0.1145952\ttotal: 23.8s\tremaining: 2.8s\n",
      "895:\tlearn: 0.1145739\ttotal: 23.9s\tremaining: 2.77s\n",
      "896:\tlearn: 0.1145579\ttotal: 23.9s\tremaining: 2.74s\n",
      "897:\tlearn: 0.1145433\ttotal: 23.9s\tremaining: 2.71s\n",
      "898:\tlearn: 0.1145300\ttotal: 23.9s\tremaining: 2.69s\n",
      "899:\tlearn: 0.1145055\ttotal: 23.9s\tremaining: 2.66s\n",
      "900:\tlearn: 0.1144848\ttotal: 24s\tremaining: 2.63s\n",
      "901:\tlearn: 0.1144731\ttotal: 24s\tremaining: 2.6s\n",
      "902:\tlearn: 0.1144538\ttotal: 24s\tremaining: 2.58s\n",
      "903:\tlearn: 0.1144398\ttotal: 24s\tremaining: 2.55s\n",
      "904:\tlearn: 0.1144189\ttotal: 24s\tremaining: 2.52s\n",
      "905:\tlearn: 0.1143953\ttotal: 24s\tremaining: 2.5s\n",
      "906:\tlearn: 0.1143771\ttotal: 24.1s\tremaining: 2.47s\n",
      "907:\tlearn: 0.1143590\ttotal: 24.1s\tremaining: 2.44s\n",
      "908:\tlearn: 0.1143373\ttotal: 24.1s\tremaining: 2.41s\n",
      "909:\tlearn: 0.1143221\ttotal: 24.1s\tremaining: 2.39s\n",
      "910:\tlearn: 0.1143030\ttotal: 24.1s\tremaining: 2.36s\n",
      "911:\tlearn: 0.1142939\ttotal: 24.2s\tremaining: 2.33s\n",
      "912:\tlearn: 0.1142720\ttotal: 24.2s\tremaining: 2.31s\n",
      "913:\tlearn: 0.1142556\ttotal: 24.2s\tremaining: 2.28s\n",
      "914:\tlearn: 0.1142352\ttotal: 24.2s\tremaining: 2.25s\n",
      "915:\tlearn: 0.1142228\ttotal: 24.3s\tremaining: 2.23s\n",
      "916:\tlearn: 0.1141989\ttotal: 24.3s\tremaining: 2.2s\n",
      "917:\tlearn: 0.1141844\ttotal: 24.3s\tremaining: 2.17s\n",
      "918:\tlearn: 0.1141734\ttotal: 24.3s\tremaining: 2.14s\n",
      "919:\tlearn: 0.1141582\ttotal: 24.4s\tremaining: 2.12s\n",
      "920:\tlearn: 0.1141296\ttotal: 24.4s\tremaining: 2.09s\n",
      "921:\tlearn: 0.1141118\ttotal: 24.4s\tremaining: 2.06s\n",
      "922:\tlearn: 0.1140974\ttotal: 24.4s\tremaining: 2.04s\n",
      "923:\tlearn: 0.1140850\ttotal: 24.4s\tremaining: 2.01s\n",
      "924:\tlearn: 0.1140661\ttotal: 24.5s\tremaining: 1.98s\n",
      "925:\tlearn: 0.1140522\ttotal: 24.5s\tremaining: 1.96s\n",
      "926:\tlearn: 0.1140399\ttotal: 24.5s\tremaining: 1.93s\n",
      "927:\tlearn: 0.1140288\ttotal: 24.5s\tremaining: 1.9s\n",
      "928:\tlearn: 0.1140130\ttotal: 24.6s\tremaining: 1.88s\n",
      "929:\tlearn: 0.1140019\ttotal: 24.6s\tremaining: 1.85s\n",
      "930:\tlearn: 0.1139885\ttotal: 24.6s\tremaining: 1.82s\n",
      "931:\tlearn: 0.1139721\ttotal: 24.6s\tremaining: 1.8s\n",
      "932:\tlearn: 0.1139619\ttotal: 24.6s\tremaining: 1.77s\n",
      "933:\tlearn: 0.1139408\ttotal: 24.7s\tremaining: 1.74s\n",
      "934:\tlearn: 0.1138982\ttotal: 24.7s\tremaining: 1.72s\n",
      "935:\tlearn: 0.1138740\ttotal: 24.7s\tremaining: 1.69s\n",
      "936:\tlearn: 0.1138452\ttotal: 24.7s\tremaining: 1.66s\n",
      "937:\tlearn: 0.1138339\ttotal: 24.7s\tremaining: 1.64s\n",
      "938:\tlearn: 0.1138071\ttotal: 24.8s\tremaining: 1.61s\n",
      "939:\tlearn: 0.1137899\ttotal: 24.8s\tremaining: 1.58s\n",
      "940:\tlearn: 0.1137732\ttotal: 24.8s\tremaining: 1.55s\n",
      "941:\tlearn: 0.1137554\ttotal: 24.8s\tremaining: 1.53s\n",
      "942:\tlearn: 0.1137387\ttotal: 24.8s\tremaining: 1.5s\n",
      "943:\tlearn: 0.1137203\ttotal: 24.9s\tremaining: 1.47s\n",
      "944:\tlearn: 0.1136993\ttotal: 24.9s\tremaining: 1.45s\n",
      "945:\tlearn: 0.1136816\ttotal: 24.9s\tremaining: 1.42s\n",
      "946:\tlearn: 0.1136631\ttotal: 24.9s\tremaining: 1.39s\n",
      "947:\tlearn: 0.1136460\ttotal: 24.9s\tremaining: 1.37s\n",
      "948:\tlearn: 0.1136312\ttotal: 24.9s\tremaining: 1.34s\n",
      "949:\tlearn: 0.1136223\ttotal: 25s\tremaining: 1.31s\n",
      "950:\tlearn: 0.1136097\ttotal: 25s\tremaining: 1.29s\n",
      "951:\tlearn: 0.1135886\ttotal: 25s\tremaining: 1.26s\n",
      "952:\tlearn: 0.1135767\ttotal: 25s\tremaining: 1.23s\n",
      "953:\tlearn: 0.1135662\ttotal: 25s\tremaining: 1.21s\n",
      "954:\tlearn: 0.1135550\ttotal: 25.1s\tremaining: 1.18s\n",
      "955:\tlearn: 0.1135367\ttotal: 25.1s\tremaining: 1.15s\n",
      "956:\tlearn: 0.1135189\ttotal: 25.1s\tremaining: 1.13s\n",
      "957:\tlearn: 0.1135078\ttotal: 25.1s\tremaining: 1.1s\n",
      "958:\tlearn: 0.1134974\ttotal: 25.1s\tremaining: 1.07s\n",
      "959:\tlearn: 0.1134708\ttotal: 25.2s\tremaining: 1.05s\n",
      "960:\tlearn: 0.1134550\ttotal: 25.2s\tremaining: 1.02s\n",
      "961:\tlearn: 0.1134306\ttotal: 25.2s\tremaining: 996ms\n",
      "962:\tlearn: 0.1134136\ttotal: 25.2s\tremaining: 969ms\n",
      "963:\tlearn: 0.1133616\ttotal: 25.3s\tremaining: 943ms\n",
      "964:\tlearn: 0.1133439\ttotal: 25.3s\tremaining: 917ms\n",
      "965:\tlearn: 0.1133274\ttotal: 25.3s\tremaining: 890ms\n",
      "966:\tlearn: 0.1133102\ttotal: 25.3s\tremaining: 864ms\n",
      "967:\tlearn: 0.1132947\ttotal: 25.3s\tremaining: 837ms\n",
      "968:\tlearn: 0.1132842\ttotal: 25.3s\tremaining: 811ms\n",
      "969:\tlearn: 0.1132664\ttotal: 25.4s\tremaining: 784ms\n",
      "970:\tlearn: 0.1132514\ttotal: 25.4s\tremaining: 758ms\n",
      "971:\tlearn: 0.1132373\ttotal: 25.4s\tremaining: 732ms\n",
      "972:\tlearn: 0.1132152\ttotal: 25.4s\tremaining: 706ms\n",
      "973:\tlearn: 0.1132037\ttotal: 25.4s\tremaining: 679ms\n",
      "974:\tlearn: 0.1131503\ttotal: 25.5s\tremaining: 653ms\n",
      "975:\tlearn: 0.1131318\ttotal: 25.5s\tremaining: 627ms\n",
      "976:\tlearn: 0.1131187\ttotal: 25.5s\tremaining: 601ms\n",
      "977:\tlearn: 0.1131024\ttotal: 25.5s\tremaining: 574ms\n",
      "978:\tlearn: 0.1130879\ttotal: 25.5s\tremaining: 548ms\n",
      "979:\tlearn: 0.1130733\ttotal: 25.6s\tremaining: 522ms\n",
      "980:\tlearn: 0.1130642\ttotal: 25.6s\tremaining: 496ms\n",
      "981:\tlearn: 0.1130425\ttotal: 25.6s\tremaining: 469ms\n",
      "982:\tlearn: 0.1130301\ttotal: 25.6s\tremaining: 443ms\n",
      "983:\tlearn: 0.1130131\ttotal: 25.6s\tremaining: 417ms\n",
      "984:\tlearn: 0.1129954\ttotal: 25.7s\tremaining: 391ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985:\tlearn: 0.1129805\ttotal: 25.7s\tremaining: 365ms\n",
      "986:\tlearn: 0.1129678\ttotal: 25.7s\tremaining: 338ms\n",
      "987:\tlearn: 0.1129553\ttotal: 25.7s\tremaining: 312ms\n",
      "988:\tlearn: 0.1129371\ttotal: 25.7s\tremaining: 286ms\n",
      "989:\tlearn: 0.1129221\ttotal: 25.8s\tremaining: 260ms\n",
      "990:\tlearn: 0.1128970\ttotal: 25.8s\tremaining: 234ms\n",
      "991:\tlearn: 0.1128758\ttotal: 25.8s\tremaining: 208ms\n",
      "992:\tlearn: 0.1128599\ttotal: 25.8s\tremaining: 182ms\n",
      "993:\tlearn: 0.1128466\ttotal: 25.8s\tremaining: 156ms\n",
      "994:\tlearn: 0.1128266\ttotal: 25.8s\tremaining: 130ms\n",
      "995:\tlearn: 0.1128172\ttotal: 25.9s\tremaining: 104ms\n",
      "996:\tlearn: 0.1128044\ttotal: 25.9s\tremaining: 77.9ms\n",
      "997:\tlearn: 0.1127817\ttotal: 25.9s\tremaining: 51.9ms\n",
      "998:\tlearn: 0.1127738\ttotal: 25.9s\tremaining: 26ms\n",
      "999:\tlearn: 0.1127486\ttotal: 26s\tremaining: 0us\n",
      "Train\n",
      "Accuracy: 0.9578295644779847\n",
      "Confusion Matrix:\n",
      " [[18460   365]\n",
      " [ 1222 17586]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     18825\n",
      "         1.0       0.98      0.94      0.96     18808\n",
      "\n",
      "    accuracy                           0.96     37633\n",
      "   macro avg       0.96      0.96      0.96     37633\n",
      "weighted avg       0.96      0.96      0.96     37633\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9542942176870748\n",
      "Confusion Matrix:\n",
      " [[2266   57]\n",
      " [ 158 2223]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95      2323\n",
      "         1.0       0.97      0.93      0.95      2381\n",
      "\n",
      "    accuracy                           0.95      4704\n",
      "   macro avg       0.95      0.95      0.95      4704\n",
      "weighted avg       0.96      0.95      0.95      4704\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.9566418703506907\n",
      "Confusion Matrix:\n",
      " [[2328   45]\n",
      " [ 159 2173]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      2373\n",
      "         1.0       0.98      0.93      0.96      2332\n",
      "\n",
      "    accuracy                           0.96      4705\n",
      "   macro avg       0.96      0.96      0.96      4705\n",
      "weighted avg       0.96      0.96      0.96      4705\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9248983314963324\n",
      "Confusion Matrix:\n",
      " [[23054   467]\n",
      " [ 1509  1281]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     23521\n",
      "         1.0       0.73      0.46      0.56      2790\n",
      "\n",
      "    accuracy                           0.92     26311\n",
      "   macro avg       0.84      0.72      0.76     26311\n",
      "weighted avg       0.92      0.92      0.92     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize the CatBoostClassifier\n",
    "cat = CatBoostClassifier(iterations=1000, learning_rate=0.01, depth=6)\n",
    "\n",
    "# Fit the model\n",
    "cat.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = cat.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = cat.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = cat.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "#X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "y_pred_2017 = cat.predict(X_test_2017)\n",
    "\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 0.9967581643770096\n",
      "Confusion Matrix:\n",
      " [[18791    34]\n",
      " [   88 18720]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     18825\n",
      "         1.0       1.00      1.00      1.00     18808\n",
      "\n",
      "    accuracy                           1.00     37633\n",
      "   macro avg       1.00      1.00      1.00     37633\n",
      "weighted avg       1.00      1.00      1.00     37633\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9553571428571429\n",
      "Confusion Matrix:\n",
      " [[2249   74]\n",
      " [ 136 2245]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96      2323\n",
      "         1.0       0.97      0.94      0.96      2381\n",
      "\n",
      "    accuracy                           0.96      4704\n",
      "   macro avg       0.96      0.96      0.96      4704\n",
      "weighted avg       0.96      0.96      0.96      4704\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.9583421891604675\n",
      "Confusion Matrix:\n",
      " [[2318   55]\n",
      " [ 141 2191]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      2373\n",
      "         1.0       0.98      0.94      0.96      2332\n",
      "\n",
      "    accuracy                           0.96      4705\n",
      "   macro avg       0.96      0.96      0.96      4705\n",
      "weighted avg       0.96      0.96      0.96      4705\n",
      "\n",
      "\n",
      "[[23443    78]\n",
      " [  829  1961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98     23521\n",
      "         1.0       0.96      0.70      0.81      2790\n",
      "\n",
      "    accuracy                           0.97     26311\n",
      "   macro avg       0.96      0.85      0.90     26311\n",
      "weighted avg       0.97      0.97      0.96     26311\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9800083615217969\n",
      "Confusion Matrix:\n",
      " [[23358   163]\n",
      " [  363  2427]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99     23521\n",
      "         1.0       0.94      0.87      0.90      2790\n",
      "\n",
      "    accuracy                           0.98     26311\n",
      "   macro avg       0.96      0.93      0.95     26311\n",
      "weighted avg       0.98      0.98      0.98     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(n_estimators=1000, learning_rate=0.01)),\n",
    "]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = stacking_clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = stacking_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "#X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "y_pred_2017 = stacking_clf.predict(X_test_2017)\n",
    "\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'smoker', 'sex', 'coronary_heart_disease', 'weight', 'bmi',\n",
      "       'height', 'hypertension', 'heart_condition', 'cancer',\n",
      "       'family_history_diabetes', 'doctor_recommend_exercise',\n",
      "       'moderate_physical_activity', 'vigorous_physical_activity',\n",
      "       'alcohol_past_year', 'high_blood_pressure_prescription', 'medicated',\n",
      "       'prediabetes', 'insulin', 'stroke', 'cholesterol', 'region_Midwest',\n",
      "       'region_Northwest', 'region_South'],\n",
      "      dtype='object')\n",
      "Index(['age', 'smoker', 'sex', 'coronary_heart_disease', 'weight', 'bmi',\n",
      "       'height', 'hypertension', 'heart_condition', 'cancer',\n",
      "       'family_history_diabetes', 'doctor_recommend_exercise',\n",
      "       'moderate_physical_activity', 'vigorous_physical_activity',\n",
      "       'alcohol_past_year', 'high_blood_pressure_prescription', 'medicated',\n",
      "       'prediabetes', 'insulin', 'stroke', 'cholesterol', 'region_Midwest',\n",
      "       'region_Northwest', 'region_South'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_test.columns)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     14\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     16\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1532\u001b[0m     params,\n\u001b[0;32m   1533\u001b[0m     train_dmatrix,\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1535\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1536\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1537\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1538\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1539\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1540\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1541\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1542\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1543\u001b[0m )\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2102\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2103\u001b[0m         )\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'scale_pos_weight': [1, 10, 20]  # Adjust this based on the imbalance\n",
    "}\n",
    "\n",
    "model = XGBClassifier()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='precision', cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = best_model.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\15184\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install lightgbm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightGBM version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lgb\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"LightGBM version:\", lgb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15184\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665694785366072 0.6543052146339281\n"
     ]
    }
   ],
   "source": [
    "m = 26311\n",
    "p0 = 0.94\n",
    "p1 = 0.66\n",
    "p_ = p1+ 1.95*((p1*(1-p1)/m)**0.5)\n",
    "p__ = p1-1.95*((p1*(1-p1)/m)**0.5)\n",
    "\n",
    "print(p_,p__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = xgb_clf.predict(X_val)\n",
    "\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "report = classification_report((y_val, y_val_pred, output_dict=True)\n",
    "precision_0 = report['0.0']['precision']\n",
    "recall_0 = report['0.0']['recall']\n",
    "precision_1 = report['1.0']['precision']\n",
    "recall_1 = report['1.0']['recall']\n",
    "\n",
    "y_pred_2017 = xgb_clf.predict(X_test_2017)\n",
    "\n",
    "report_2017 = classification_report(y_test_2017, y_pred_2017, output_dict=True)\n",
    "precision_0_2017 = report_2017['0.0']['precision']\n",
    "recall_0_2017 = report_2017['0.0']['recall']\n",
    "precision_1_2017 = report_2017['1.0']['precision']\n",
    "recall_1_2017 = report_2017['1.0']['recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 Performance Evaluation:\n",
      "Observed Precision: 0.9354\n",
      "Null Hypothesis Precision (p0): 0.9451\n",
      "Z-Statistic: -6.9477\n",
      "P-Value: 0.0000\n",
      "Reject the null hypothesis: The model's precision for class 0.0 is significantly different from the expected value.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Class 1.0 Performance Evaluation:\n",
      "Observed Precision: 0.6569\n",
      "Null Hypothesis Precision (p0): 0.9560\n",
      "Z-Statistic: -236.4810\n",
      "P-Value: 0.0000\n",
      "Reject the null hypothesis: The model's precision for class 1.0 is significantly different from the expected value.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Define null hypothesis values (expected precision under H0)\n",
    "p0_0 = precision_0  # Expected precision for class 0.0 (you can adjust this)\n",
    "p0_1 = precision_1  # Expected precision for class 1.0 (you can adjust this)\n",
    "\n",
    "# Get the number of samples for the precision calculations\n",
    "n = len(y_pred_2017)  # Total number of samples\n",
    "\n",
    "# 1. Evaluate the performance for class 0.0\n",
    "observed_precision_0 = precision_0_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 0.0\n",
    "Z_0 = (observed_precision_0 - p0_0) / np.sqrt((p0_0 * (1 - p0_0)) / n)\n",
    "\n",
    "# Calculate p-value for class 0.0\n",
    "p_value_0 = 2 * (1 - stats.norm.cdf(np.abs(Z_0)))\n",
    "\n",
    "# Evaluate the hypothesis for class 0.0\n",
    "print(f\"Class 0.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_0:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_0:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_0:.4f}\")\n",
    "print(f\"P-Value: {p_value_0:.4f}\")\n",
    "\n",
    "if p_value_0 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 0.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 0.0.\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity\n",
    "\n",
    "# 2. Evaluate the performance for class 1.0\n",
    "observed_precision_1 = precision_1_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 1.0\n",
    "Z_1 = (observed_precision_1 - p0_1) / np.sqrt((p0_1 * (1 - p0_1)) / n)\n",
    "\n",
    "# Calculate p-value for class 1.0\n",
    "p_value_1 = 2 * (1 - stats.norm.cdf(np.abs(Z_1)))\n",
    "\n",
    "# Evaluate the hypothesis for class 1.0\n",
    "print(f\"Class 1.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_1:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_1:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_1:.4f}\")\n",
    "print(f\"P-Value: {p_value_1:.4f}\")\n",
    "\n",
    "if p_value_1 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 1.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 1.0.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.36085\n",
      "[1]\tvalidation_0-logloss:0.35843\n",
      "[2]\tvalidation_0-logloss:0.35608\n",
      "[3]\tvalidation_0-logloss:0.35378\n",
      "[4]\tvalidation_0-logloss:0.35157\n",
      "[5]\tvalidation_0-logloss:0.34943\n",
      "[6]\tvalidation_0-logloss:0.34730\n",
      "[7]\tvalidation_0-logloss:0.34523\n",
      "[8]\tvalidation_0-logloss:0.34323\n",
      "[9]\tvalidation_0-logloss:0.34126\n",
      "[10]\tvalidation_0-logloss:0.33935\n",
      "[11]\tvalidation_0-logloss:0.33744\n",
      "[12]\tvalidation_0-logloss:0.33564\n",
      "[13]\tvalidation_0-logloss:0.33382\n",
      "[14]\tvalidation_0-logloss:0.33207\n",
      "[15]\tvalidation_0-logloss:0.33033\n",
      "[16]\tvalidation_0-logloss:0.32865\n",
      "[17]\tvalidation_0-logloss:0.32697\n",
      "[18]\tvalidation_0-logloss:0.32536\n",
      "[19]\tvalidation_0-logloss:0.32378\n",
      "[20]\tvalidation_0-logloss:0.32221\n",
      "[21]\tvalidation_0-logloss:0.32067\n",
      "[22]\tvalidation_0-logloss:0.31912\n",
      "[23]\tvalidation_0-logloss:0.31766\n",
      "[24]\tvalidation_0-logloss:0.31620\n",
      "[25]\tvalidation_0-logloss:0.31479\n",
      "[26]\tvalidation_0-logloss:0.31338\n",
      "[27]\tvalidation_0-logloss:0.31200\n",
      "[28]\tvalidation_0-logloss:0.31066\n",
      "[29]\tvalidation_0-logloss:0.30932\n",
      "[30]\tvalidation_0-logloss:0.30803\n",
      "[31]\tvalidation_0-logloss:0.30674\n",
      "[32]\tvalidation_0-logloss:0.30546\n",
      "[33]\tvalidation_0-logloss:0.30422\n",
      "[34]\tvalidation_0-logloss:0.30296\n",
      "[35]\tvalidation_0-logloss:0.30176\n",
      "[36]\tvalidation_0-logloss:0.30055\n",
      "[37]\tvalidation_0-logloss:0.29940\n",
      "[38]\tvalidation_0-logloss:0.29825\n",
      "[39]\tvalidation_0-logloss:0.29711\n",
      "[40]\tvalidation_0-logloss:0.29600\n",
      "[41]\tvalidation_0-logloss:0.29489\n",
      "[42]\tvalidation_0-logloss:0.29382\n",
      "[43]\tvalidation_0-logloss:0.29276\n",
      "[44]\tvalidation_0-logloss:0.29170\n",
      "[45]\tvalidation_0-logloss:0.29068\n",
      "[46]\tvalidation_0-logloss:0.28966\n",
      "[47]\tvalidation_0-logloss:0.28866\n",
      "[48]\tvalidation_0-logloss:0.28767\n",
      "[49]\tvalidation_0-logloss:0.28670\n",
      "[50]\tvalidation_0-logloss:0.28574\n",
      "[51]\tvalidation_0-logloss:0.28479\n",
      "[52]\tvalidation_0-logloss:0.28386\n",
      "[53]\tvalidation_0-logloss:0.28295\n",
      "[54]\tvalidation_0-logloss:0.28205\n",
      "[55]\tvalidation_0-logloss:0.28115\n",
      "[56]\tvalidation_0-logloss:0.28028\n",
      "[57]\tvalidation_0-logloss:0.27941\n",
      "[58]\tvalidation_0-logloss:0.27856\n",
      "[59]\tvalidation_0-logloss:0.27773\n",
      "[60]\tvalidation_0-logloss:0.27691\n",
      "[61]\tvalidation_0-logloss:0.27610\n",
      "[62]\tvalidation_0-logloss:0.27528\n",
      "[63]\tvalidation_0-logloss:0.27449\n",
      "[64]\tvalidation_0-logloss:0.27371\n",
      "[65]\tvalidation_0-logloss:0.27292\n",
      "[66]\tvalidation_0-logloss:0.27215\n",
      "[67]\tvalidation_0-logloss:0.27140\n",
      "[68]\tvalidation_0-logloss:0.27067\n",
      "[69]\tvalidation_0-logloss:0.26995\n",
      "[70]\tvalidation_0-logloss:0.26924\n",
      "[71]\tvalidation_0-logloss:0.26854\n",
      "[72]\tvalidation_0-logloss:0.26784\n",
      "[73]\tvalidation_0-logloss:0.26717\n",
      "[74]\tvalidation_0-logloss:0.26650\n",
      "[75]\tvalidation_0-logloss:0.26585\n",
      "[76]\tvalidation_0-logloss:0.26518\n",
      "[77]\tvalidation_0-logloss:0.26452\n",
      "[78]\tvalidation_0-logloss:0.26388\n",
      "[79]\tvalidation_0-logloss:0.26325\n",
      "[80]\tvalidation_0-logloss:0.26265\n",
      "[81]\tvalidation_0-logloss:0.26205\n",
      "[82]\tvalidation_0-logloss:0.26145\n",
      "[83]\tvalidation_0-logloss:0.26087\n",
      "[84]\tvalidation_0-logloss:0.26029\n",
      "[85]\tvalidation_0-logloss:0.25972\n",
      "[86]\tvalidation_0-logloss:0.25914\n",
      "[87]\tvalidation_0-logloss:0.25858\n",
      "[88]\tvalidation_0-logloss:0.25802\n",
      "[89]\tvalidation_0-logloss:0.25748\n",
      "[90]\tvalidation_0-logloss:0.25695\n",
      "[91]\tvalidation_0-logloss:0.25641\n",
      "[92]\tvalidation_0-logloss:0.25588\n",
      "[93]\tvalidation_0-logloss:0.25536\n",
      "[94]\tvalidation_0-logloss:0.25485\n",
      "[95]\tvalidation_0-logloss:0.25434\n",
      "[96]\tvalidation_0-logloss:0.25384\n",
      "[97]\tvalidation_0-logloss:0.25335\n",
      "[98]\tvalidation_0-logloss:0.25287\n",
      "[99]\tvalidation_0-logloss:0.25239\n",
      "[100]\tvalidation_0-logloss:0.25192\n",
      "[101]\tvalidation_0-logloss:0.25146\n",
      "[102]\tvalidation_0-logloss:0.25100\n",
      "[103]\tvalidation_0-logloss:0.25056\n",
      "[104]\tvalidation_0-logloss:0.25010\n",
      "[105]\tvalidation_0-logloss:0.24967\n",
      "[106]\tvalidation_0-logloss:0.24924\n",
      "[107]\tvalidation_0-logloss:0.24882\n",
      "[108]\tvalidation_0-logloss:0.24839\n",
      "[109]\tvalidation_0-logloss:0.24798\n",
      "[110]\tvalidation_0-logloss:0.24756\n",
      "[111]\tvalidation_0-logloss:0.24715\n",
      "[112]\tvalidation_0-logloss:0.24675\n",
      "[113]\tvalidation_0-logloss:0.24634\n",
      "[114]\tvalidation_0-logloss:0.24595\n",
      "[115]\tvalidation_0-logloss:0.24557\n",
      "[116]\tvalidation_0-logloss:0.24518\n",
      "[117]\tvalidation_0-logloss:0.24482\n",
      "[118]\tvalidation_0-logloss:0.24445\n",
      "[119]\tvalidation_0-logloss:0.24408\n",
      "[120]\tvalidation_0-logloss:0.24371\n",
      "[121]\tvalidation_0-logloss:0.24336\n",
      "[122]\tvalidation_0-logloss:0.24301\n",
      "[123]\tvalidation_0-logloss:0.24267\n",
      "[124]\tvalidation_0-logloss:0.24232\n",
      "[125]\tvalidation_0-logloss:0.24199\n",
      "[126]\tvalidation_0-logloss:0.24165\n",
      "[127]\tvalidation_0-logloss:0.24131\n",
      "[128]\tvalidation_0-logloss:0.24098\n",
      "[129]\tvalidation_0-logloss:0.24065\n",
      "[130]\tvalidation_0-logloss:0.24034\n",
      "[131]\tvalidation_0-logloss:0.24000\n",
      "[132]\tvalidation_0-logloss:0.23970\n",
      "[133]\tvalidation_0-logloss:0.23937\n",
      "[134]\tvalidation_0-logloss:0.23907\n",
      "[135]\tvalidation_0-logloss:0.23874\n",
      "[136]\tvalidation_0-logloss:0.23843\n",
      "[137]\tvalidation_0-logloss:0.23813\n",
      "[138]\tvalidation_0-logloss:0.23783\n",
      "[139]\tvalidation_0-logloss:0.23753\n",
      "[140]\tvalidation_0-logloss:0.23723\n",
      "[141]\tvalidation_0-logloss:0.23696\n",
      "[142]\tvalidation_0-logloss:0.23665\n",
      "[143]\tvalidation_0-logloss:0.23635\n",
      "[144]\tvalidation_0-logloss:0.23605\n",
      "[145]\tvalidation_0-logloss:0.23578\n",
      "[146]\tvalidation_0-logloss:0.23548\n",
      "[147]\tvalidation_0-logloss:0.23520\n",
      "[148]\tvalidation_0-logloss:0.23491\n",
      "[149]\tvalidation_0-logloss:0.23465\n",
      "[150]\tvalidation_0-logloss:0.23437\n",
      "[151]\tvalidation_0-logloss:0.23414\n",
      "[152]\tvalidation_0-logloss:0.23387\n",
      "[153]\tvalidation_0-logloss:0.23361\n",
      "[154]\tvalidation_0-logloss:0.23335\n",
      "[155]\tvalidation_0-logloss:0.23311\n",
      "[156]\tvalidation_0-logloss:0.23285\n",
      "[157]\tvalidation_0-logloss:0.23261\n",
      "[158]\tvalidation_0-logloss:0.23236\n",
      "[159]\tvalidation_0-logloss:0.23211\n",
      "[160]\tvalidation_0-logloss:0.23189\n",
      "[161]\tvalidation_0-logloss:0.23166\n",
      "[162]\tvalidation_0-logloss:0.23143\n",
      "[163]\tvalidation_0-logloss:0.23120\n",
      "[164]\tvalidation_0-logloss:0.23099\n",
      "[165]\tvalidation_0-logloss:0.23075\n",
      "[166]\tvalidation_0-logloss:0.23053\n",
      "[167]\tvalidation_0-logloss:0.23029\n",
      "[168]\tvalidation_0-logloss:0.23010\n",
      "[169]\tvalidation_0-logloss:0.22988\n",
      "[170]\tvalidation_0-logloss:0.22966\n",
      "[171]\tvalidation_0-logloss:0.22947\n",
      "[172]\tvalidation_0-logloss:0.22925\n",
      "[173]\tvalidation_0-logloss:0.22905\n",
      "[174]\tvalidation_0-logloss:0.22883\n",
      "[175]\tvalidation_0-logloss:0.22862\n",
      "[176]\tvalidation_0-logloss:0.22843\n",
      "[177]\tvalidation_0-logloss:0.22825\n",
      "[178]\tvalidation_0-logloss:0.22807\n",
      "[179]\tvalidation_0-logloss:0.22790\n",
      "[180]\tvalidation_0-logloss:0.22770\n",
      "[181]\tvalidation_0-logloss:0.22752\n",
      "[182]\tvalidation_0-logloss:0.22735\n",
      "[183]\tvalidation_0-logloss:0.22718\n",
      "[184]\tvalidation_0-logloss:0.22698\n",
      "[185]\tvalidation_0-logloss:0.22682\n",
      "[186]\tvalidation_0-logloss:0.22666\n",
      "[187]\tvalidation_0-logloss:0.22650\n",
      "[188]\tvalidation_0-logloss:0.22631\n",
      "[189]\tvalidation_0-logloss:0.22616\n",
      "[190]\tvalidation_0-logloss:0.22600\n",
      "[191]\tvalidation_0-logloss:0.22586\n",
      "[192]\tvalidation_0-logloss:0.22569\n",
      "[193]\tvalidation_0-logloss:0.22555\n",
      "[194]\tvalidation_0-logloss:0.22538\n",
      "[195]\tvalidation_0-logloss:0.22525\n",
      "[196]\tvalidation_0-logloss:0.22510\n",
      "[197]\tvalidation_0-logloss:0.22498\n",
      "[198]\tvalidation_0-logloss:0.22483\n",
      "[199]\tvalidation_0-logloss:0.22470\n",
      "[200]\tvalidation_0-logloss:0.22456\n",
      "[201]\tvalidation_0-logloss:0.22441\n",
      "[202]\tvalidation_0-logloss:0.22428\n",
      "[203]\tvalidation_0-logloss:0.22411\n",
      "[204]\tvalidation_0-logloss:0.22397\n",
      "[205]\tvalidation_0-logloss:0.22382\n",
      "[206]\tvalidation_0-logloss:0.22372\n",
      "[207]\tvalidation_0-logloss:0.22356\n",
      "[208]\tvalidation_0-logloss:0.22343\n",
      "[209]\tvalidation_0-logloss:0.22330\n",
      "[210]\tvalidation_0-logloss:0.22316\n",
      "[211]\tvalidation_0-logloss:0.22305\n",
      "[212]\tvalidation_0-logloss:0.22295\n",
      "[213]\tvalidation_0-logloss:0.22283\n",
      "[214]\tvalidation_0-logloss:0.22269\n",
      "[215]\tvalidation_0-logloss:0.22258\n",
      "[216]\tvalidation_0-logloss:0.22245\n",
      "[217]\tvalidation_0-logloss:0.22233\n",
      "[218]\tvalidation_0-logloss:0.22222\n",
      "[219]\tvalidation_0-logloss:0.22211\n",
      "[220]\tvalidation_0-logloss:0.22202\n",
      "[221]\tvalidation_0-logloss:0.22191\n",
      "[222]\tvalidation_0-logloss:0.22177\n",
      "[223]\tvalidation_0-logloss:0.22163\n",
      "[224]\tvalidation_0-logloss:0.22152\n",
      "[225]\tvalidation_0-logloss:0.22139\n",
      "[226]\tvalidation_0-logloss:0.22127\n",
      "[227]\tvalidation_0-logloss:0.22117\n",
      "[228]\tvalidation_0-logloss:0.22105\n",
      "[229]\tvalidation_0-logloss:0.22093\n",
      "[230]\tvalidation_0-logloss:0.22083\n",
      "[231]\tvalidation_0-logloss:0.22072\n",
      "[232]\tvalidation_0-logloss:0.22061\n",
      "[233]\tvalidation_0-logloss:0.22052\n",
      "[234]\tvalidation_0-logloss:0.22042\n",
      "[235]\tvalidation_0-logloss:0.22032\n",
      "[236]\tvalidation_0-logloss:0.22019\n",
      "[237]\tvalidation_0-logloss:0.22009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238]\tvalidation_0-logloss:0.21997\n",
      "[239]\tvalidation_0-logloss:0.21987\n",
      "[240]\tvalidation_0-logloss:0.21976\n",
      "[241]\tvalidation_0-logloss:0.21964\n",
      "[242]\tvalidation_0-logloss:0.21953\n",
      "[243]\tvalidation_0-logloss:0.21944\n",
      "[244]\tvalidation_0-logloss:0.21936\n",
      "[245]\tvalidation_0-logloss:0.21927\n",
      "[246]\tvalidation_0-logloss:0.21919\n",
      "[247]\tvalidation_0-logloss:0.21908\n",
      "[248]\tvalidation_0-logloss:0.21898\n",
      "[249]\tvalidation_0-logloss:0.21888\n",
      "[250]\tvalidation_0-logloss:0.21880\n",
      "[251]\tvalidation_0-logloss:0.21871\n",
      "[252]\tvalidation_0-logloss:0.21861\n",
      "[253]\tvalidation_0-logloss:0.21853\n",
      "[254]\tvalidation_0-logloss:0.21845\n",
      "[255]\tvalidation_0-logloss:0.21838\n",
      "[256]\tvalidation_0-logloss:0.21830\n",
      "[257]\tvalidation_0-logloss:0.21821\n",
      "[258]\tvalidation_0-logloss:0.21811\n",
      "[259]\tvalidation_0-logloss:0.21804\n",
      "[260]\tvalidation_0-logloss:0.21796\n",
      "[261]\tvalidation_0-logloss:0.21788\n",
      "[262]\tvalidation_0-logloss:0.21780\n",
      "[263]\tvalidation_0-logloss:0.21772\n",
      "[264]\tvalidation_0-logloss:0.21765\n",
      "[265]\tvalidation_0-logloss:0.21756\n",
      "[266]\tvalidation_0-logloss:0.21748\n",
      "[267]\tvalidation_0-logloss:0.21740\n",
      "[268]\tvalidation_0-logloss:0.21731\n",
      "[269]\tvalidation_0-logloss:0.21721\n",
      "[270]\tvalidation_0-logloss:0.21713\n",
      "[271]\tvalidation_0-logloss:0.21706\n",
      "[272]\tvalidation_0-logloss:0.21696\n",
      "[273]\tvalidation_0-logloss:0.21691\n",
      "[274]\tvalidation_0-logloss:0.21684\n",
      "[275]\tvalidation_0-logloss:0.21677\n",
      "[276]\tvalidation_0-logloss:0.21669\n",
      "[277]\tvalidation_0-logloss:0.21662\n",
      "[278]\tvalidation_0-logloss:0.21655\n",
      "[279]\tvalidation_0-logloss:0.21647\n",
      "[280]\tvalidation_0-logloss:0.21640\n",
      "[281]\tvalidation_0-logloss:0.21632\n",
      "[282]\tvalidation_0-logloss:0.21626\n",
      "[283]\tvalidation_0-logloss:0.21619\n",
      "[284]\tvalidation_0-logloss:0.21613\n",
      "[285]\tvalidation_0-logloss:0.21607\n",
      "[286]\tvalidation_0-logloss:0.21600\n",
      "[287]\tvalidation_0-logloss:0.21594\n",
      "[288]\tvalidation_0-logloss:0.21587\n",
      "[289]\tvalidation_0-logloss:0.21581\n",
      "[290]\tvalidation_0-logloss:0.21574\n",
      "[291]\tvalidation_0-logloss:0.21568\n",
      "[292]\tvalidation_0-logloss:0.21562\n",
      "[293]\tvalidation_0-logloss:0.21557\n",
      "[294]\tvalidation_0-logloss:0.21551\n",
      "[295]\tvalidation_0-logloss:0.21546\n",
      "[296]\tvalidation_0-logloss:0.21539\n",
      "[297]\tvalidation_0-logloss:0.21534\n",
      "[298]\tvalidation_0-logloss:0.21528\n",
      "[299]\tvalidation_0-logloss:0.21524\n",
      "[300]\tvalidation_0-logloss:0.21519\n",
      "[301]\tvalidation_0-logloss:0.21514\n",
      "[302]\tvalidation_0-logloss:0.21508\n",
      "[303]\tvalidation_0-logloss:0.21504\n",
      "[304]\tvalidation_0-logloss:0.21499\n",
      "[305]\tvalidation_0-logloss:0.21495\n",
      "[306]\tvalidation_0-logloss:0.21490\n",
      "[307]\tvalidation_0-logloss:0.21484\n",
      "[308]\tvalidation_0-logloss:0.21479\n",
      "[309]\tvalidation_0-logloss:0.21474\n",
      "[310]\tvalidation_0-logloss:0.21470\n",
      "[311]\tvalidation_0-logloss:0.21465\n",
      "[312]\tvalidation_0-logloss:0.21462\n",
      "[313]\tvalidation_0-logloss:0.21457\n",
      "[314]\tvalidation_0-logloss:0.21452\n",
      "[315]\tvalidation_0-logloss:0.21448\n",
      "[316]\tvalidation_0-logloss:0.21442\n",
      "[317]\tvalidation_0-logloss:0.21439\n",
      "[318]\tvalidation_0-logloss:0.21434\n",
      "[319]\tvalidation_0-logloss:0.21430\n",
      "[320]\tvalidation_0-logloss:0.21427\n",
      "[321]\tvalidation_0-logloss:0.21422\n",
      "[322]\tvalidation_0-logloss:0.21418\n",
      "[323]\tvalidation_0-logloss:0.21412\n",
      "[324]\tvalidation_0-logloss:0.21409\n",
      "[325]\tvalidation_0-logloss:0.21405\n",
      "[326]\tvalidation_0-logloss:0.21401\n",
      "[327]\tvalidation_0-logloss:0.21397\n",
      "[328]\tvalidation_0-logloss:0.21393\n",
      "[329]\tvalidation_0-logloss:0.21389\n",
      "[330]\tvalidation_0-logloss:0.21383\n",
      "[331]\tvalidation_0-logloss:0.21379\n",
      "[332]\tvalidation_0-logloss:0.21375\n",
      "[333]\tvalidation_0-logloss:0.21370\n",
      "[334]\tvalidation_0-logloss:0.21366\n",
      "[335]\tvalidation_0-logloss:0.21363\n",
      "[336]\tvalidation_0-logloss:0.21357\n",
      "[337]\tvalidation_0-logloss:0.21353\n",
      "[338]\tvalidation_0-logloss:0.21350\n",
      "[339]\tvalidation_0-logloss:0.21347\n",
      "[340]\tvalidation_0-logloss:0.21341\n",
      "[341]\tvalidation_0-logloss:0.21336\n",
      "[342]\tvalidation_0-logloss:0.21332\n",
      "[343]\tvalidation_0-logloss:0.21329\n",
      "[344]\tvalidation_0-logloss:0.21324\n",
      "[345]\tvalidation_0-logloss:0.21321\n",
      "[346]\tvalidation_0-logloss:0.21317\n",
      "[347]\tvalidation_0-logloss:0.21313\n",
      "[348]\tvalidation_0-logloss:0.21310\n",
      "[349]\tvalidation_0-logloss:0.21306\n",
      "[350]\tvalidation_0-logloss:0.21302\n",
      "[351]\tvalidation_0-logloss:0.21300\n",
      "[352]\tvalidation_0-logloss:0.21296\n",
      "[353]\tvalidation_0-logloss:0.21293\n",
      "[354]\tvalidation_0-logloss:0.21289\n",
      "[355]\tvalidation_0-logloss:0.21286\n",
      "[356]\tvalidation_0-logloss:0.21282\n",
      "[357]\tvalidation_0-logloss:0.21279\n",
      "[358]\tvalidation_0-logloss:0.21275\n",
      "[359]\tvalidation_0-logloss:0.21272\n",
      "[360]\tvalidation_0-logloss:0.21269\n",
      "[361]\tvalidation_0-logloss:0.21266\n",
      "[362]\tvalidation_0-logloss:0.21263\n",
      "[363]\tvalidation_0-logloss:0.21261\n",
      "[364]\tvalidation_0-logloss:0.21258\n",
      "[365]\tvalidation_0-logloss:0.21256\n",
      "[366]\tvalidation_0-logloss:0.21253\n",
      "[367]\tvalidation_0-logloss:0.21251\n",
      "[368]\tvalidation_0-logloss:0.21248\n",
      "[369]\tvalidation_0-logloss:0.21246\n",
      "[370]\tvalidation_0-logloss:0.21242\n",
      "[371]\tvalidation_0-logloss:0.21240\n",
      "[372]\tvalidation_0-logloss:0.21239\n",
      "[373]\tvalidation_0-logloss:0.21237\n",
      "[374]\tvalidation_0-logloss:0.21234\n",
      "[375]\tvalidation_0-logloss:0.21233\n",
      "[376]\tvalidation_0-logloss:0.21231\n",
      "[377]\tvalidation_0-logloss:0.21229\n",
      "[378]\tvalidation_0-logloss:0.21227\n",
      "[379]\tvalidation_0-logloss:0.21225\n",
      "[380]\tvalidation_0-logloss:0.21222\n",
      "[381]\tvalidation_0-logloss:0.21220\n",
      "[382]\tvalidation_0-logloss:0.21219\n",
      "[383]\tvalidation_0-logloss:0.21217\n",
      "[384]\tvalidation_0-logloss:0.21215\n",
      "[385]\tvalidation_0-logloss:0.21212\n",
      "[386]\tvalidation_0-logloss:0.21210\n",
      "[387]\tvalidation_0-logloss:0.21207\n",
      "[388]\tvalidation_0-logloss:0.21206\n",
      "[389]\tvalidation_0-logloss:0.21204\n",
      "[390]\tvalidation_0-logloss:0.21201\n",
      "[391]\tvalidation_0-logloss:0.21200\n",
      "[392]\tvalidation_0-logloss:0.21198\n",
      "[393]\tvalidation_0-logloss:0.21197\n",
      "[394]\tvalidation_0-logloss:0.21196\n",
      "[395]\tvalidation_0-logloss:0.21194\n",
      "[396]\tvalidation_0-logloss:0.21193\n",
      "[397]\tvalidation_0-logloss:0.21191\n",
      "[398]\tvalidation_0-logloss:0.21190\n",
      "[399]\tvalidation_0-logloss:0.21188\n",
      "[400]\tvalidation_0-logloss:0.21186\n",
      "[401]\tvalidation_0-logloss:0.21184\n",
      "[402]\tvalidation_0-logloss:0.21182\n",
      "[403]\tvalidation_0-logloss:0.21181\n",
      "[404]\tvalidation_0-logloss:0.21180\n",
      "[405]\tvalidation_0-logloss:0.21179\n",
      "[406]\tvalidation_0-logloss:0.21178\n",
      "[407]\tvalidation_0-logloss:0.21177\n",
      "[408]\tvalidation_0-logloss:0.21176\n",
      "[409]\tvalidation_0-logloss:0.21175\n",
      "[410]\tvalidation_0-logloss:0.21174\n",
      "[411]\tvalidation_0-logloss:0.21174\n",
      "[412]\tvalidation_0-logloss:0.21173\n",
      "[413]\tvalidation_0-logloss:0.21172\n",
      "[414]\tvalidation_0-logloss:0.21171\n",
      "[415]\tvalidation_0-logloss:0.21170\n",
      "[416]\tvalidation_0-logloss:0.21169\n",
      "[417]\tvalidation_0-logloss:0.21168\n",
      "[418]\tvalidation_0-logloss:0.21167\n",
      "[419]\tvalidation_0-logloss:0.21167\n",
      "[420]\tvalidation_0-logloss:0.21166\n",
      "[421]\tvalidation_0-logloss:0.21164\n",
      "[422]\tvalidation_0-logloss:0.21163\n",
      "[423]\tvalidation_0-logloss:0.21162\n",
      "[424]\tvalidation_0-logloss:0.21162\n",
      "[425]\tvalidation_0-logloss:0.21162\n",
      "[426]\tvalidation_0-logloss:0.21161\n",
      "[427]\tvalidation_0-logloss:0.21160\n",
      "[428]\tvalidation_0-logloss:0.21160\n",
      "[429]\tvalidation_0-logloss:0.21159\n",
      "[430]\tvalidation_0-logloss:0.21158\n",
      "[431]\tvalidation_0-logloss:0.21158\n",
      "[432]\tvalidation_0-logloss:0.21158\n",
      "[433]\tvalidation_0-logloss:0.21155\n",
      "[434]\tvalidation_0-logloss:0.21154\n",
      "[435]\tvalidation_0-logloss:0.21153\n",
      "[436]\tvalidation_0-logloss:0.21151\n",
      "[437]\tvalidation_0-logloss:0.21150\n",
      "[438]\tvalidation_0-logloss:0.21150\n",
      "[439]\tvalidation_0-logloss:0.21149\n",
      "[440]\tvalidation_0-logloss:0.21148\n",
      "[441]\tvalidation_0-logloss:0.21147\n",
      "[442]\tvalidation_0-logloss:0.21145\n",
      "[443]\tvalidation_0-logloss:0.21144\n",
      "[444]\tvalidation_0-logloss:0.21143\n",
      "[445]\tvalidation_0-logloss:0.21142\n",
      "[446]\tvalidation_0-logloss:0.21141\n",
      "[447]\tvalidation_0-logloss:0.21141\n",
      "[448]\tvalidation_0-logloss:0.21139\n",
      "[449]\tvalidation_0-logloss:0.21138\n",
      "[450]\tvalidation_0-logloss:0.21136\n",
      "[451]\tvalidation_0-logloss:0.21135\n",
      "[452]\tvalidation_0-logloss:0.21135\n",
      "[453]\tvalidation_0-logloss:0.21135\n",
      "[454]\tvalidation_0-logloss:0.21132\n",
      "[455]\tvalidation_0-logloss:0.21131\n",
      "[456]\tvalidation_0-logloss:0.21129\n",
      "[457]\tvalidation_0-logloss:0.21129\n",
      "[458]\tvalidation_0-logloss:0.21129\n",
      "[459]\tvalidation_0-logloss:0.21127\n",
      "[460]\tvalidation_0-logloss:0.21127\n",
      "[461]\tvalidation_0-logloss:0.21127\n",
      "[462]\tvalidation_0-logloss:0.21127\n",
      "[463]\tvalidation_0-logloss:0.21126\n",
      "[464]\tvalidation_0-logloss:0.21123\n",
      "[465]\tvalidation_0-logloss:0.21124\n",
      "[466]\tvalidation_0-logloss:0.21121\n",
      "[467]\tvalidation_0-logloss:0.21121\n",
      "[468]\tvalidation_0-logloss:0.21120\n",
      "[469]\tvalidation_0-logloss:0.21118\n",
      "[470]\tvalidation_0-logloss:0.21118\n",
      "[471]\tvalidation_0-logloss:0.21117\n",
      "[472]\tvalidation_0-logloss:0.21116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[473]\tvalidation_0-logloss:0.21116\n",
      "[474]\tvalidation_0-logloss:0.21116\n",
      "[475]\tvalidation_0-logloss:0.21113\n",
      "[476]\tvalidation_0-logloss:0.21113\n",
      "[477]\tvalidation_0-logloss:0.21114\n",
      "[478]\tvalidation_0-logloss:0.21114\n",
      "[479]\tvalidation_0-logloss:0.21113\n",
      "[480]\tvalidation_0-logloss:0.21112\n",
      "[481]\tvalidation_0-logloss:0.21112\n",
      "[482]\tvalidation_0-logloss:0.21112\n",
      "[483]\tvalidation_0-logloss:0.21110\n",
      "[484]\tvalidation_0-logloss:0.21108\n",
      "[485]\tvalidation_0-logloss:0.21108\n",
      "[486]\tvalidation_0-logloss:0.21110\n",
      "[487]\tvalidation_0-logloss:0.21109\n",
      "[488]\tvalidation_0-logloss:0.21107\n",
      "[489]\tvalidation_0-logloss:0.21107\n",
      "[490]\tvalidation_0-logloss:0.21106\n",
      "[491]\tvalidation_0-logloss:0.21106\n",
      "[492]\tvalidation_0-logloss:0.21105\n",
      "[493]\tvalidation_0-logloss:0.21106\n",
      "[494]\tvalidation_0-logloss:0.21106\n",
      "[495]\tvalidation_0-logloss:0.21106\n",
      "[496]\tvalidation_0-logloss:0.21105\n",
      "[497]\tvalidation_0-logloss:0.21103\n",
      "[498]\tvalidation_0-logloss:0.21103\n",
      "[499]\tvalidation_0-logloss:0.21103\n",
      "[500]\tvalidation_0-logloss:0.21103\n",
      "[501]\tvalidation_0-logloss:0.21102\n",
      "[502]\tvalidation_0-logloss:0.21102\n",
      "[503]\tvalidation_0-logloss:0.21101\n",
      "[504]\tvalidation_0-logloss:0.21101\n",
      "[505]\tvalidation_0-logloss:0.21102\n",
      "[506]\tvalidation_0-logloss:0.21101\n",
      "[507]\tvalidation_0-logloss:0.21101\n",
      "[508]\tvalidation_0-logloss:0.21098\n",
      "[509]\tvalidation_0-logloss:0.21098\n",
      "[510]\tvalidation_0-logloss:0.21099\n",
      "[511]\tvalidation_0-logloss:0.21098\n",
      "[512]\tvalidation_0-logloss:0.21098\n",
      "[513]\tvalidation_0-logloss:0.21099\n",
      "[514]\tvalidation_0-logloss:0.21098\n",
      "[515]\tvalidation_0-logloss:0.21098\n",
      "[516]\tvalidation_0-logloss:0.21097\n",
      "[517]\tvalidation_0-logloss:0.21097\n",
      "[518]\tvalidation_0-logloss:0.21094\n",
      "[519]\tvalidation_0-logloss:0.21096\n",
      "[520]\tvalidation_0-logloss:0.21096\n",
      "[521]\tvalidation_0-logloss:0.21096\n",
      "[522]\tvalidation_0-logloss:0.21095\n",
      "[523]\tvalidation_0-logloss:0.21096\n",
      "[524]\tvalidation_0-logloss:0.21095\n",
      "[525]\tvalidation_0-logloss:0.21094\n",
      "[526]\tvalidation_0-logloss:0.21094\n",
      "[527]\tvalidation_0-logloss:0.21093\n",
      "[528]\tvalidation_0-logloss:0.21093\n",
      "[529]\tvalidation_0-logloss:0.21093\n",
      "[530]\tvalidation_0-logloss:0.21092\n",
      "[531]\tvalidation_0-logloss:0.21093\n",
      "[532]\tvalidation_0-logloss:0.21093\n",
      "[533]\tvalidation_0-logloss:0.21093\n",
      "[534]\tvalidation_0-logloss:0.21094\n",
      "[535]\tvalidation_0-logloss:0.21092\n",
      "[536]\tvalidation_0-logloss:0.21093\n",
      "[537]\tvalidation_0-logloss:0.21093\n",
      "[538]\tvalidation_0-logloss:0.21093\n",
      "[539]\tvalidation_0-logloss:0.21092\n",
      "[540]\tvalidation_0-logloss:0.21092\n",
      "[541]\tvalidation_0-logloss:0.21092\n",
      "[542]\tvalidation_0-logloss:0.21091\n",
      "[543]\tvalidation_0-logloss:0.21092\n",
      "[544]\tvalidation_0-logloss:0.21092\n",
      "[545]\tvalidation_0-logloss:0.21093\n",
      "[546]\tvalidation_0-logloss:0.21092\n",
      "[547]\tvalidation_0-logloss:0.21091\n",
      "[548]\tvalidation_0-logloss:0.21091\n",
      "[549]\tvalidation_0-logloss:0.21091\n",
      "[550]\tvalidation_0-logloss:0.21089\n",
      "[551]\tvalidation_0-logloss:0.21089\n",
      "[552]\tvalidation_0-logloss:0.21089\n",
      "[553]\tvalidation_0-logloss:0.21089\n",
      "[554]\tvalidation_0-logloss:0.21088\n",
      "[555]\tvalidation_0-logloss:0.21089\n",
      "[556]\tvalidation_0-logloss:0.21088\n",
      "[557]\tvalidation_0-logloss:0.21088\n",
      "[558]\tvalidation_0-logloss:0.21088\n",
      "[559]\tvalidation_0-logloss:0.21087\n",
      "[560]\tvalidation_0-logloss:0.21086\n",
      "[561]\tvalidation_0-logloss:0.21085\n",
      "[562]\tvalidation_0-logloss:0.21086\n",
      "[563]\tvalidation_0-logloss:0.21085\n",
      "[564]\tvalidation_0-logloss:0.21086\n",
      "[565]\tvalidation_0-logloss:0.21085\n",
      "[566]\tvalidation_0-logloss:0.21086\n",
      "[567]\tvalidation_0-logloss:0.21085\n",
      "[568]\tvalidation_0-logloss:0.21085\n",
      "[569]\tvalidation_0-logloss:0.21084\n",
      "[570]\tvalidation_0-logloss:0.21085\n",
      "[571]\tvalidation_0-logloss:0.21085\n",
      "[572]\tvalidation_0-logloss:0.21085\n",
      "[573]\tvalidation_0-logloss:0.21083\n",
      "[574]\tvalidation_0-logloss:0.21083\n",
      "[575]\tvalidation_0-logloss:0.21081\n",
      "[576]\tvalidation_0-logloss:0.21083\n",
      "[577]\tvalidation_0-logloss:0.21083\n",
      "[578]\tvalidation_0-logloss:0.21083\n",
      "[579]\tvalidation_0-logloss:0.21082\n",
      "[580]\tvalidation_0-logloss:0.21081\n",
      "[581]\tvalidation_0-logloss:0.21081\n",
      "[582]\tvalidation_0-logloss:0.21081\n",
      "[583]\tvalidation_0-logloss:0.21081\n",
      "[584]\tvalidation_0-logloss:0.21081\n",
      "[585]\tvalidation_0-logloss:0.21082\n",
      "[586]\tvalidation_0-logloss:0.21082\n",
      "[587]\tvalidation_0-logloss:0.21082\n",
      "[588]\tvalidation_0-logloss:0.21081\n",
      "[589]\tvalidation_0-logloss:0.21081\n",
      "[590]\tvalidation_0-logloss:0.21082\n",
      "[591]\tvalidation_0-logloss:0.21082\n",
      "[592]\tvalidation_0-logloss:0.21082\n",
      "[593]\tvalidation_0-logloss:0.21083\n",
      "[594]\tvalidation_0-logloss:0.21083\n",
      "[595]\tvalidation_0-logloss:0.21083\n",
      "[596]\tvalidation_0-logloss:0.21084\n",
      "[597]\tvalidation_0-logloss:0.21084\n",
      "[598]\tvalidation_0-logloss:0.21086\n",
      "[599]\tvalidation_0-logloss:0.21086\n",
      "[600]\tvalidation_0-logloss:0.21086\n",
      "[601]\tvalidation_0-logloss:0.21087\n",
      "[602]\tvalidation_0-logloss:0.21087\n",
      "[603]\tvalidation_0-logloss:0.21087\n",
      "[604]\tvalidation_0-logloss:0.21088\n",
      "[605]\tvalidation_0-logloss:0.21087\n",
      "[606]\tvalidation_0-logloss:0.21086\n",
      "[607]\tvalidation_0-logloss:0.21086\n",
      "[608]\tvalidation_0-logloss:0.21086\n",
      "[609]\tvalidation_0-logloss:0.21086\n",
      "[610]\tvalidation_0-logloss:0.21086\n",
      "[611]\tvalidation_0-logloss:0.21086\n",
      "[612]\tvalidation_0-logloss:0.21086\n",
      "[613]\tvalidation_0-logloss:0.21086\n",
      "[614]\tvalidation_0-logloss:0.21084\n",
      "[615]\tvalidation_0-logloss:0.21085\n",
      "[616]\tvalidation_0-logloss:0.21085\n",
      "[617]\tvalidation_0-logloss:0.21085\n",
      "[618]\tvalidation_0-logloss:0.21085\n",
      "[619]\tvalidation_0-logloss:0.21084\n",
      "[620]\tvalidation_0-logloss:0.21084\n",
      "[621]\tvalidation_0-logloss:0.21083\n",
      "[622]\tvalidation_0-logloss:0.21083\n",
      "[623]\tvalidation_0-logloss:0.21084\n",
      "[624]\tvalidation_0-logloss:0.21084\n",
      "[625]\tvalidation_0-logloss:0.21085\n",
      "[626]\tvalidation_0-logloss:0.21084\n",
      "[627]\tvalidation_0-logloss:0.21084\n",
      "[628]\tvalidation_0-logloss:0.21082\n",
      "[629]\tvalidation_0-logloss:0.21082\n",
      "[630]\tvalidation_0-logloss:0.21082\n",
      "[631]\tvalidation_0-logloss:0.21083\n",
      "[632]\tvalidation_0-logloss:0.21083\n",
      "[633]\tvalidation_0-logloss:0.21083\n",
      "[634]\tvalidation_0-logloss:0.21082\n",
      "[635]\tvalidation_0-logloss:0.21082\n",
      "[636]\tvalidation_0-logloss:0.21082\n",
      "[637]\tvalidation_0-logloss:0.21082\n",
      "[638]\tvalidation_0-logloss:0.21082\n",
      "[639]\tvalidation_0-logloss:0.21082\n",
      "[640]\tvalidation_0-logloss:0.21082\n",
      "[641]\tvalidation_0-logloss:0.21082\n",
      "[642]\tvalidation_0-logloss:0.21082\n",
      "[643]\tvalidation_0-logloss:0.21081\n",
      "[644]\tvalidation_0-logloss:0.21081\n",
      "[645]\tvalidation_0-logloss:0.21082\n",
      "[646]\tvalidation_0-logloss:0.21082\n",
      "[647]\tvalidation_0-logloss:0.21082\n",
      "[648]\tvalidation_0-logloss:0.21080\n",
      "[649]\tvalidation_0-logloss:0.21080\n",
      "[650]\tvalidation_0-logloss:0.21081\n",
      "[651]\tvalidation_0-logloss:0.21081\n",
      "[652]\tvalidation_0-logloss:0.21082\n",
      "[653]\tvalidation_0-logloss:0.21083\n",
      "[654]\tvalidation_0-logloss:0.21082\n",
      "[655]\tvalidation_0-logloss:0.21081\n",
      "[656]\tvalidation_0-logloss:0.21082\n",
      "[657]\tvalidation_0-logloss:0.21082\n",
      "[658]\tvalidation_0-logloss:0.21083\n",
      "[659]\tvalidation_0-logloss:0.21082\n",
      "[660]\tvalidation_0-logloss:0.21083\n",
      "[661]\tvalidation_0-logloss:0.21084\n",
      "[662]\tvalidation_0-logloss:0.21084\n",
      "[663]\tvalidation_0-logloss:0.21085\n",
      "[664]\tvalidation_0-logloss:0.21084\n",
      "[665]\tvalidation_0-logloss:0.21085\n",
      "[666]\tvalidation_0-logloss:0.21085\n",
      "[667]\tvalidation_0-logloss:0.21085\n",
      "[668]\tvalidation_0-logloss:0.21086\n",
      "[669]\tvalidation_0-logloss:0.21085\n",
      "[670]\tvalidation_0-logloss:0.21084\n",
      "[671]\tvalidation_0-logloss:0.21085\n",
      "[672]\tvalidation_0-logloss:0.21084\n",
      "[673]\tvalidation_0-logloss:0.21084\n",
      "[674]\tvalidation_0-logloss:0.21084\n",
      "[675]\tvalidation_0-logloss:0.21085\n",
      "[676]\tvalidation_0-logloss:0.21084\n",
      "[677]\tvalidation_0-logloss:0.21084\n",
      "[678]\tvalidation_0-logloss:0.21086\n",
      "[679]\tvalidation_0-logloss:0.21086\n",
      "[680]\tvalidation_0-logloss:0.21086\n",
      "[681]\tvalidation_0-logloss:0.21086\n",
      "[682]\tvalidation_0-logloss:0.21087\n",
      "[683]\tvalidation_0-logloss:0.21086\n",
      "[684]\tvalidation_0-logloss:0.21086\n",
      "[685]\tvalidation_0-logloss:0.21087\n",
      "[686]\tvalidation_0-logloss:0.21088\n",
      "[687]\tvalidation_0-logloss:0.21087\n",
      "[688]\tvalidation_0-logloss:0.21088\n",
      "[689]\tvalidation_0-logloss:0.21089\n",
      "[690]\tvalidation_0-logloss:0.21088\n",
      "[691]\tvalidation_0-logloss:0.21088\n",
      "[692]\tvalidation_0-logloss:0.21089\n",
      "[693]\tvalidation_0-logloss:0.21089\n",
      "[694]\tvalidation_0-logloss:0.21089\n",
      "[695]\tvalidation_0-logloss:0.21089\n",
      "[696]\tvalidation_0-logloss:0.21090\n",
      "[697]\tvalidation_0-logloss:0.21090\n",
      "[698]\tvalidation_0-logloss:0.21090\n",
      "[699]\tvalidation_0-logloss:0.21089\n",
      "[700]\tvalidation_0-logloss:0.21090\n",
      "[701]\tvalidation_0-logloss:0.21091\n",
      "[702]\tvalidation_0-logloss:0.21091\n",
      "[703]\tvalidation_0-logloss:0.21091\n",
      "[704]\tvalidation_0-logloss:0.21091\n",
      "[705]\tvalidation_0-logloss:0.21090\n",
      "[706]\tvalidation_0-logloss:0.21090\n",
      "[707]\tvalidation_0-logloss:0.21091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708]\tvalidation_0-logloss:0.21091\n",
      "[709]\tvalidation_0-logloss:0.21091\n",
      "[710]\tvalidation_0-logloss:0.21091\n",
      "[711]\tvalidation_0-logloss:0.21091\n",
      "[712]\tvalidation_0-logloss:0.21091\n",
      "[713]\tvalidation_0-logloss:0.21091\n",
      "[714]\tvalidation_0-logloss:0.21091\n",
      "[715]\tvalidation_0-logloss:0.21092\n",
      "[716]\tvalidation_0-logloss:0.21093\n",
      "[717]\tvalidation_0-logloss:0.21092\n",
      "[718]\tvalidation_0-logloss:0.21093\n",
      "[719]\tvalidation_0-logloss:0.21093\n",
      "[720]\tvalidation_0-logloss:0.21093\n",
      "[721]\tvalidation_0-logloss:0.21094\n",
      "[722]\tvalidation_0-logloss:0.21093\n",
      "[723]\tvalidation_0-logloss:0.21092\n",
      "[724]\tvalidation_0-logloss:0.21092\n",
      "[725]\tvalidation_0-logloss:0.21092\n",
      "[726]\tvalidation_0-logloss:0.21092\n",
      "[727]\tvalidation_0-logloss:0.21093\n",
      "[728]\tvalidation_0-logloss:0.21094\n",
      "[729]\tvalidation_0-logloss:0.21094\n",
      "[730]\tvalidation_0-logloss:0.21094\n",
      "[731]\tvalidation_0-logloss:0.21093\n",
      "[732]\tvalidation_0-logloss:0.21092\n",
      "[733]\tvalidation_0-logloss:0.21094\n",
      "[734]\tvalidation_0-logloss:0.21095\n",
      "[735]\tvalidation_0-logloss:0.21093\n",
      "[736]\tvalidation_0-logloss:0.21094\n",
      "[737]\tvalidation_0-logloss:0.21094\n",
      "[738]\tvalidation_0-logloss:0.21094\n",
      "[739]\tvalidation_0-logloss:0.21095\n",
      "[740]\tvalidation_0-logloss:0.21095\n",
      "[741]\tvalidation_0-logloss:0.21093\n",
      "[742]\tvalidation_0-logloss:0.21094\n",
      "[743]\tvalidation_0-logloss:0.21095\n",
      "[744]\tvalidation_0-logloss:0.21095\n",
      "[745]\tvalidation_0-logloss:0.21095\n",
      "[746]\tvalidation_0-logloss:0.21095\n",
      "[747]\tvalidation_0-logloss:0.21096\n",
      "[748]\tvalidation_0-logloss:0.21096\n",
      "[749]\tvalidation_0-logloss:0.21097\n",
      "[750]\tvalidation_0-logloss:0.21098\n",
      "[751]\tvalidation_0-logloss:0.21097\n",
      "[752]\tvalidation_0-logloss:0.21097\n",
      "[753]\tvalidation_0-logloss:0.21097\n",
      "[754]\tvalidation_0-logloss:0.21097\n",
      "[755]\tvalidation_0-logloss:0.21097\n",
      "[756]\tvalidation_0-logloss:0.21097\n",
      "[757]\tvalidation_0-logloss:0.21098\n",
      "[758]\tvalidation_0-logloss:0.21097\n",
      "[759]\tvalidation_0-logloss:0.21097\n",
      "[760]\tvalidation_0-logloss:0.21097\n",
      "[761]\tvalidation_0-logloss:0.21097\n",
      "[762]\tvalidation_0-logloss:0.21099\n",
      "[763]\tvalidation_0-logloss:0.21098\n",
      "[764]\tvalidation_0-logloss:0.21099\n",
      "[765]\tvalidation_0-logloss:0.21099\n",
      "[766]\tvalidation_0-logloss:0.21099\n",
      "[767]\tvalidation_0-logloss:0.21099\n",
      "[768]\tvalidation_0-logloss:0.21099\n",
      "[769]\tvalidation_0-logloss:0.21099\n",
      "[770]\tvalidation_0-logloss:0.21100\n",
      "[771]\tvalidation_0-logloss:0.21099\n",
      "[772]\tvalidation_0-logloss:0.21099\n",
      "[773]\tvalidation_0-logloss:0.21099\n",
      "[774]\tvalidation_0-logloss:0.21099\n",
      "[775]\tvalidation_0-logloss:0.21100\n",
      "[776]\tvalidation_0-logloss:0.21100\n",
      "[777]\tvalidation_0-logloss:0.21099\n",
      "[778]\tvalidation_0-logloss:0.21099\n",
      "[779]\tvalidation_0-logloss:0.21100\n",
      "[780]\tvalidation_0-logloss:0.21100\n",
      "[781]\tvalidation_0-logloss:0.21100\n",
      "[782]\tvalidation_0-logloss:0.21101\n",
      "[783]\tvalidation_0-logloss:0.21101\n",
      "[784]\tvalidation_0-logloss:0.21101\n",
      "[785]\tvalidation_0-logloss:0.21101\n",
      "[786]\tvalidation_0-logloss:0.21101\n",
      "[787]\tvalidation_0-logloss:0.21101\n",
      "[788]\tvalidation_0-logloss:0.21100\n",
      "[789]\tvalidation_0-logloss:0.21100\n",
      "[790]\tvalidation_0-logloss:0.21100\n",
      "[791]\tvalidation_0-logloss:0.21100\n",
      "[792]\tvalidation_0-logloss:0.21100\n",
      "[793]\tvalidation_0-logloss:0.21101\n",
      "[794]\tvalidation_0-logloss:0.21102\n",
      "[795]\tvalidation_0-logloss:0.21102\n",
      "[796]\tvalidation_0-logloss:0.21101\n",
      "[797]\tvalidation_0-logloss:0.21102\n",
      "[798]\tvalidation_0-logloss:0.21102\n",
      "[799]\tvalidation_0-logloss:0.21102\n",
      "[800]\tvalidation_0-logloss:0.21102\n",
      "[801]\tvalidation_0-logloss:0.21101\n",
      "[802]\tvalidation_0-logloss:0.21101\n",
      "[803]\tvalidation_0-logloss:0.21101\n",
      "[804]\tvalidation_0-logloss:0.21100\n",
      "[805]\tvalidation_0-logloss:0.21101\n",
      "[806]\tvalidation_0-logloss:0.21101\n",
      "[807]\tvalidation_0-logloss:0.21101\n",
      "[808]\tvalidation_0-logloss:0.21102\n",
      "[809]\tvalidation_0-logloss:0.21101\n",
      "[810]\tvalidation_0-logloss:0.21103\n",
      "[811]\tvalidation_0-logloss:0.21104\n",
      "[812]\tvalidation_0-logloss:0.21103\n",
      "[813]\tvalidation_0-logloss:0.21102\n",
      "[814]\tvalidation_0-logloss:0.21102\n",
      "[815]\tvalidation_0-logloss:0.21101\n",
      "[816]\tvalidation_0-logloss:0.21101\n",
      "[817]\tvalidation_0-logloss:0.21101\n",
      "[818]\tvalidation_0-logloss:0.21103\n",
      "[819]\tvalidation_0-logloss:0.21103\n",
      "[820]\tvalidation_0-logloss:0.21104\n",
      "[821]\tvalidation_0-logloss:0.21105\n",
      "[822]\tvalidation_0-logloss:0.21105\n",
      "[823]\tvalidation_0-logloss:0.21108\n",
      "[824]\tvalidation_0-logloss:0.21108\n",
      "[825]\tvalidation_0-logloss:0.21108\n",
      "[826]\tvalidation_0-logloss:0.21107\n",
      "[827]\tvalidation_0-logloss:0.21107\n",
      "[828]\tvalidation_0-logloss:0.21107\n",
      "[829]\tvalidation_0-logloss:0.21107\n",
      "[830]\tvalidation_0-logloss:0.21107\n",
      "[831]\tvalidation_0-logloss:0.21106\n",
      "[832]\tvalidation_0-logloss:0.21106\n",
      "[833]\tvalidation_0-logloss:0.21108\n",
      "[834]\tvalidation_0-logloss:0.21108\n",
      "[835]\tvalidation_0-logloss:0.21107\n",
      "[836]\tvalidation_0-logloss:0.21107\n",
      "[837]\tvalidation_0-logloss:0.21108\n",
      "[838]\tvalidation_0-logloss:0.21108\n",
      "[839]\tvalidation_0-logloss:0.21108\n",
      "[840]\tvalidation_0-logloss:0.21108\n",
      "[841]\tvalidation_0-logloss:0.21107\n",
      "[842]\tvalidation_0-logloss:0.21109\n",
      "[843]\tvalidation_0-logloss:0.21110\n",
      "[844]\tvalidation_0-logloss:0.21111\n",
      "[845]\tvalidation_0-logloss:0.21111\n",
      "[846]\tvalidation_0-logloss:0.21112\n",
      "[847]\tvalidation_0-logloss:0.21113\n",
      "[848]\tvalidation_0-logloss:0.21112\n",
      "[849]\tvalidation_0-logloss:0.21112\n",
      "[850]\tvalidation_0-logloss:0.21112\n",
      "[851]\tvalidation_0-logloss:0.21112\n",
      "[852]\tvalidation_0-logloss:0.21113\n",
      "[853]\tvalidation_0-logloss:0.21113\n",
      "[854]\tvalidation_0-logloss:0.21113\n",
      "[855]\tvalidation_0-logloss:0.21113\n",
      "[856]\tvalidation_0-logloss:0.21115\n",
      "[857]\tvalidation_0-logloss:0.21115\n",
      "[858]\tvalidation_0-logloss:0.21115\n",
      "[859]\tvalidation_0-logloss:0.21115\n",
      "[860]\tvalidation_0-logloss:0.21114\n",
      "[861]\tvalidation_0-logloss:0.21113\n",
      "[862]\tvalidation_0-logloss:0.21113\n",
      "[863]\tvalidation_0-logloss:0.21114\n",
      "[864]\tvalidation_0-logloss:0.21113\n",
      "[865]\tvalidation_0-logloss:0.21113\n",
      "[866]\tvalidation_0-logloss:0.21114\n",
      "[867]\tvalidation_0-logloss:0.21113\n",
      "[868]\tvalidation_0-logloss:0.21114\n",
      "[869]\tvalidation_0-logloss:0.21114\n",
      "[870]\tvalidation_0-logloss:0.21114\n",
      "[871]\tvalidation_0-logloss:0.21113\n",
      "[872]\tvalidation_0-logloss:0.21113\n",
      "[873]\tvalidation_0-logloss:0.21113\n",
      "[874]\tvalidation_0-logloss:0.21113\n",
      "[875]\tvalidation_0-logloss:0.21116\n",
      "[876]\tvalidation_0-logloss:0.21114\n",
      "[877]\tvalidation_0-logloss:0.21114\n",
      "[878]\tvalidation_0-logloss:0.21114\n",
      "[879]\tvalidation_0-logloss:0.21114\n",
      "[880]\tvalidation_0-logloss:0.21114\n",
      "[881]\tvalidation_0-logloss:0.21114\n",
      "[882]\tvalidation_0-logloss:0.21114\n",
      "[883]\tvalidation_0-logloss:0.21115\n",
      "[884]\tvalidation_0-logloss:0.21115\n",
      "[885]\tvalidation_0-logloss:0.21116\n",
      "[886]\tvalidation_0-logloss:0.21116\n",
      "[887]\tvalidation_0-logloss:0.21116\n",
      "[888]\tvalidation_0-logloss:0.21116\n",
      "[889]\tvalidation_0-logloss:0.21117\n",
      "[890]\tvalidation_0-logloss:0.21118\n",
      "[891]\tvalidation_0-logloss:0.21119\n",
      "[892]\tvalidation_0-logloss:0.21119\n",
      "[893]\tvalidation_0-logloss:0.21119\n",
      "[894]\tvalidation_0-logloss:0.21120\n",
      "[895]\tvalidation_0-logloss:0.21122\n",
      "[896]\tvalidation_0-logloss:0.21121\n",
      "[897]\tvalidation_0-logloss:0.21122\n",
      "[898]\tvalidation_0-logloss:0.21121\n",
      "[899]\tvalidation_0-logloss:0.21121\n",
      "[900]\tvalidation_0-logloss:0.21121\n",
      "[901]\tvalidation_0-logloss:0.21123\n",
      "[902]\tvalidation_0-logloss:0.21122\n",
      "[903]\tvalidation_0-logloss:0.21124\n",
      "[904]\tvalidation_0-logloss:0.21124\n",
      "[905]\tvalidation_0-logloss:0.21125\n",
      "[906]\tvalidation_0-logloss:0.21125\n",
      "[907]\tvalidation_0-logloss:0.21125\n",
      "[908]\tvalidation_0-logloss:0.21127\n",
      "[909]\tvalidation_0-logloss:0.21127\n",
      "[910]\tvalidation_0-logloss:0.21127\n",
      "[911]\tvalidation_0-logloss:0.21128\n",
      "[912]\tvalidation_0-logloss:0.21128\n",
      "[913]\tvalidation_0-logloss:0.21128\n",
      "[914]\tvalidation_0-logloss:0.21128\n",
      "[915]\tvalidation_0-logloss:0.21129\n",
      "[916]\tvalidation_0-logloss:0.21129\n",
      "[917]\tvalidation_0-logloss:0.21130\n",
      "[918]\tvalidation_0-logloss:0.21130\n",
      "[919]\tvalidation_0-logloss:0.21130\n",
      "[920]\tvalidation_0-logloss:0.21130\n",
      "[921]\tvalidation_0-logloss:0.21130\n",
      "[922]\tvalidation_0-logloss:0.21130\n",
      "[923]\tvalidation_0-logloss:0.21130\n",
      "[924]\tvalidation_0-logloss:0.21130\n",
      "[925]\tvalidation_0-logloss:0.21131\n",
      "[926]\tvalidation_0-logloss:0.21131\n",
      "[927]\tvalidation_0-logloss:0.21131\n",
      "[928]\tvalidation_0-logloss:0.21131\n",
      "[929]\tvalidation_0-logloss:0.21131\n",
      "[930]\tvalidation_0-logloss:0.21132\n",
      "[931]\tvalidation_0-logloss:0.21131\n",
      "[932]\tvalidation_0-logloss:0.21132\n",
      "[933]\tvalidation_0-logloss:0.21132\n",
      "[934]\tvalidation_0-logloss:0.21133\n",
      "[935]\tvalidation_0-logloss:0.21134\n",
      "[936]\tvalidation_0-logloss:0.21134\n",
      "[937]\tvalidation_0-logloss:0.21134\n",
      "[938]\tvalidation_0-logloss:0.21134\n",
      "[939]\tvalidation_0-logloss:0.21134\n",
      "[940]\tvalidation_0-logloss:0.21134\n",
      "[941]\tvalidation_0-logloss:0.21134\n",
      "[942]\tvalidation_0-logloss:0.21134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[943]\tvalidation_0-logloss:0.21134\n",
      "[944]\tvalidation_0-logloss:0.21134\n",
      "[945]\tvalidation_0-logloss:0.21134\n",
      "[946]\tvalidation_0-logloss:0.21135\n",
      "[947]\tvalidation_0-logloss:0.21135\n",
      "[948]\tvalidation_0-logloss:0.21135\n",
      "[949]\tvalidation_0-logloss:0.21136\n",
      "[950]\tvalidation_0-logloss:0.21137\n",
      "[951]\tvalidation_0-logloss:0.21137\n",
      "[952]\tvalidation_0-logloss:0.21137\n",
      "[953]\tvalidation_0-logloss:0.21137\n",
      "[954]\tvalidation_0-logloss:0.21137\n",
      "[955]\tvalidation_0-logloss:0.21137\n",
      "[956]\tvalidation_0-logloss:0.21140\n",
      "[957]\tvalidation_0-logloss:0.21140\n",
      "[958]\tvalidation_0-logloss:0.21141\n",
      "[959]\tvalidation_0-logloss:0.21141\n",
      "[960]\tvalidation_0-logloss:0.21141\n",
      "[961]\tvalidation_0-logloss:0.21142\n",
      "[962]\tvalidation_0-logloss:0.21142\n",
      "[963]\tvalidation_0-logloss:0.21143\n",
      "[964]\tvalidation_0-logloss:0.21142\n",
      "[965]\tvalidation_0-logloss:0.21142\n",
      "[966]\tvalidation_0-logloss:0.21144\n",
      "[967]\tvalidation_0-logloss:0.21144\n",
      "[968]\tvalidation_0-logloss:0.21145\n",
      "[969]\tvalidation_0-logloss:0.21145\n",
      "[970]\tvalidation_0-logloss:0.21146\n",
      "[971]\tvalidation_0-logloss:0.21146\n",
      "[972]\tvalidation_0-logloss:0.21146\n",
      "[973]\tvalidation_0-logloss:0.21146\n",
      "[974]\tvalidation_0-logloss:0.21147\n",
      "[975]\tvalidation_0-logloss:0.21146\n",
      "[976]\tvalidation_0-logloss:0.21147\n",
      "[977]\tvalidation_0-logloss:0.21147\n",
      "[978]\tvalidation_0-logloss:0.21146\n",
      "[979]\tvalidation_0-logloss:0.21146\n",
      "[980]\tvalidation_0-logloss:0.21147\n",
      "[981]\tvalidation_0-logloss:0.21147\n",
      "[982]\tvalidation_0-logloss:0.21147\n",
      "[983]\tvalidation_0-logloss:0.21146\n",
      "[984]\tvalidation_0-logloss:0.21146\n",
      "[985]\tvalidation_0-logloss:0.21147\n",
      "[986]\tvalidation_0-logloss:0.21147\n",
      "[987]\tvalidation_0-logloss:0.21148\n",
      "[988]\tvalidation_0-logloss:0.21149\n",
      "[989]\tvalidation_0-logloss:0.21150\n",
      "[990]\tvalidation_0-logloss:0.21149\n",
      "[991]\tvalidation_0-logloss:0.21149\n",
      "[992]\tvalidation_0-logloss:0.21149\n",
      "[993]\tvalidation_0-logloss:0.21150\n",
      "[994]\tvalidation_0-logloss:0.21150\n",
      "[995]\tvalidation_0-logloss:0.21151\n",
      "[996]\tvalidation_0-logloss:0.21152\n",
      "[997]\tvalidation_0-logloss:0.21153\n",
      "[998]\tvalidation_0-logloss:0.21153\n",
      "[999]\tvalidation_0-logloss:0.21154\n",
      "Train_noSMOTE\n",
      "Accuracy: 0.10723626852659111\n",
      "Confusion Matrix:\n",
      " [[    0 17408]\n",
      " [    0  2091]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     17408\n",
      "         1.0       0.11      1.00      0.19      2091\n",
      "\n",
      "    accuracy                           0.11     19499\n",
      "   macro avg       0.05      0.50      0.10     19499\n",
      "weighted avg       0.01      0.11      0.02     19499\n",
      "\n",
      "VAL_noSMOTE\n",
      "Accuracy: 0.11107692307692307\n",
      "Confusion Matrix:\n",
      " [[   0 5778]\n",
      " [   0  722]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      5778\n",
      "         1.0       0.11      1.00      0.20       722\n",
      "\n",
      "    accuracy                           0.11      6500\n",
      "   macro avg       0.06      0.50      0.10      6500\n",
      "weighted avg       0.01      0.11      0.02      6500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\15184\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_noSMOTE = XGBClassifier(\n",
    "    reg_alpha=0.1,  # L1 regularization term (alpha)\n",
    "    reg_lambda=1    # L2 regularization term (lambda)\n",
    ")\n",
    "xgb_clf_noSMOTE = XGBClassifier(n_estimators=1000, learning_rate=0.01)\n",
    "xgb_clf_noSMOTE.fit(X_train_scaled_noSMOTE, y_train_noSMOTE, eval_set=[(X_val_scaled_noSMOTE, y_val_noSMOTE)])\n",
    "\n",
    "y_train_pred_noSMOTE = xgb_clf.predict(X_train_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train_noSMOTE, y_train_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train_noSMOTE, y_train_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train_noSMOTE, y_train_pred_noSMOTE))\n",
    "\n",
    "y_val_pred_noSMOTE = xgb_clf.predict(X_val_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_noSMOTE, y_val_pred_noSMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Accuracy: 0.9999734275768607\n",
      "Confusion Matrix:\n",
      " [[18825     0]\n",
      " [    1 18807]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     18825\n",
      "         1.0       1.00      1.00      1.00     18808\n",
      "\n",
      "    accuracy                           1.00     37633\n",
      "   macro avg       1.00      1.00      1.00     37633\n",
      "weighted avg       1.00      1.00      1.00     37633\n",
      "\n",
      "VAL\n",
      "Accuracy: 0.9566326530612245\n",
      "Confusion Matrix:\n",
      " [[2269   54]\n",
      " [ 150 2231]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      2323\n",
      "         1.0       0.98      0.94      0.96      2381\n",
      "\n",
      "    accuracy                           0.96      4704\n",
      "   macro avg       0.96      0.96      0.96      4704\n",
      "weighted avg       0.96      0.96      0.96      4704\n",
      "\n",
      "TEST\n",
      "Accuracy: 0.9581296493092455\n",
      "Confusion Matrix:\n",
      " [[2333   40]\n",
      " [ 157 2175]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      2373\n",
      "         1.0       0.98      0.93      0.96      2332\n",
      "\n",
      "    accuracy                           0.96      4705\n",
      "   macro avg       0.96      0.96      0.96      4705\n",
      "weighted avg       0.96      0.96      0.96      4705\n",
      "\n",
      "TEST 2017\n",
      "Accuracy: 0.9847972330964235\n",
      "Confusion Matrix:\n",
      " [[23427    94]\n",
      " [  306  2484]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99     23521\n",
      "         1.0       0.96      0.89      0.93      2790\n",
      "\n",
      "    accuracy                           0.98     26311\n",
      "   macro avg       0.98      0.94      0.96     26311\n",
      "weighted avg       0.98      0.98      0.98     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier  # for regression tasks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instantiate the Random Forest Regressor\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred =  rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "y_pred_2017 = rf_model.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 5\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:814\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    812\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 814\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:431\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    430\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:450\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    443\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be equal to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of samples at training time\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    446\u001b[0m         )\n\u001b[0;32m    448\u001b[0m svm_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m libsvm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    451\u001b[0m     X,\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dual_coef_,\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intercept_,\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    459\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msvm_type,\n\u001b[0;32m    460\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    461\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    462\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    463\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    464\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    465\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred =  model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# To predict on the test data\n",
    "#X_test = test_data.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "#y_test = test_data['diabetes']\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "#X_test_2017 = X_test_2017.drop(columns=columns_to_drop.values[1:])\n",
    "y_pred_2017 = model.predict(X_test_2017)\n",
    "print(\"TEST 2017\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_pred_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL\n",
      "Accuracy: 0.8520408163265306\n",
      "Confusion Matrix:\n",
      " [[1955  368]\n",
      " [ 328 2053]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85      2323\n",
      "         1.0       0.85      0.86      0.86      2381\n",
      "\n",
      "    accuracy                           0.85      4704\n",
      "   macro avg       0.85      0.85      0.85      4704\n",
      "weighted avg       0.85      0.85      0.85      4704\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 48\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_val, y_val_pred))\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# To predict on the test data\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#X_test = test_data.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#y_test = test_data['diabetes']\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     50\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "#train_data = pd.read_csv('train_data.csv')\n",
    "#val_data = pd.read_csv('val_data.csv')\n",
    "#test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Inspect the data\n",
    "#print(train_data.head())\n",
    "#print(val_data.head())\n",
    "#print(test_data.head())\n",
    "\n",
    "# Assuming the target variable is named 'diabetes' and is binary (0 or 1)\n",
    "#X_train = train_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "#y_train = train_data['diabetes']\n",
    "\n",
    "#X_val = val_data.drop(['diabetes', 'house_family_person_id'], axis=1)\n",
    "#y_val = val_data['diabetes']\n",
    "\n",
    "# Optional: Check for missing values\n",
    "#print(X_train.isnull().sum())\n",
    "#print(X_val.isnull().sum())\n",
    "\n",
    "# Scale the features\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# To predict on the test data\n",
    "#X_test = test_data.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "#y_test = test_data['diabetes']\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL_noSMOTE\n",
      "Accuracy: 0.9107692307692308\n",
      "Confusion Matrix:\n",
      " [[5653  125]\n",
      " [ 455  267]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95      5778\n",
      "         1.0       0.68      0.37      0.48       722\n",
      "\n",
      "    accuracy                           0.91      6500\n",
      "   macro avg       0.80      0.67      0.72      6500\n",
      "weighted avg       0.90      0.91      0.90      6500\n",
      "\n",
      "TEST_noSMOTE\n",
      "Accuracy: 0.912\n",
      "Confusion Matrix:\n",
      " [[5778   41]\n",
      " [ 531  150]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95      5819\n",
      "         1.0       0.79      0.22      0.34       681\n",
      "\n",
      "    accuracy                           0.91      6500\n",
      "   macro avg       0.85      0.61      0.65      6500\n",
      "weighted avg       0.90      0.91      0.89      6500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "model_noSMOTE = LogisticRegression()\n",
    "model_noSMOTE.fit(X_train_scaled_noSMOTE, y_train_noSMOTE)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred_noSMOTE = model_noSMOTE.predict(X_val_scaled_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"VAL_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_noSMOTE, y_val_pred_noSMOTE))\n",
    "\n",
    "# To predict on the test data\n",
    "X_test_noSMOTE = test_data_noSMOTE.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "y_test_noSMOTE = test_data_noSMOTE['diabetes']\n",
    "X_test_scaled_noSMOTE = scaler.transform(X_test_noSMOTE)\n",
    "\n",
    "y_test_pred_noSMOTE = model_noSMOTE.predict(X_test_scaled_noSMOTE)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_noSMOTE, y_test_pred_noSMOTE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_noSMOTE, y_test_pred_noSMOTE))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_noSMOTE, y_test_pred_noSMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "Accuracy: 0.8264604157956749\n",
      "Confusion Matrix:\n",
      " [[19498  4023]\n",
      " [  543  2247]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.83      0.90     23521\n",
      "         1.0       0.36      0.81      0.50      2790\n",
      "\n",
      "    accuracy                           0.83     26311\n",
      "   macro avg       0.67      0.82      0.70     26311\n",
      "weighted avg       0.91      0.83      0.85     26311\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ny_test_pred_2017 = model_noSMOTE.predict(X_test_scaled_2017)\\n\\n# Evaluate the model\\nprint(\"TEST_noSMOTE\")\\nprint(\"Accuracy:\", accuracy_score(y_test_2017, y_test_pred_2017))\\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_test_pred_2017))\\nprint(\"Classification Report:\\n\", classification_report(y_test_2017, y_test_pred_2017))'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To predict on the test data\n",
    "model = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "#X_test_2017 = imputed_2017.drop(['diabetes', 'house_family_person_id'], axis=1)  # Ensure the test data has the same features\n",
    "#y_test_2017 = imputed_2017['diabetes']\n",
    "#X_test_scaled_2017 = scaler.transform(X_test_2017)\n",
    "\n",
    "y_test_pred_2017 = model.predict(X_test_2017)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_test_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_test_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_test_pred_2017))\n",
    "'''\n",
    "y_test_pred_2017 = model_noSMOTE.predict(X_test_scaled_2017)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"TEST_noSMOTE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_2017, y_test_pred_2017))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_2017, y_test_pred_2017))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_2017, y_test_pred_2017))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.87      0.90     23521\n",
      "         1.0       0.31      0.50      0.38      2790\n",
      "\n",
      "    accuracy                           0.83     26311\n",
      "   macro avg       0.62      0.68      0.64     26311\n",
      "weighted avg       0.87      0.83      0.84     26311\n",
      "\n",
      "C: 0.01, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.54      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.70      0.79      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 0.1, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 1, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 10, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 100, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n",
      "C: 1000, Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     23521\n",
      "         1.0       0.45      0.69      0.55      2790\n",
      "\n",
      "    accuracy                           0.88     26311\n",
      "   macro avg       0.71      0.80      0.74     26311\n",
      "weighted avg       0.91      0.88      0.89     26311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of trying different values for C\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    log_reg_l2 = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    log_reg_l2.fit(X_train, y_train)\n",
    "    y_pred_l2 = log_reg_l2.predict(X_test_2017)\n",
    "    #print(f\"C: {c}, Performance:\\n\", classification_report(y_val, y_pred_l2))\n",
    "    y_test_pred_2017 = log_reg_l2.predict(X_test_2017)\n",
    "    print(f\"C: {c}, Performance:\\n\", classification_report(y_test_2017, y_test_pred_2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "report_2017 = classification_report(y_test_2017, y_test_pred_2017)\n",
    "precision_0_2017 = report['0.0']['precision']\n",
    "recall_0_2017 = report['0.0']['recall']\n",
    "precision_1 = report['1.0']['precision']\n",
    "recall_1 = report['1.0']['recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Define null hypothesis values (expected precision under H0)\n",
    "p0_0 = precision_0  # Expected precision for class 0.0 (you can adjust this)\n",
    "p0_1 = precision_1  # Expected precision for class 1.0 (you can adjust this)\n",
    "\n",
    "# Get the number of samples for the precision calculations\n",
    "n = len(y_pred_2017)  # Total number of samples\n",
    "\n",
    "# 1. Evaluate the performance for class 0.0\n",
    "observed_precision_0 = precision_0_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 0.0\n",
    "Z_0 = (observed_precision_0 - p0_0) / np.sqrt((p0_0 * (1 - p0_0)) / n)\n",
    "\n",
    "# Calculate p-value for class 0.0\n",
    "p_value_0 = 2 * (1 - stats.norm.cdf(np.abs(Z_0)))\n",
    "\n",
    "# Evaluate the hypothesis for class 0.0\n",
    "print(f\"Class 0.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_0:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_0:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_0:.4f}\")\n",
    "print(f\"P-Value: {p_value_0:.4f}\")\n",
    "\n",
    "if p_value_0 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 0.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 0.0.\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator for clarity\n",
    "\n",
    "# 2. Evaluate the performance for class 1.0\n",
    "observed_precision_1 = precision_1_2017\n",
    "\n",
    "# Calculate Z-test statistic for class 1.0\n",
    "Z_1 = (observed_precision_1 - p0_1) / np.sqrt((p0_1 * (1 - p0_1)) / n)\n",
    "\n",
    "# Calculate p-value for class 1.0\n",
    "p_value_1 = 2 * (1 - stats.norm.cdf(np.abs(Z_1)))\n",
    "\n",
    "# Evaluate the hypothesis for class 1.0\n",
    "print(f\"Class 1.0 Performance Evaluation:\")\n",
    "print(f\"Observed Precision: {observed_precision_1:.4f}\")\n",
    "print(f\"Null Hypothesis Precision (p0): {p0_1:.4f}\")\n",
    "print(f\"Z-Statistic: {Z_1:.4f}\")\n",
    "print(f\"P-Value: {p_value_1:.4f}\")\n",
    "\n",
    "if p_value_1 < alpha:\n",
    "    print(\"Reject the null hypothesis: The model's precision for class 1.0 is significantly different from the expected value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the model's precision for class 1.0.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill in this document to complete the diabetes prediction exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
